%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Francois Collin at 2023-06-12 21:18:56 -0700 


%% Saved with string encoding Unicode (UTF-8) 



@article{Caraus:2017wa,
	abstract = {Considerable attention has been paid recently to improve data quality in high-throughput screening (HTS) and high-content screening (HCS) technologies widely used in drug development and chemical toxicity research. However, several environmentally- and procedurally-induced spatial biases in experimental HTS and HCS screens decrease measurement accuracy, leading to increased numbers of false positives and false negatives in hit selection. Although effective bias correction methods and software have been developed over the past decades, almost all of these tools have been designed to reduce the effect of additive bias only. Here, we address the case of multiplicative spatial bias.We introduce three new statistical methods meant to reduce multiplicative spatial bias in screening technologies. We assess the performance of the methods with synthetic and real data affected by multiplicative spatial bias, including comparisons with current bias correction methods. We also describe a wider data correction protocol that integrates methods for removing both assay and plate-specific spatial biases, which can be either additive or multiplicative.The methods for removing multiplicative spatial bias and the data correction protocol are effective in detecting and cleaning experimental data generated by screening technologies. As our protocol is of a general nature, it can be used by researchers analyzing current or next-generation high-throughput screens.The AssayCorrector program, implemented in R, is available on CRAN.Supplementary data are available at Bioinformatics online.},
	author = {Caraus, Iurie and Mazoure, Bogdan and Nadon, Robert and Makarenkov, Vladimir},
	date-added = {2023-06-12 21:18:41 -0700},
	date-modified = {2023-06-12 21:18:41 -0700},
	doi = {10.1093/bioinformatics/btx327},
	isbn = {1367-4803},
	journal = {Bioinformatics},
	journal1 = {Bioinformatics},
	month = {6/13/2023},
	number = {20},
	pages = {3258--3267},
	title = {Detecting and removing multiplicative spatial bias in high-throughput screening technologies},
	ty = {JOUR},
	url = {https://doi.org/10.1093/bioinformatics/btx327},
	volume = {33},
	year = {2017},
	year1 = {2017/10/15},
	Bdsk-Url-1 = {https://doi.org/10.1093/bioinformatics/btx327}}

@article{Shockley:2015ww,
	abstract = {In vitro HTS holds much potential to advance drug discovery and provide cell-based alternatives for toxicity testing. In quantitative HTS, concentration-response data can be generated simultaneously for thousands of different compounds and mixtures. However, nonlinear modeling in these multiple-concentration assays presents important statistical challenges that are not problematic for linear models. The uncertainty of parameter estimates obtained from the widely used Hill equation model can be extremely large when using standard designs. Failure to properly consider standard errors of these parameter estimates would greatly hinder chemical genomics and toxicity testing efforts. In this light, optimal study designs should be developed to improve nonlinear parameter estimation; or alternative approaches with reliable performance characteristics should be used to describe concentration-response profiles.},
	address = {Biostatistics and Computational Biology Branch, The National Institute of Environmental Health Sciences, National Institutes of Health, Research Triangle Park, NC 27709, USA. Electronic address: shockleykr@niehs.nih.gov.},
	author = {Shockley, Keith R},
	copyright = {Published by Elsevier Ltd.},
	crdt = {2014/12/03 06:00},
	date = {2015 Mar},
	date-added = {2023-06-12 14:08:48 -0700},
	date-modified = {2023-06-12 14:08:48 -0700},
	dcom = {20150831},
	dep = {20141023},
	doi = {10.1016/j.drudis.2014.10.005},
	edat = {2014/12/03 06:00},
	gr = {ZIA ES102865/Intramural NIH HHS/United States; ZIA ES102865-05/Intramural NIH HHS/United States},
	issn = {1878-5832 (Electronic); 1359-6446 (Print); 1359-6446 (Linking)},
	jid = {9604391},
	journal = {Drug Discov Today},
	jt = {Drug discovery today},
	language = {eng},
	lid = {S1359-6446(14)00401-2 {$[$}pii{$]$}; 10.1016/j.drudis.2014.10.005 {$[$}doi{$]$}},
	lr = {20191220},
	mh = {Data Interpretation, Statistical; Drug Discovery/statistics \& numerical data; High-Throughput Screening Assays/*statistics \& numerical data; Nonlinear Dynamics; Regression Analysis},
	mhda = {2015/09/01 06:00},
	mid = {NIHMS641404},
	month = {Mar},
	number = {3},
	own = {NLM},
	pages = {296--300},
	phst = {2014/07/15 00:00 {$[$}received{$]$}; 2014/09/18 00:00 {$[$}revised{$]$}; 2014/10/16 00:00 {$[$}accepted{$]$}; 2014/12/03 06:00 {$[$}entrez{$]$}; 2014/12/03 06:00 {$[$}pubmed{$]$}; 2015/09/01 06:00 {$[$}medline{$]$}},
	pii = {S1359-6446(14)00401-2},
	pl = {England},
	pmc = {PMC4375054},
	pmid = {25449657},
	pst = {ppublish},
	pt = {Journal Article; Research Support, N.I.H., Intramural},
	sb = {IM},
	status = {MEDLINE},
	title = {Quantitative high-throughput screening data analysis: challenges and recent advances.},
	volume = {20},
	year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.drudis.2014.10.005}}

@article{Klawonn:2013wk,
	abstract = {Contingency tables are a very common basis for the investigation of effects of different treatments or influences on a disease or the health state of patients. Many journals put a strong emphasis on p-values to support the validity of results. Therefore, even small contingency tables are analysed by techniques like t-test or ANOVA. Both these concepts are based on normality assumptions for the underlying data. For larger data sets, this assumption is not so critical, since the underlying statistics are based on sums of (independent) random variables which can be assumed to follow approximately a normal distribution, at least for a larger number of summands. But for smaller data sets, the normality assumption can often not be justified. Robust methods like the Wilcoxon-Mann-Whitney-U test or the Kruskal-Wallis test do not lead to statistically significant p-values for small samples. Median polish is a robust alternative to analyse contingency tables providing much more insight than just a p-value. Median polish is a technique that provides more information than just a p-value. It explains the contingency table in terms of an overall effect, row and columns effects and residuals. The underlying model for median polish is an additive model which is sometimes too restrictive. In this paper, we propose two related approach to generalise median polish. A power transformation can be applied to the values in the table, so that better results for median polish can be achieved. We propose a graphical method how to find a suitable power transformation. If the original data should be preserved, one can apply other transformations - based on so-called additive generators - that have an inverse transformation. In this way, median polish can be applied to the original data, but based on a non-additive model. The non-linearity of such a model can also be visualised to better understand the joint effects of rows and columns in a contingency table.},
	address = {Bioinformatics and Statistics, Helmholtz Centre for Infection Research, Inhoffenstr. 7, Braunschweig, D-38124 Germany ; Ostfalia University of Applied Sciences, Salzdahlumer Str. 46/48, Wolfenbuettel, D-38302 Germany.; Department of Mathematics, Indian Institute of Technology Hyderabad, Yeddumailaram, 502 205 India.; Department of Molecular Immunology, Helmholtz Centre for Infection Research, Inhoffenstr. 7, Braunschweig, D-38124 Germany.; Department of Microbiology, Saga Medical School, Saga, Japan.; Department of Epidemiology, Helmholtz Centre for Infection Research, Inhoffenstr. 7, Braunschweig, D-38124 Germany.},
	author = {Klawonn, Frank and Jayaram, Balasubramaniam and Crull, Katja and Kukita, Akiko and Pessler, Frank},
	crdt = {2015/04/01 06:00},
	date = {2013},
	date-added = {2023-06-12 13:53:21 -0700},
	date-modified = {2023-06-12 13:53:21 -0700},
	dcom = {20150331},
	dep = {20130530},
	doi = {10.1186/2047-2501-1-11},
	edat = {2013/01/01 00:00},
	issn = {2047-2501 (Print); 2047-2501 (Electronic); 2047-2501 (Linking)},
	jid = {101638060},
	journal = {Health Inf Sci Syst},
	jt = {Health information science and systems},
	language = {eng},
	lid = {10.1186/2047-2501-1-11 {$[$}doi{$]$}; 11},
	lr = {20200930},
	mhda = {2013/01/01 00:01},
	own = {NLM},
	pages = {11},
	phst = {2013/03/27 00:00 {$[$}received{$]$}; 2013/05/14 00:00 {$[$}accepted{$]$}; 2015/04/01 06:00 {$[$}entrez{$]$}; 2013/01/01 00:00 {$[$}pubmed{$]$}; 2013/01/01 00:01 {$[$}medline{$]$}},
	pii = {11},
	pl = {England},
	pmc = {PMC4340119},
	pmid = {25825662},
	pst = {epublish},
	pt = {Journal Article},
	status = {PubMed-not-MEDLINE},
	title = {Analysis of contingency tables based on generalised median polish with power transformations and non-additive models.},
	volume = {1},
	year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1186/2047-2501-1-11}}

@article{Shockley:2019uf,
	abstract = {Quantitative high throughput screening (qHTS) experiments can generate 1000s of concentration-response profiles to screen compounds for potentially adverse effects. However, potency estimates for a single compound can vary considerably in study designs incorporating multiple concentration-response profiles for each compound. We introduce an automated quality control procedure based on analysis of variance (ANOVA) to identify and filter out compounds with multiple cluster response patterns and improve potency estimation in qHTS assays. Our approach, called Cluster Analysis by Subgroups using ANOVA (CASANOVA), clusters compound-specific response patterns into statistically supported subgroups. Applying CASANOVA to 43 publicly available qHTS data sets, we found that only about 20% of compounds with response values outside of the noise band have single cluster responses. The error rates for incorrectly separating true clusters and incorrectly clumping disparate clusters were both less than 5% in extensive simulation studies. Simulation studies also showed that the bias and variance of concentration at half-maximal response (AC(50) ) estimates were usually within 10-fold when using a weighted average approach for potency estimation. In short, CASANOVA effectively sorts out compounds with "inconsistent" response patterns and produces trustworthy AC(50) values.},
	address = {Biostatistics and Computational Biology Branch, National Institute of Environmental Health Sciences, National Institutes of Health, Durham, NC, United States.; Statistics Department, University of Pennsylvania, Philadelphia, PA, United States.; Social and Scientific Systems, Durham, NC, United States.; Department of Statistics, North Carolina State University, Raleigh, NC, United States.; Department of Biostatistics, Graduate School of Public Health, University of Pittsburgh, Pittsburgh, PA, United States.},
	author = {Shockley, Keith R and Gupta, Shuva and Harris, Shawn F and Lahiri, Soumendra N and Peddada, Shyamal D},
	crdt = {2019/05/31 06:00},
	date = {2019},
	date-added = {2023-06-12 13:44:57 -0700},
	date-modified = {2023-06-12 13:44:57 -0700},
	dep = {20190509},
	doi = {10.3389/fgene.2019.00387},
	edat = {2019/05/31 06:00},
	issn = {1664-8021 (Print); 1664-8021 (Electronic); 1664-8021 (Linking)},
	jid = {101560621},
	journal = {Front Genet},
	jt = {Frontiers in genetics},
	keywords = {ANOVA; clustering; concentration-response; potency; quantitative high throughput screening; toxicological response},
	language = {eng},
	lid = {10.3389/fgene.2019.00387 {$[$}doi{$]$}; 387},
	lr = {20201001},
	mhda = {2019/05/31 06:01},
	oto = {NOTNLM},
	own = {NLM},
	pages = {387},
	phst = {2018/05/24 00:00 {$[$}received{$]$}; 2019/04/10 00:00 {$[$}accepted{$]$}; 2019/05/31 06:00 {$[$}entrez{$]$}; 2019/05/31 06:00 {$[$}pubmed{$]$}; 2019/05/31 06:01 {$[$}medline{$]$}},
	pl = {Switzerland},
	pmc = {PMC6520559},
	pmid = {31143201},
	pst = {epublish},
	pt = {Journal Article},
	status = {PubMed-not-MEDLINE},
	title = {Quality Control of Quantitative High Throughput Screening Data.},
	volume = {10},
	year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.3389/fgene.2019.00387}}

@article{Birmingham:2009vy,
	abstract = {RNA interference (RNAi) has become a powerful technique for reverse genetics and drug discovery, and in both of these areas large-scale high-throughput RNAi screens are commonly performed. The statistical techniques used to analyze these screens are frequently borrowed directly from small-molecule screening; however, small-molecule and RNAi data characteristics differ in meaningful ways. We examine the similarities and differences between RNAi and small-molecule screens, highlighting particular characteristics of RNAi screen data that must be addressed during analysis. Additionally, we provide guidance on selection of analysis techniques in the context of a sample workflow.},
	address = {The RNAi Global Initiative, Lafayette, Colorado, USA. amanda.birmingham@thermofisher.com},
	author = {Birmingham, Amanda and Selfors, Laura M and Forster, Thorsten and Wrobel, David and Kennedy, Caleb J and Shanks, Emma and Santoyo-Lopez, Javier and Dunican, Dara J and Long, Aideen and Kelleher, Dermot and Smith, Queta and Beijersbergen, Roderick L and Ghazal, Peter and Shamu, Caroline E},
	crdt = {2009/08/01 09:00},
	date = {2009 Aug},
	date-added = {2023-06-12 13:44:43 -0700},
	date-modified = {2023-06-12 13:44:43 -0700},
	dcom = {20090813},
	doi = {10.1038/nmeth.1351},
	edat = {2009/08/01 09:00},
	gr = {WT{\_}/Wellcome Trust/United Kingdom; CA078048/CA/NCI NIH HHS/United States; U54 AI057159-065330/AI/NIAID NIH HHS/United States; U54 AI057159/AI/NIAID NIH HHS/United States; BB/D019621/1/BB{\_}/Biotechnology and Biological Sciences Research Council/United Kingdom; U19 AI067751/AI/NIAID NIH HHS/United States; AI057159/AI/NIAID NIH HHS/United States; P01 CA078048/CA/NCI NIH HHS/United States; AI067751/AI/NIAID NIH HHS/United States},
	issn = {1548-7105 (Electronic); 1548-7091 (Print); 1548-7091 (Linking)},
	jid = {101215604},
	journal = {Nat Methods},
	jt = {Nature methods},
	language = {eng},
	lid = {10.1038/nmeth.1351 {$[$}doi{$]$}},
	lr = {20220321},
	mh = {Animals; Computer Simulation; Models, Statistical; *RNA Interference; RNA, Small Interfering/*chemistry/*genetics; Research Design/*statistics \& numerical data; *Small Molecule Libraries},
	mhda = {2009/08/14 09:00},
	mid = {NIHMS159092},
	month = {Aug},
	number = {8},
	own = {NLM},
	pages = {569--575},
	phst = {2009/08/01 09:00 {$[$}entrez{$]$}; 2009/08/01 09:00 {$[$}pubmed{$]$}; 2009/08/14 09:00 {$[$}medline{$]$}},
	pii = {nmeth.1351},
	pl = {United States},
	pmc = {PMC2789971},
	pmid = {19644458},
	pst = {ppublish},
	pt = {Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't; Review},
	rn = {0 (RNA, Small Interfering); 0 (Small Molecule Libraries)},
	sb = {IM},
	status = {MEDLINE},
	title = {Statistical methods for analysis of high-throughput RNA interference screens.},
	volume = {6},
	year = {2009},
	Bdsk-Url-1 = {https://doi.org/10.1038/nmeth.1351}}

@article{Piepho:2021ws,
	annote = {https://doi.org/10.1111/jac.12463},
	author = {Piepho, Hans-Peter and Williams, Emlyn R. and Michel, Volker},
	booktitle = {Journal of Agronomy and Crop Science},
	da = {2021/08/01},
	date = {2021/08/01},
	date-added = {2023-06-12 13:44:23 -0700},
	date-modified = {2023-06-12 13:44:23 -0700},
	doi = {https://doi.org/10.1111/jac.12463},
	isbn = {0931-2250},
	journal = {Journal of Agronomy and Crop Science},
	journal1 = {Journal of Agronomy and Crop Science},
	journal2 = {J Agro Crop Sci},
	keywords = {A-efficiency; average efficiency factor; experimental design; latinization; row--column design},
	m3 = {https://doi.org/10.1111/jac.12463},
	month = {2023/06/12},
	n2 = {Abstract Blocking is a standard strategy for improving the precision of randomized experimental designs. In field trials, it is usually beneficial to impose blocks in both row and column directions. A common problem with classical randomized row?column designs is that replications of a treatment may be clustered and that some pairs of treatments appear next to each other rather more often than others. Such patterns adversely affect certain design properties which we refer to as neighbour balance (NB) and evenness of distribution (ED), and they may be particularly harmful if some of the treatments are very susceptible to environmental stresses. Here, we consider an experimental design strategy for blocked experiments that achieves good NB\&ED properties. The approach is exemplified using five examples, spanning non-resolvable and resolvable replicated designs as well as partially replicated designs.},
	number = {4},
	pages = {745--753},
	publisher = {John Wiley \& Sons, Ltd},
	title = {Generating row--column field experimental designs with good neighbour balance and even distribution of treatment replications},
	ty = {JOUR},
	url = {https://doi.org/10.1111/jac.12463},
	volume = {207},
	year = {2021},
	year1 = {2021},
	Bdsk-Url-1 = {https://doi.org/10.1111/jac.12463}}

@article{Park:2020wb,
	abstract = {Quantitative high throughput screening (qHTS) assays are used to assess toxicity for many chemicals in a short period by collectively analyzing them at several concentrations. Data are routinely analyzed using nonlinear regression models; however, we propose a new method to analyze qHTS data using a nonlinear mixed effects model. qHTS data are generated by repeating the same experiment several times for each chemical; therefor, they can be viewed as if they are repeated measures data and hence analyzed using a nonlinear mixed effects model which accounts for both intra- and inter-individual variabilities. Furthermore, we apply a one-step approach incorporating robust estimation methods to estimate fixed effect parameters and the variance-covariance structure since outliers or influential observations are not uncommon in qHTS data. The toxicity of chemicals from a qHTS assay is classified based on the significance of a parameter related to the efficacy of the chemicals using the proposed method. We evaluate the performance of the proposed method in terms of power and false discovery rate using simulation studies comparing with one existing method. The proposed method is illustrated using a dataset obtained from the National Toxicology Program.},
	author = {Park, Chorong and Lee, Jongga and Lim, Changwon},
	date = {2020/11/},
	date-added = {2023-06-12 13:44:17 -0700},
	date-modified = {2023-06-12 13:44:17 -0700},
	doi = {10.29220/CSAM.2020.27.6.701},
	et = {2020/11/30},
	isbn = {2287-7843; 2383-4757},
	j2 = {CSAM},
	journal = {Communications for Statistical Applications and Methods},
	keywords = {nonlinear mixed effects model; robust estimation; quantitative high throughput screening},
	la = {eng},
	month = {11},
	number = {6},
	pages = {701--714},
	publisher = {The Korean Statistical Society, and Korean International Statistical Society},
	title = {Analysis of quantitative high throughput screening data using a robust method for nonlinear mixed effects models},
	ty = {JOUR},
	url = {http://http://www.csam.or.kr/journal/view.html?doi=10.29220/CSAM.2020.27.6.701},
	volume = {27},
	year = {2020},
	Bdsk-Url-1 = {http://http://www.csam.or.kr/journal/view.html?doi=10.29220/CSAM.2020.27.6.701},
	Bdsk-Url-2 = {https://doi.org/10.29220/CSAM.2020.27.6.701}}

@article{Lachmann:2016vk,
	abstract = {Motivation: Multiplex readout assays are now increasingly being performed using microfluidic automation in multiwell format. For instance, the Library of Integrated Network-based Cellular Signatures (LINCS) has produced gene expression measurements for tens of thousands of distinct cell perturbations using a 384-well plate format. This dataset is by far the largest 384-well gene expression measurement assay ever performed. We investigated the gene expression profiles of a million samples from the LINCS dataset and found that the vast majority (96{\%}) of the tested plates were affected by a significant 2D spatial bias.Results: Using a novel algorithm combining spatial autocorrelation detection and principal component analysis, we could remove most of the spatial bias from the LINCS dataset and show in parallel a dramatic improvement of similarity between biological replicates assayed in different plates. The proposed methodology is fully general and can be applied to any highly multiplexed assay performed in multiwell format.Contact:  ac2248{\char64}columbia.eduSupplementary information: Supplementary data are available at Bioinformatics online.},
	author = {Lachmann, Alexander and Giorgi, Federico M. and Alvarez, Mariano J. and Califano, Andrea},
	date-added = {2023-06-12 12:03:40 -0700},
	date-modified = {2023-06-12 12:03:40 -0700},
	doi = {10.1093/bioinformatics/btw092},
	isbn = {1367-4803},
	journal = {Bioinformatics},
	journal1 = {Bioinformatics},
	month = {6/12/2023},
	number = {13},
	pages = {1959--1965},
	title = {Detection and removal of spatial bias in multiwell assays},
	ty = {JOUR},
	url = {https://doi.org/10.1093/bioinformatics/btw092},
	volume = {32},
	year = {2016},
	year1 = {2016/07/01},
	Bdsk-Url-1 = {https://doi.org/10.1093/bioinformatics/btw092}}

@article{Zhang:2008uu,
	abstract = {RNA interference (RNAi) is a modality in which small double-stranded RNA molecules (siRNAs) designed to lead to the degradation of specific mRNAs are introduced into cells or organisms. siRNA libraries have been developed in which siRNAs targeting virtually every gene in the human genome are designed, synthesized and are presented for introduction into cells by transfection in a microtiter plate array. These siRNAs can then be transfected into cells using high-throughput screening (HTS) methodologies. The goal of RNAi HTS is to identify a set of siRNAs that inhibit or activate defined cellular phenotypes. The commonly used analysis methods including median $\pm$k MAD have issues about error rates in multiple hypothesis testing and plate-wise versus experiment-wise analysis. We propose a methodology based on a Bayesian framework to address these issues. Our approach allows for sharing of information across plates in a plate-wise analysis, which obviates the need for choosing either a plate-wise or experimental-wise analysis. The proposed approach incorporates information from reliable controls to achieve a higher power and a balance between the contribution from the samples and control wells. Our approach provides false discovery rate (FDR) control to address multiple testing issues and it is robust to outliers.},
	author = {Zhang, Xiaohua Douglas and Kuan, Pei Fen and Ferrer, Marc and Shu, Xiaohua and Liu, Yingxue C. and Gates, Adam T. and Kunapuli, Priya and Stec, Erica M. and Xu, Min and Marine, Shane D. and Holder, Daniel J. and Strulovici, Berta and Heyse, Joseph F. and Espeseth, Amy S.},
	date-added = {2023-06-12 11:27:01 -0700},
	date-modified = {2023-06-12 11:27:01 -0700},
	doi = {10.1093/nar/gkn435},
	isbn = {0305-1048},
	journal = {Nucleic Acids Research},
	journal1 = {Nucleic Acids Res},
	month = {6/12/2023},
	number = {14},
	pages = {4667--4679},
	title = {Hit selection with false discovery rate control in genome-scale RNAi screens},
	ty = {JOUR},
	url = {https://doi.org/10.1093/nar/gkn435},
	volume = {36},
	year = {2008},
	year1 = {2008/08/01},
	Bdsk-Url-1 = {https://doi.org/10.1093/nar/gkn435}}

@article{Wu:2008wu,
	annote = {doi: 10.1177/1087057107312628},
	author = {Zhijin Wu and Dongmei Liu and Yunxia Sui},
	booktitle = {Journal of Biomolecular Screening},
	da = {2008/02/01},
	date = {2008/01/23},
	date-added = {2023-06-12 10:39:07 -0700},
	date-modified = {2023-06-12 10:39:07 -0700},
	doi = {10.1177/1087057107312628},
	isbn = {1087-0571},
	journal = {Journal of Biomolecular Screening},
	journal1 = {J Biomol Screen},
	m3 = {doi: 10.1177/1087057107312628},
	month = {2023/06/12},
	n2 = {The process of identifying active targets (hits) in high-throughput screening (HTS) usually involves 2 steps: first, removing or adjusting for systematic variation in the measurement process so that extreme values represent strong biological activity instead of systematic biases such as plate effect or edge effect and, second, choosing a meaningful cutoff on the calculated statistic to declare positive compounds. Both false-positive and false-negative errors are inevitable in this process. Common control or estimation of error rates is often based on an assumption of normal distribution of the noise. The error rates in hit detection, especially false-negative rates, are hard to verify because in most assays, only compounds selected in primary screening are followed up in confirmation experiments. In this article, the authors take advantage of a quantitative HTS experiment in which all compounds are tested 42 times over a wide range of 14 concentrations so true positives can be found through a dose-response curve. Using the activity status defined by dose curve, the authors analyzed the effect of various data-processing procedures on the sensitivity and specificity of hit detection, the control of error rate, and hit confirmation. A new summary score is proposed and demonstrated to perform well in hit detection and useful in confirmation rate estimation. In general, adjusting for positional effects is beneficial, but a robust test can prevent overadjustment. Error rates estimated based on normal assumption do not agree with actual error rates, for the tails of noise distribution deviate from normal distribution. However, false discovery rate based on empirically estimated null distribution is very close to observed false discovery proportion. (Journal of Biomolecular Screening 2008:159-167)},
	number = {2},
	pages = {159--167},
	publisher = {SAGE Publications Inc STM},
	title = {Quantitative Assessment of Hit Detection and Confirmation in Single and Duplicate High-Throughput Screenings},
	ty = {JOUR},
	url = {https://doi.org/10.1177/1087057107312628},
	volume = {13},
	year = {2008},
	year1 = {2008},
	Bdsk-Url-1 = {https://doi.org/10.1177/1087057107312628}}

@article{Brideau:2003vv,
	annote = {doi: 10.1177/1087057103258285},
	author = {Brideau, Christine and Gunter, Bert and Pikounis, Bill and Liaw, Andy},
	booktitle = {Journal of Biomolecular Screening},
	da = {2003/12/01},
	date = {2003/12/01},
	date-added = {2023-06-12 10:34:56 -0700},
	date-modified = {2023-06-12 10:34:56 -0700},
	doi = {10.1177/1087057103258285},
	isbn = {1087-0571},
	journal = {Journal of Biomolecular Screening},
	journal1 = {J Biomol Screen},
	m3 = {doi: 10.1177/1087057103258285},
	month = {2023/06/12},
	n2 = {High-throughput screening (HTS) plays a central role in modern drug discovery, allowing the rapid screening of large compound collections against a variety of putative drug targets. HTS is an industrial-scale process, relying on sophisticated auto mation, control, and state-of-the art detection technologies to organize, test, and measure hundreds of thousands to millions of compounds in nano-to microliter volumes. Despite this high technology, hit selection for HTS is still typically done using simple data analysis and basic statistical methods. The authors discuss in this article some shortcomings of these methods and present alternatives based on modern methods of statistical data analysis. Most important, they describe and show numerous real examples from the biologist-friendly Stat Server? HTS application (SHS), a custom-developed software tool built on the commercially available S-PLUS? and StatServer? statistical analysis and server software. This system remotely processes HTS data using powerful and sophisticated statistical methodology but insulates users from the technical details by outputting results in a variety of readily interpretable graphs and tables.},
	number = {6},
	pages = {634--647},
	publisher = {SAGE Publications Inc STM},
	title = {Improved Statistical Methods for Hit Selection in High-Throughput Screening},
	ty = {JOUR},
	url = {https://doi.org/10.1177/1087057103258285},
	volume = {8},
	year = {2003},
	year1 = {2003},
	Bdsk-Url-1 = {https://doi.org/10.1177/1087057103258285}}

@article{Caraus:2015wb,
	abstract = {Significant efforts have been made recently to improve data throughput and data quality in screening technologies related to drug design. The modern pharmaceutical industry relies heavily on high-throughput screening (HTS) and high-content screening (HCS) technologies, which include small molecule, complementary DNA (cDNA) and RNA interference (RNAi) types of screening. Data generated by these screening technologies are subject to several environmental and procedural systematic biases, which introduce errors into the hit identification process. We first review systematic biases typical of HTS and HCS screens. We highlight that study design issues and the way in which data are generated are crucial for providing unbiased screening results. Considering various data sets, including the publicly available ChemBank data, we assess the rates of systematic bias in experimental HTS by using plate-specific and assay-specific error detection tests. We describe main data normalization and correction techniques and introduce a general data preprocessing protocol. This protocol can be recommended for academic and industrial researchers involved in the analysis of current or next-generation HTS data.},
	author = {Caraus, Iurie and Alsuwailem, Abdulaziz A. and Nadon, Robert and Makarenkov, Vladimir},
	date-added = {2023-06-12 10:03:21 -0700},
	date-modified = {2023-06-12 10:03:21 -0700},
	doi = {10.1093/bib/bbv004},
	isbn = {1467-5463},
	journal = {Briefings in Bioinformatics},
	journal1 = {Brief Bioinform},
	month = {6/12/2023},
	number = {6},
	pages = {974--986},
	title = {Detecting and overcoming systematic bias in high-throughput screening technologies: a comprehensive review of practical issues and methodological solutions},
	ty = {JOUR},
	url = {https://doi.org/10.1093/bib/bbv004},
	volume = {16},
	year = {2015},
	year1 = {2015/11/01},
	Bdsk-Url-1 = {https://doi.org/10.1093/bib/bbv004}}

@inproceedings{Gagarin:2006uc,
	abstract = {High-throughput screening (HTS) is an efficient technological tool for drug discovery in the modern pharmaceutical industry. It consists of testing thousands of chemical compounds per day to select active ones. This process has many drawbacks that may result in missing a potential drug candidate or in selecting inactive compounds. We describe and compare two statistical methods for correcting systematic errors that may occur during HTS experiments. Namely, the collected HTS measurements and the hit selection procedure are corrected.},
	address = {Berlin, Heidelberg},
	author = {Gagarin, Andrei and Kevorkov, Dmytro and Makarenkov, Vladimir and Zentilli, Pablo},
	booktitle = {Data Science and Classification},
	da = {2006//},
	date-added = {2023-06-12 10:03:21 -0700},
	date-modified = {2023-06-12 10:03:21 -0700},
	editor = {Batagelj, Vladimir and Bock, Hans-Hermann and Ferligoj, Anu{\v s}ka and {\v Z}iberna, Ale{\v s}},
	id = {10.1007/3-540-34416-0{\_}26},
	isbn = {978-3-540-34416-2},
	pages = {241--249},
	publisher = {Springer Berlin Heidelberg},
	title = {Comparison of Two Methods for Detecting and Correcting Systematic Error in High-throughput Screening Data},
	ty = {CONF},
	year = {2006}}

@article{Qu:2010tm,
	annote = {doi: 10.1198/TECH.2010.09128},
	author = {Qu, Xianggui},
	booktitle = {Technometrics},
	da = {2010/11/01},
	date = {2010/11/01},
	date-added = {2023-06-12 10:03:21 -0700},
	date-modified = {2023-06-12 10:03:21 -0700},
	doi = {10.1198/TECH.2010.09128},
	isbn = {0040-1706},
	journal = {Technometrics},
	journal1 = {Technometrics},
	m3 = {doi: 10.1198/TECH.2010.09128},
	month = {11},
	number = {4},
	pages = {409--420},
	publisher = {Taylor \& Francis},
	title = {Optimal Row--Column Designs in High-Throughput Screening Experiments},
	ty = {JOUR},
	url = {https://doi.org/10.1198/TECH.2010.09128},
	volume = {52},
	year = {2010},
	year1 = {2010},
	Bdsk-Url-1 = {https://doi.org/10.1198/TECH.2010.09128}}

@article{Qu:2011tp,
	abstract = {A new class of row--column designs is proposed. These designs are saturated in terms of eliminating two-way heterogeneity with an additive model. The proposed designs are treatment-connected, i.e., all paired comparisons of treatments in the designs are estimable in spite of the existence of row and column effects. The connectedness of the designs is justified from two perspectives: linear model and contrast estimability. Comparisons with other designs are studied in terms of A-, D-, E-efficiencies as well as design balance.},
	author = {Qu, Xianggui},
	da = {2011/09/01/},
	date-added = {2023-06-12 10:03:21 -0700},
	date-modified = {2023-06-12 10:03:21 -0700},
	doi = {https://doi.org/10.1016/j.jspi.2011.04.006},
	isbn = {0378-3758},
	journal = {Journal of Statistical Planning and Inference},
	keywords = {Binary design; (M,S)-optimal design; Row--column design; Saturated design; S-optimal design},
	number = {9},
	pages = {3193--3200},
	title = {Row--column designs with minimal units},
	ty = {JOUR},
	url = {https://www.sciencedirect.com/science/article/pii/S0378375811001492},
	volume = {141},
	year = {2011},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/S0378375811001492},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.jspi.2011.04.006}}

@article{Zhang:2012wj,
	abstract = {The pharmaceutical industry is presently suffering difficult times due to low productivity of new molecular entities. As a major source of drug leads, high-throughput screening (HTS) has been often criticized for its `dead end'lead compounds. However, the fruitful achievements resulting from HTS technology indicate that it remains a feasible way for drug innovation. Because of increasing considerations of earlier stage ADMET (absorption, distribution, metabolism, excretion and toxicity) in drug development, cell-based HTS is highly recommended in modern drug discovery for its ability to detect more biologically relevant characteristics of compounds in living systems. This review provides a systematic and practical description of vital points for conducting high quality cell-based HTS, from assay development to optimization, compound management, data analyses, hit validation as well as lead identification. Potential problems and solutions are also covered.},
	author = {Zhang, Zhiyun and Guan, Ni and Li, Ting and Mais, Dale E. and Wang, Mingwei},
	da = {2012/10/01/},
	date-added = {2023-06-12 10:03:21 -0700},
	date-modified = {2023-06-12 10:03:21 -0700},
	doi = {https://doi.org/10.1016/j.apsb.2012.03.006},
	isbn = {2211-3835},
	journal = {Acta Pharmaceutica Sinica B},
	keywords = {High-throughput screening; Cell-based assay; Quality control},
	number = {5},
	pages = {429--438},
	title = {Quality control of cell-based high-throughput drug screening},
	ty = {JOUR},
	url = {https://www.sciencedirect.com/science/article/pii/S2211383512000548},
	volume = {2},
	year = {2012},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/S2211383512000548},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.apsb.2012.03.006}}

@article{Paricharak:2018aa,
	abstract = {High-throughput screening (HTS) campaigns are routinely performed in pharmaceutical companies to explore activity profiles of chemical libraries for the identification of promising candidates for further investigation. With the aim of improving hit rates in these campaigns, data-driven approaches have been used to design relevant compound screening collections, enable effective hit triage and perform activity modeling for compound prioritization. Remarkable progress has been made in the activity modeling area since the recent introduction of large-scale bioactivity-based compound similarity metrics. This is evidenced by increased hit rates in iterative screening strategies and novel insights into compound mode of action obtained through activity modeling. Here, we provide an overview of the developments in data-driven approaches, elaborate on novel activity modeling techniques and screening paradigms explored and outline their significance in HTS.},
	address = {Centre for Molecular Informatics, Department of Chemistry, University of Cambridge, Lensfield Road, Cambridge, United Kingdom.; Division of Medicinal Chemistry, Leiden Academic Centre for Drug Research, Leiden University, RA Leiden, The Netherlands.; Centre for Molecular Informatics, Department of Chemistry, University of Cambridge, Lensfield Road, Cambridge, United Kingdom.; Facultad de Qu{\'\i}mica, Departamento de Farmacia, Universidad Nacional Aut{\'o}noma de M{\'e}xico, Avenida Universidad 3000, Mexico City, Mexico.; Centre for Molecular Informatics, Department of Chemistry, University of Cambridge, Lensfield Road, Cambridge, United Kingdom.; Centre for Molecular Informatics, Department of Chemistry, University of Cambridge, Lensfield Road, Cambridge, United Kingdom.; Division of Medicinal Chemistry, Leiden Academic Centre for Drug Research, Leiden University, RA Leiden, The Netherlands.; Division of Medicinal Chemistry, Leiden Academic Centre for Drug Research, Leiden University, RA Leiden, The Netherlands.},
	author = {Paricharak, Shardul and M{\'e}ndez-Lucio, Oscar and Chavan Ravindranath, Aakash and Bender, Andreas and IJzerman, Adriaan P and van Westen, Gerard J P},
	crdt = {2016/10/30 06:00},
	date = {2018 Mar 1},
	date-added = {2023-06-12 10:03:21 -0700},
	date-modified = {2023-06-12 10:03:21 -0700},
	dcom = {20190228},
	doi = {10.1093/bib/bbw105},
	edat = {2016/10/30 06:00},
	issn = {1477-4054 (Electronic); 1467-5463 (Print); 1467-5463 (Linking)},
	jid = {100912837},
	journal = {Brief Bioinform},
	jt = {Briefings in bioinformatics},
	language = {eng},
	lid = {10.1093/bib/bbw105 {$[$}doi{$]$}},
	lr = {20190228},
	mh = {Animals; Data Collection; *Drug Design; Drug Discovery/*methods; High-Throughput Screening Assays/*methods; Humans; *Models, Molecular; Small Molecule Libraries/*chemistry/*metabolism; Structure-Activity Relationship},
	mhda = {2019/03/01 06:00},
	month = {Mar},
	number = {2},
	own = {NLM},
	pages = {277--285},
	phst = {2016/07/19 00:00 {$[$}received{$]$}; 2016/10/30 06:00 {$[$}pubmed{$]$}; 2019/03/01 06:00 {$[$}medline{$]$}; 2016/10/30 06:00 {$[$}entrez{$]$}},
	pii = {2568609; bbw105},
	pl = {England},
	pmc = {PMC6018726},
	pmid = {27789427},
	pst = {ppublish},
	pt = {Journal Article; Research Support, Non-U.S. Gov't; Review},
	rn = {0 (Small Molecule Libraries)},
	sb = {IM},
	status = {MEDLINE},
	title = {Data-driven approaches used for compound library design, hit triage and bioactivity modeling in high-throughput screening.},
	volume = {19},
	year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1093/bib/bbw105}}

@article{Kevorkov:2005tk,
	abstract = {High-throughput screening (HTS) is an efficient technology for drug discovery. It allows for screening of more than 100,000 compounds a day per screen and requires effective procedures for quality control. The authors have developed a method for evaluating a background surface of an HTS assay; it can be used to correct raw HTS data. This correction is necessary to take into account systematic errors that may affect the procedure of hit selection. The described method allows one to analyze experimental HTS data and determine trends and local fluctuations of the corresponding background surfaces. For an assay with a large number of plates, the deviations of the background surface from a plane are caused by systematic errors. Their influence can be minimized by the subtraction of the systematic background from the raw data. Two experimental HTS assays from the ChemBank database are examined in this article. The systematic error present in these data was estimated and removed from them. It enabled the authors to correct the hit selection procedure for both assays.},
	address = {Laboratoire LACIM, Universit{\'e}du Qu{\'e}bec {\`a}Montr{\'e}al, Canada.},
	author = {Kevorkov, Dmytro and Makarenkov, Vladimir},
	crdt = {2005/08/17 09:00},
	date = {2005 Sep},
	date-added = {2023-06-12 10:03:21 -0700},
	date-modified = {2023-06-12 10:03:21 -0700},
	dcom = {20051123},
	dep = {20050815},
	doi = {10.1177/1087057105276989},
	edat = {2005/08/17 09:00},
	issn = {1087-0571 (Print); 1087-0571 (Linking)},
	jid = {9612112},
	journal = {J Biomol Screen},
	jt = {Journal of biomolecular screening},
	language = {eng},
	lr = {20110523},
	mh = {Algorithms; Automation; Chemistry, Pharmaceutical; Computational Biology/methods; Drug Evaluation, Preclinical/methods; Internet; Models, Statistical; Normal Distribution; Oligonucleotide Array Sequence Analysis/*methods; Quality Control; Reproducibility of Results; Software; Statistics as Topic/methods; Technology, Pharmaceutical; Time Factors},
	mhda = {2005/12/13 09:00},
	month = {Sep},
	number = {6},
	own = {NLM},
	pages = {557--567},
	phst = {2005/08/17 09:00 {$[$}pubmed{$]$}; 2005/12/13 09:00 {$[$}medline{$]$}; 2005/08/17 09:00 {$[$}entrez{$]$}},
	pii = {1087057105276989},
	pl = {United States},
	pmid = {16103415},
	pst = {ppublish},
	pt = {Journal Article; Research Support, Non-U.S. Gov't},
	sb = {IM},
	status = {MEDLINE},
	title = {Statistical analysis of systematic errors in high-throughput screening.},
	volume = {10},
	year = {2005},
	Bdsk-Url-1 = {https://doi.org/10.1177/1087057105276989}}

@article{List:2016wp,
	abstract = {High-throughput screening (HTS) is an indispensable tool for drug (target) discovery that currently lacks user-friendly software tools for the robust identification of putative hits from HTS experiments and for the interpretation of these findings in the context of systems biology. We developed HiTSeekR as a one-stop solution for chemical compound screens, siRNA knock-down and CRISPR/Cas9 knock-out screens, as well as microRNA inhibitor and -mimics screens. We chose three use cases that demonstrate the potential of HiTSeekR to fully exploit HTS screening data in quite heterogeneous contexts to generate novel hypotheses for follow-up experiments: (i) a genome-wide RNAi screen to uncover modulators of TNFα, (ii) a combined siRNA and miRNA mimics screen on vorinostat resistance and (iii) a small compound screen on KRAS synthetic lethality. HiTSeekR is publicly available at http://hitseekr.compbio.sdu.dk It is the first approach to close the gap between raw data processing, network enrichment and wet lab target generation for various HTS screen types.},
	address = {Lundbeckfonden Center of Excellence in Nanomedicine (NanoCAN), University of Southern Denmark, 5000 Odense, Denmark Molecular Oncology, Institute of Molecular Medicin (IMM), University of Southern Denmark, 5000 Odense, Denmark Clinical Institute (CI), University of Southern Denmark, 5000 Odense, Denmark markus.list@mpi-inf.mpg.de.; Lundbeckfonden Center of Excellence in Nanomedicine (NanoCAN), University of Southern Denmark, 5000 Odense, Denmark Molecular Oncology, Institute of Molecular Medicin (IMM), University of Southern Denmark, 5000 Odense, Denmark.; Lundbeckfonden Center of Excellence in Nanomedicine (NanoCAN), University of Southern Denmark, 5000 Odense, Denmark Molecular Oncology, Institute of Molecular Medicin (IMM), University of Southern Denmark, 5000 Odense, Denmark.; Computational Biology Unit, Department of Informatics, University of Bergen, 5020 Bergen, Norway.; Clinical Institute (CI), University of Southern Denmark, 5000 Odense, Denmark Epidemiology, Biostatistics and Biodemography, Institute of Public Health, University of Southern Denmark, 5000 Odense, Denmark.; Lundbeckfonden Center of Excellence in Nanomedicine (NanoCAN), University of Southern Denmark, 5000 Odense, Denmark Molecular Oncology, Institute of Molecular Medicin (IMM), University of Southern Denmark, 5000 Odense, Denmark.; Department of Mathematics and Computer Science (IMADA), University of Southern Denmark, 5230 Odense, Denmark Max Planck Institute for Informatics, 66123 Saarbr{\"u}cken, Germany jbaumbac@mpi-inf.mpg.de.},
	auid = {ORCID: 0000-0002-0941-4168},
	author = {List, Markus and Schmidt, Steffen and Christiansen, Helle and Rehmsmeier, Marc and Tan, Qihua and Mollenhauer, Jan and Baumbach, Jan},
	copyright = {{\copyright}The Author(s) 2016. Published by Oxford University Press on behalf of Nucleic Acids Research.},
	crdt = {2016/06/23 06:00},
	date = {2016 Aug 19},
	date-added = {2023-06-12 10:03:21 -0700},
	date-modified = {2023-06-12 10:03:21 -0700},
	dcom = {20170605},
	dep = {20160621},
	doi = {10.1093/nar/gkw554},
	edat = {2016/06/23 06:00},
	issn = {1362-4962 (Electronic); 0305-1048 (Print); 0305-1048 (Linking)},
	jid = {0411011},
	journal = {Nucleic Acids Res},
	jt = {Nucleic acids research},
	language = {eng},
	lid = {10.1093/nar/gkw554 {$[$}doi{$]$}},
	lr = {20220316},
	mh = {Caspases/metabolism; Drug Delivery Systems; *Drug Evaluation, Preclinical; High-Throughput Screening Assays/*methods; Humans; MicroRNAs/genetics/metabolism; Quality Control; RNA Interference; Robotics; Signal Transduction; Tumor Necrosis Factor-alpha/metabolism},
	mhda = {2017/06/06 06:00},
	month = {Aug},
	number = {14},
	own = {NLM},
	pages = {6639--6648},
	phst = {2016/06/08 00:00 {$[$}accepted{$]$}; 2016/04/12 00:00 {$[$}received{$]$}; 2016/06/23 06:00 {$[$}entrez{$]$}; 2016/06/23 06:00 {$[$}pubmed{$]$}; 2017/06/06 06:00 {$[$}medline{$]$}},
	pii = {gkw554},
	pl = {England},
	pmc = {PMC5001608},
	pmid = {27330136},
	pst = {ppublish},
	pt = {Journal Article; Research Support, Non-U.S. Gov't},
	rn = {0 (MicroRNAs); 0 (Tumor Necrosis Factor-alpha); EC 3.4.22.- (Caspases)},
	sb = {IM},
	status = {MEDLINE},
	title = {Comprehensive analysis of high-throughput screens with HiTSeekR.},
	volume = {44},
	year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.1093/nar/gkw554}}

@article{Malo:2010wk,
	abstract = {Identification of active compounds in high-throughput screening (HTS) contexts can be substantially improved by applying classical experimental design and statistical inference principles to all phases of HTS studies. The authors present both experimental and simulated data to illustrate how true-positive rates can be maximized without increasing false-positive rates by the following analytical process. First, the use of robust data preprocessing methods reduces unwanted variation by removing row, column, and plate biases. Second, replicate measurements allow estimation of the magnitude of the remaining random error and the use of formal statistical models to benchmark putative hits relative to what is expected by chance. Receiver Operating Characteristic (ROC) analyses revealed superior power for data preprocessed by a trimmed-mean polish method combined with the RVM t-test, particularly for small- to moderate-sized biological hits.},
	address = {McGill University and Genome Quebec Innovation Centre, Montreal, Quebec, Canada.},
	author = {Malo, Nathalie and Hanley, James A and Carlile, Graeme and Liu, Jing and Pelletier, Jerry and Thomas, David and Nadon, Robert},
	crdt = {2010/09/07 06:00},
	date = {2010 Sep},
	date-added = {2023-06-12 10:03:21 -0700},
	date-modified = {2023-06-12 10:03:21 -0700},
	dcom = {20110112},
	doi = {10.1177/1087057110377497},
	edat = {2010/09/08 06:00},
	issn = {1552-454X (Electronic); 1087-0571 (Linking)},
	jid = {9612112},
	journal = {J Biomol Screen},
	jt = {Journal of biomolecular screening},
	language = {eng},
	lid = {10.1177/1087057110377497 {$[$}doi{$]$}},
	lr = {20191210},
	mh = {Animals; Cell-Free System/drug effects; Computer Simulation; Drug Evaluation, Preclinical/methods/standards/statistics \& numerical data; False Positive Reactions; Fluorescent Antibody Technique/methods/standards/statistics \& numerical data; High-Throughput Screening Assays/methods/*standards/*statistics \& numerical data; Luciferases, Firefly/analysis/metabolism; Luciferases, Renilla/analysis/metabolism; *Models, Statistical; Protein Biosynthesis/drug effects; Protein Synthesis Inhibitors/isolation \& purification/pharmacology; ROC Curve; Random Allocation; *Research Design},
	mhda = {2011/01/13 06:00},
	month = {Sep},
	number = {8},
	own = {NLM},
	pages = {990--1000},
	phst = {2010/09/07 06:00 {$[$}entrez{$]$}; 2010/09/08 06:00 {$[$}pubmed{$]$}; 2011/01/13 06:00 {$[$}medline{$]$}},
	pii = {15/8/990},
	pl = {United States},
	pmid = {20817887},
	pst = {ppublish},
	pt = {Journal Article; Research Support, Non-U.S. Gov't; Validation Study},
	rn = {0 (Protein Synthesis Inhibitors); EC 1.13.12.5 (Luciferases, Renilla); EC 1.13.12.7 (Luciferases, Firefly)},
	sb = {IM},
	status = {MEDLINE},
	title = {Experimental design and statistical methods for improved hit detection in high-throughput screening.},
	volume = {15},
	year = {2010},
	Bdsk-Url-1 = {https://doi.org/10.1177/1087057110377497}}

@article{Mazoure:2017wh,
	abstract = {Spatial bias continues to be a major challenge in high-throughput screening technologies. Its successful detection and elimination are critical for identifying the most promising drug candidates. Here, we examine experimental small molecule assays from the popular ChemBank database and show that screening data are widely affected by both assay-specific and plate-specific spatial biases. Importantly, the bias affecting screening data can fit an additive or multiplicative model. We show that the use of appropriate statistical methods is essential for improving the quality of experimental screening data. The presented methodology can be recommended for the analysis of current and next-generation screening data.},
	address = {Department of Computer Science, McGill University, Montreal, Canada.; Department of Human Genetics, McGill University, Montreal, Canada.; McGill University and Genome Quebec Innovation Centre, Montreal, Canada.; Department of Computer Science, Universit{\'e}du Qu{\'e}bec {\`a}Montr{\'e}al, Montreal, Canada. makarenkov.vladimir@uqam.ca.},
	auid = {ORCID: 0000-0003-3753-5925},
	author = {Mazoure, Bogdan and Nadon, Robert and Makarenkov, Vladimir},
	cois = {The authors declare that they have no competing interests.},
	crdt = {2017/09/22 06:00},
	date = {2017 Sep 20},
	date-added = {2023-06-12 10:03:21 -0700},
	date-modified = {2023-06-12 10:03:21 -0700},
	dep = {20170920},
	doi = {10.1038/s41598-017-11940-4},
	edat = {2017/09/22 06:00},
	issn = {2045-2322 (Electronic); 2045-2322 (Linking)},
	jid = {101563288},
	journal = {Sci Rep},
	jt = {Scientific reports},
	language = {eng},
	lid = {10.1038/s41598-017-11940-4 {$[$}doi{$]$}; 11921},
	lr = {20191120},
	mhda = {2017/09/22 06:01},
	month = {Sep},
	number = {1},
	own = {NLM},
	pages = {11921},
	phst = {2017/01/16 00:00 {$[$}received{$]$}; 2017/09/01 00:00 {$[$}accepted{$]$}; 2017/09/22 06:00 {$[$}entrez{$]$}; 2017/09/22 06:00 {$[$}pubmed{$]$}; 2017/09/22 06:01 {$[$}medline{$]$}},
	pii = {10.1038/s41598-017-11940-4; 11940},
	pl = {England},
	pmc = {PMC5607347},
	pmid = {28931934},
	pst = {epublish},
	pt = {Journal Article; Research Support, Non-U.S. Gov't},
	status = {PubMed-not-MEDLINE},
	title = {Identification and correction of spatial bias are essential for obtaining quality data in high-throughput screening technologies.},
	volume = {7},
	year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1038/s41598-017-11940-4}}

@article{Shterev:2018ws,
	abstract = {High-throughput screening of compounds (chemicals) is an essential part of drug discovery, involving thousands to millions of compounds, with the purpose of identifying candidate hits. Most statistical tools, including the industry standard B-score method, work on individual compound plates and do not exploit cross-plate correlation or statistical strength among plates. We present a new statistical framework for high-throughput screening of compounds based on Bayesian nonparametric modeling. The proposed approach is able to identify candidate hits from multiple plates simultaneously, sharing statistical strength among plates and providing more robust estimates of compound activity. It can flexibly accommodate arbitrary distributions of compound activities and is applicable to any plate geometry. The algorithm provides a principled statistical approach for hit identification and false discovery rate control. Experiments demonstrate significant improvements in hit identification sensitivity and specificity over the B-score and R-score methods, which are highly sensitive to threshold choice. These improvements are maintained at low hit rates. The framework is implemented as an efficient R extension package BHTSpack and is suitable for large scale data sets.},
	address = {Duke Human Vaccine Institute, Duke University, Durham, NC, 27710, USA. i.shterev@duke.edu.; Department of Statistical Science, Duke University, Durham, NC, 27708, USA.; Department of Biostatistics and Bioinformatics, Duke University, Durham, NC, 27705, USA.; Duke Human Vaccine Institute, Duke University, Durham, NC, 27710, USA.},
	author = {Shterev, Ivo D and Dunson, David B and Chan, Cliburn and Sempowski, Gregory D},
	cois = {The authors declare no competing interests.},
	crdt = {2018/06/24 06:00},
	date = {2018 Jun 22},
	date-added = {2023-06-12 10:03:21 -0700},
	date-modified = {2023-06-12 10:03:21 -0700},
	dcom = {20191015},
	dep = {20180622},
	doi = {10.1038/s41598-018-27531-w},
	edat = {2018/06/24 06:00},
	gr = {HHSN272201400054C/AI/NIAID NIH HHS/United States; UC6 AI058607/AI/NIAID NIH HHS/United States},
	issn = {2045-2322 (Electronic); 2045-2322 (Linking)},
	jid = {101563288},
	journal = {Sci Rep},
	jt = {Scientific reports},
	language = {eng},
	lid = {10.1038/s41598-018-27531-w {$[$}doi{$]$}; 9551},
	lr = {20210109},
	mh = {Bayes Theorem; Cell Division/drug effects; DNA Damage; Drug Evaluation, Preclinical/*methods; Escherichia coli/cytology/drug effects/genetics; High-Throughput Screening Assays/*methods},
	mhda = {2019/10/16 06:00},
	month = {Jun},
	number = {1},
	own = {NLM},
	pages = {9551},
	phst = {2018/01/11 00:00 {$[$}received{$]$}; 2018/06/05 00:00 {$[$}accepted{$]$}; 2018/06/24 06:00 {$[$}entrez{$]$}; 2018/06/24 06:00 {$[$}pubmed{$]$}; 2019/10/16 06:00 {$[$}medline{$]$}},
	pii = {10.1038/s41598-018-27531-w; 27531},
	pl = {England},
	pmc = {PMC6015058},
	pmid = {29934615},
	pst = {epublish},
	pt = {Journal Article; Research Support, N.I.H., Extramural},
	sb = {IM},
	status = {MEDLINE},
	title = {Bayesian Multi-Plate High-Throughput Screening of Compounds.},
	volume = {8},
	year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1038/s41598-018-27531-w}}

@article{Zhang:2013uv,
	abstract = {The R package displayHTS implements recently developed methods and figures for displaying data and hit selection results in high-throughput screening (HTS) experiments. It generates not only certain useful distinctive graphics such as the plate-well series plot, plate image and dual-flashlight plot but also other commonly used figures such as volcano plot and plate correlation plot. These figures are critical for visualizing the data and displaying important features of HTS data and hit selection results.},
	address = {Early Development Statistics, BARDS, Merck Research Laboratories, West Point, PA 19486, USA. xiaohua_zhang@merck.com},
	author = {Zhang, Xiaohua Douglas and Zhang, Zhaozhi},
	crdt = {2013/02/12 06:00},
	date = {2013 Mar 15},
	date-added = {2023-06-12 10:03:21 -0700},
	date-modified = {2023-06-12 10:03:21 -0700},
	dcom = {20130923},
	dep = {20130208},
	doi = {10.1093/bioinformatics/btt060},
	edat = {2013/02/12 06:00},
	issn = {1367-4811 (Electronic); 1367-4803 (Linking)},
	jid = {9808944},
	journal = {Bioinformatics},
	jt = {Bioinformatics (Oxford, England)},
	language = {eng},
	lid = {10.1093/bioinformatics/btt060 {$[$}doi{$]$}},
	lr = {20130315},
	mh = {High-Throughput Screening Assays/*methods; *Software},
	mhda = {2013/09/24 06:00},
	month = {Mar},
	number = {6},
	own = {NLM},
	pages = {794--796},
	phst = {2013/02/12 06:00 {$[$}entrez{$]$}; 2013/02/12 06:00 {$[$}pubmed{$]$}; 2013/09/24 06:00 {$[$}medline{$]$}},
	pii = {btt060},
	pl = {England},
	pmid = {23396118},
	pst = {ppublish},
	pt = {Journal Article},
	sb = {IM},
	status = {MEDLINE},
	title = {displayHTS: a R package for displaying data and results from high-throughput screening experiments.},
	volume = {29},
	year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1093/bioinformatics/btt060}}

@article{Dragiev2012TwoEM,
	author = {Plamen Dragiev and Robert Nadon and Vladimir Makarenkov},
	date-added = {2023-06-12 10:02:51 -0700},
	date-modified = {2023-06-12 10:02:51 -0700},
	journal = {Bioinformatics},
	pages = {1775-82},
	title = {Two effective methods for correcting experimental high-throughput screening data},
	volume = {28 13},
	year = {2012}}

@article{Makarenkov2007AnEM,
	author = {Vladimir Makarenkov and Pablo Zentilli and Dmytro Kevorkov and Andrei V. Gagarin and Nathalie Malo and Robert Nadon},
	date-added = {2023-06-12 10:02:51 -0700},
	date-modified = {2023-06-12 10:02:51 -0700},
	journal = {Bioinformatics},
	pages = {1648-57},
	title = {An efficient method for the detection and elimination of systematic error in high-throughput screening},
	volume = {23 13},
	year = {2007}}
