%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Fcollin at 2021-01-09 16:48:24 -0800 


%% Saved with string encoding Unicode (UTF-8) 



@article{Lee:2008aa,
	Abstract = {A complete description of the transcriptome of an organism is crucial for a comprehensive understanding of how it functions and how its transcriptional networks are controlled, and may provide insights into the organism's evolution. Despite the status of Saccharomyces cerevisiae as arguably the most well-studied model eukaryote, we still do not have a full catalog or understanding of all its genes. In order to interrogate the transcriptome of S. cerevisiae for low abundance or rapidly turned over transcripts, we deleted elements of the RNA degradation machinery with the goal of preferentially increasing the relative abundance of such transcripts. We then used high-resolution tiling microarrays and ultra high-throughput sequencing (UHTS) to identify, map, and validate unannotated transcripts that are more abundant in the RNA degradation mutants relative to wild-type cells. We identified 365 currently unannotated transcripts, the majority presumably representing low abundance or short-lived RNAs, of which 185 are previously unknown and unique to this study. It is likely that many of these are cryptic unstable transcripts (CUTs), which are rapidly degraded and whose function(s) within the cell are still unclear, while others may be novel functional transcripts. Of the 185 transcripts we identified as novel to our study, greater than 80 percent come from regions of the genome that have lower conservation scores amongst closely related yeast species than 85 percent of the verified ORFs in S. cerevisiae. Such regions of the genome have typically been less well-studied, and by definition transcripts from these regions will distinguish S. cerevisiae from these closely related species.},
	Address = {Department of Genetics, Stanford University, Stanford, CA, USA.},
	Author = {Lee, Albert and Hansen, Kasper Daniel and Bullard, James and Dudoit, Sandrine and Sherlock, Gavin},
	Cois = {The authors have declared that no competing interests exist.},
	Crdt = {2008/12/20 09:00},
	Date = {2008 Dec},
	Date-Added = {2021-01-09 16:48:15 -0800},
	Date-Modified = {2021-01-09 16:48:15 -0800},
	Dcom = {20090403},
	Dep = {20081219},
	Doi = {10.1371/journal.pgen.1000299},
	Edat = {2008/12/20 09:00},
	Gr = {R01 HG003468/HG/NHGRI NIH HHS/United States; T32 HG000044/HG/NHGRI NIH HHS/United States; U01 HG004271/HG/NHGRI NIH HHS/United States; R01 HG03468/HG/NHGRI NIH HHS/United States},
	Issn = {1553-7404 (Electronic); 1553-7390 (Print); 1553-7390 (Linking)},
	Jid = {101239074},
	Journal = {PLoS Genet},
	Jt = {PLoS genetics},
	Language = {eng},
	Lid = {10.1371/journal.pgen.1000299 {$[$}doi{$]$}; e1000299},
	Lr = {20181113},
	Mh = {Evolution, Molecular; *Gene Expression Profiling; Oligonucleotide Array Sequence Analysis; RNA, Fungal/*genetics; Saccharomyces cerevisiae/*genetics; Sequence Analysis, RNA; Transcription, Genetic; Yeasts/genetics},
	Mhda = {2009/04/04 09:00},
	Month = {Dec},
	Number = {12},
	Own = {NLM},
	Pages = {e1000299},
	Phst = {2008/06/17 00:00 {$[$}received{$]$}; 2008/11/06 00:00 {$[$}accepted{$]$}; 2008/12/20 09:00 {$[$}entrez{$]$}; 2008/12/20 09:00 {$[$}pubmed{$]$}; 2009/04/04 09:00 {$[$}medline{$]$}},
	Pii = {08-PLGE-RA-0705R2},
	Pmc = {PMC2601015},
	Pmid = {19096707},
	Pst = {ppublish},
	Pt = {Journal Article; Research Support, N.I.H., Extramural; Research Support, Non-U.S. Gov't},
	Rn = {0 (RNA, Fungal)},
	Sb = {IM},
	Si = {GEO/GSE11802},
	Status = {MEDLINE},
	Title = {Novel low abundance and transient RNAs in yeast revealed by tiling microarrays and ultra high-throughput sequencing are not conserved across closely related yeast species.},
	Volume = {4},
	Year = {2008},
	Bdsk-Url-1 = {https://doi.org/10.1371/journal.pgen.1000299}}

@article{Marioni:2008aa,
	Abstract = {Ultra-high-throughput sequencing is emerging as an attractive alternative to microarrays for genotyping, analysis of methylation patterns, and identification of transcription factor binding sites. Here, we describe an application of the Illumina sequencing (formerly Solexa sequencing) platform to study mRNA expression levels. Our goals were to estimate technical variance associated with Illumina sequencing in this context and to compare its ability to identify differentially expressed genes with existing array technologies. To do so, we estimated gene expression differences between liver and kidney RNA samples using multiple sequencing replicates, and compared the sequencing data to results obtained from Affymetrix arrays using the same RNA samples. We find that the Illumina sequencing data are highly replicable, with relatively little technical variation, and thus, for many purposes, it may suffice to sequence each mRNA sample only once (i.e., using one lane). The information in a single lane of Illumina sequencing data appears comparable to that in a single array in enabling identification of differentially expressed genes, while allowing for additional analyses such as detection of low-expressed genes, alternative splice variants, and novel transcripts. Based on our observations, we propose an empirical protocol and a statistical framework for the analysis of gene expression using ultra-high-throughput sequencing technology.},
	An = {18550803},
	Author = {Marioni, John C and Mason, Christopher E and Mane, Shrikant M and Stephens, Matthew and Gilad, Yoav},
	Date = {2008/09/},
	Date-Added = {2021-01-09 16:43:24 -0800},
	Date-Modified = {2021-01-09 16:43:24 -0800},
	Db = {PubMed},
	Doi = {10.1101/gr.079558.108},
	Et = {2008/06/11},
	Isbn = {1088-9051; 1549-5477},
	J2 = {Genome Res},
	Journal = {Genome research},
	Keywords = {Gene Expression Profiling/methods; Humans; Likelihood Functions; Male; Models, Biological; Oligonucleotide Array Sequence Analysis/methods; RNA, Messenger/chemistry/*metabolism; Reproducibility of Results; Sequence Analysis, RNA/*methods},
	L2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2527709/},
	La = {eng},
	Month = {09},
	Number = {9},
	Pages = {1509--1517},
	Publisher = {Cold Spring Harbor Laboratory Press},
	Title = {RNA-seq: an assessment of technical reproducibility and comparison with gene expression arrays},
	Ty = {JOUR},
	U1 = {18550803{$[$}pmid{$]$}},
	U2 = {PMC2527709{$[$}pmcid{$]$}},
	U4 = {gr.079558.108{$[$}PII{$]$}},
	Url = {https://pubmed.ncbi.nlm.nih.gov/18550803},
	Volume = {18},
	Year = {2008},
	Bdsk-Url-1 = {https://pubmed.ncbi.nlm.nih.gov/18550803},
	Bdsk-Url-2 = {https://doi.org/10.1101/gr.079558.108}}

@article{McCarthy:2012aa,
	Abstract = {A flexible statistical framework is developed for the analysis of read counts from RNA-Seq gene expression studies. It provides the ability to analyse complex experiments involving multiple treatment conditions and blocking variables while still taking full account of biological variation. Biological variation between RNA samples is estimated separately from the technical variation associated with sequencing technologies. Novel empirical Bayes methods allow each gene to have its own specific variability, even when there are relatively few biological replicates from which to estimate such variability. The pipeline is implemented in the edgeR package of the Bioconductor project. A case study analysis of carcinoma data demonstrates the ability of generalized linear model methods (GLMs) to detect differential expression in a paired design, and even to detect tumour-specific expression changes. The case study demonstrates the need to allow for gene-specific variability, rather than assuming a common dispersion across genes or a fixed relationship between abundance and variability. Genewise dispersions de-prioritize genes with inconsistent results and allow the main analysis to focus on changes that are consistent between biological replicates. Parallel computational approaches are developed to make non-linear model fitting faster and more reliable, making the application of GLMs to genomic data more convenient and practical. Simulations demonstrate the ability of adjusted profile likelihood estimators to return accurate estimators of biological variability in complex situations. When variation is gene-specific, empirical Bayes estimators provide an advantageous compromise between the extremes of assuming common dispersion or separate genewise dispersion. The methods developed here can also be applied to count data arising from DNA-Seq applications, including ChIP-Seq for epigenetic marks and DNA methylation analyses.},
	An = {PMC3378882},
	Author = {McCarthy, Davis J and Chen, Yunshun and Smyth, Gordon K},
	Date = {2012/05/},
	Date-Added = {2021-01-09 16:42:57 -0800},
	Date-Modified = {2021-01-09 16:42:57 -0800},
	Db = {PMC},
	Doi = {10.1093/nar/gks042},
	Isbn = {0305-1048; 1362-4962},
	J1 = {Nucleic Acids Res},
	Journal = {Nucleic Acids Research},
	Month = {05},
	Number = {10},
	Pages = {4288--4297},
	Publisher = {Oxford University Press},
	Title = {Differential expression analysis of multifactor RNA-Seq experiments with respect to biological variation},
	Ty = {JOUR},
	U1 = {gks042{$[$}PII{$]$}; 22287627{$[$}pmid{$]$}},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3378882/},
	Volume = {40},
	Year = {2012},
	Year1 = {2012/01/28},
	Year2 = {2011/08/12/received},
	Year3 = {2012/01/05/revised},
	Year4 = {2012/01/10/accepted},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3378882/},
	Bdsk-Url-2 = {http://dx.doi.org/10.1093/nar/gks042}}

@article{Hofling:2008aa,
	Abstract = {{$[$}Given a predictor of outcome derived from a high-dimensional dataset, pre-validation is a useful technique for comparing it to competing predictors on the same dataset. For microarray data, it allows one to compare a newly derived predictor for disease outcome to standard clinical predictors on the same dataset. We study pre-validation analytically to determine if the inferences drawn from it are valid. We show that while pre-validation generally works well, the straightforward "one degree of freedom" analytical test from pre-validation can be biased and we propose a permutation test to remedy this problem. In simulation studies, we show that the permutation test has the nominal level and achieves roughly the same power as the analytical test.{$]$}},
	Author = {H{\"o}fling, Holger and Tibshirani, Robert},
	Booktitle = {The Annals of Applied Statistics},
	C1 = {Full publication date: Jun., 2008},
	Date-Added = {2020-09-05 14:17:25 -0700},
	Date-Modified = {2020-09-05 14:17:25 -0700},
	Db = {JSTOR},
	Isbn = {19326157},
	Month = {2020/09/05/},
	Number = {2},
	Pages = {643--664},
	Publisher = {Institute of Mathematical Statistics},
	Title = {A Study of Pre-Validation},
	Ty = {JOUR},
	Url = {http://www.jstor.org/stable/30244221},
	Volume = {2},
	Year = {2008},
	Bdsk-Url-1 = {http://www.jstor.org/stable/30244221}}

@article{Zou:2005aa,
	Annote = {doi: 10.1111/j.1467-9868.2005.00503.x},
	Author = {Zou, Hui and Hastie, Trevor},
	Booktitle = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	Da = {2005/04/01},
	Date = {2005/04/01},
	Date-Added = {2020-09-04 13:20:47 -0700},
	Date-Modified = {2020-09-04 13:20:47 -0700},
	Doi = {10.1111/j.1467-9868.2005.00503.x},
	Isbn = {1369-7412},
	Journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	Journal1 = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	Keywords = {Grouping effect; LARS algorithm; Lasso; Penalization; p≫n problem; Variable selection},
	M3 = {doi: 10.1111/j.1467-9868.2005.00503.x},
	Month = {2020/09/04},
	N2 = {Summary.? We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together. The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the p?n case. An algorithm called LARS-EN is proposed for computing elastic net regularization paths efficiently, much like algorithm LARS does for the lasso.},
	Number = {2},
	Pages = {301--320},
	Title = {Regularization and variable selection via the elastic net},
	Ty = {JOUR},
	Url = {https://doi.org/10.1111/j.1467-9868.2005.00503.x},
	Volume = {67},
	Year = {2005},
	Year1 = {2005},
	Bdsk-Url-1 = {https://doi.org/10.1111/j.1467-9868.2005.00503.x}}

@article{Wasserman:2014aa,
	Author = {Wasserman, Larry},
	Da = {2014/04},
	Date-Added = {2020-09-04 13:14:00 -0700},
	Date-Modified = {2020-09-04 13:14:00 -0700},
	Doi = {10.1214/13-AOS1175E},
	Isbn = {0090-5364},
	Journal = {Ann. Statist.},
	La = {en},
	Number = {2},
	Pages = {501--508},
	Publisher = {The Institute of Mathematical Statistics},
	Title = {Discussion: "A significance test for the lasso"},
	Ty = {JOUR},
	Url = {https://projecteuclid.org:443/euclid.aos/1400592166},
	Volume = {42},
	Year = {2014},
	Bdsk-Url-1 = {https://projecteuclid.org:443/euclid.aos/1400592166},
	Bdsk-Url-2 = {https://doi.org/10.1214/13-AOS1175E}}

@article{Lockhart:2014aa,
	Abstract = {In the sparse linear regression setting, we consider testing the significance of the predictor variable that enters the current lasso model, in the sequence of models visited along the lasso solution path. We propose a simple test statistic based on lasso fitted values, called the covariance test statistic, and show that when the true model is linear, this statistic has an Exp(1) asymptotic distribution under the null hypothesis (the null being that all truly active variables are contained in the current lasso model). Our proof of this result for the special case of the first predictor to enter the model (i.e., testing for a single significant predictor variable against the global null) requires only weak assumptions on the predictor matrix X. On the other hand, our proof for a general step in the lasso path places further technical assumptions on X and the generative model, but still allows for the important high-dimensional case p > n, and does not necessarily require that the current lasso model achieves perfect recovery of the truly active variables. Of course, for testing the significance of an additional variable between two nested linear models, one typically uses the chi-squared test, comparing the drop in residual sum of squares (RSS) to a [Formula: see text] distribution. But when this additional variable is not fixed, and has been chosen adaptively or greedily, this test is no longer appropriate: adaptivity makes the drop in RSS stochastically much larger than [Formula: see text] under the null hypothesis. Our analysis explicitly accounts for adaptivity, as it must, since the lasso builds an adaptive sequence of linear models as the tuning parameter λ decreases. In this analysis, shrinkage plays a key role: though additional variables are chosen adaptively, the coefficients of lasso active variables are shrunken due to the [Formula: see text] penalty. Therefore, the test statistic (which is based on lasso fitted values) is in a sense balanced by these two opposing properties-adaptivity and shrinkage-and its null distribution is tractable and asymptotically Exp(1).},
	Address = {Department of Statistics and Actuarial Science, Simon Fraser University, Burnaby, British Columbia V5A 1S6, Canada.; Department of Statistics, Stanford University, Stanford, California 94305, USA.; Departments of Statistics and Machine Learning, Carnegie Mellon University, 229B Baker Hall, Pittsburgh, Pennsylvania 15213, USA.; Department of Health, Research \& Policy, Department of Statistics, Stanford University, Stanford, California 94305, USA.},
	Author = {Lockhart, Richard and Taylor, Jonathan and Tibshirani, Ryan J and Tibshirani, Robert},
	Crdt = {2015/01/10 06:00},
	Date = {2014 Apr},
	Date-Added = {2020-09-04 13:13:46 -0700},
	Date-Modified = {2020-09-04 13:13:46 -0700},
	Doi = {10.1214/13-AOS1175},
	Edat = {2015/01/13 06:00},
	Gr = {R01 EB001988/EB/NIBIB NIH HHS/United States},
	Issn = {0090-5364 (Print); 0090-5364 (Linking)},
	Jid = {0365252},
	Journal = {Ann Stat},
	Jt = {Annals of statistics},
	Keywords = {Lasso; least angle regression; p-value; significance test},
	Language = {eng},
	Lr = {20191120},
	Mhda = {2015/01/13 06:00},
	Mid = {NIHMS637361},
	Month = {Apr},
	Number = {2},
	Oto = {NOTNLM},
	Own = {NLM},
	Pages = {413--468},
	Phst = {2015/01/10 06:00 {$[$}entrez{$]$}; 2015/01/13 06:00 {$[$}pubmed{$]$}; 2015/01/13 06:00 {$[$}medline{$]$}},
	Pmc = {PMC4285373},
	Pmid = {25574062},
	Pst = {ppublish},
	Pt = {Journal Article},
	Status = {Publisher},
	Title = {A SIGNIFICANCE TEST FOR THE LASSO.},
	Volume = {42},
	Year = {2014},
	Bdsk-Url-1 = {https://doi.org/10.1214/13-AOS1175}}

@article{Engebretsen:2019aa,
	Abstract = {Elastic net type regression methods have become very popular for prediction of certain outcomes in epigenome-wide association studies (EWAS). The methods considered accept biased coefficient estimates in return for lower variance thus obtaining improved prediction accuracy. We provide guidelines on how to obtain parsimonious models with low mean squared error and include easy to follow walk-through examples for each step in R.},
	An = {31443682},
	Author = {Engebretsen, Solveig and Bohlin, Jon},
	Date = {2019/08/23},
	Date-Added = {2020-09-04 10:14:22 -0700},
	Date-Modified = {2020-09-04 10:14:22 -0700},
	Db = {PubMed},
	Doi = {10.1186/s13148-019-0730-1},
	Isbn = {1868-7083; 1868-7075},
	J2 = {Clin Epigenetics},
	Journal = {Clinical epigenetics},
	Keywords = {*Elastic net; *Statistical prediction; *Ultra-high dimensional regression; *glmnet package; Algorithms; Computational Biology; DNA Methylation; Epigenomics/*methods; Genome-Wide Association Study; Humans; Models, Statistical},
	L2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6708235/},
	La = {eng},
	Month = {08},
	Number = {1},
	Pages = {123--123},
	Publisher = {BioMed Central},
	Title = {Statistical predictions with glmnet},
	Ty = {JOUR},
	U1 = {31443682{$[$}pmid{$]$}},
	U2 = {PMC6708235{$[$}pmcid{$]$}},
	U4 = {10.1186/s13148-019-0730-1{$[$}PII{$]$}},
	Url = {https://pubmed.ncbi.nlm.nih.gov/31443682},
	Volume = {11},
	Year = {2019},
	Bdsk-Url-1 = {https://pubmed.ncbi.nlm.nih.gov/31443682},
	Bdsk-Url-2 = {https://doi.org/10.1186/s13148-019-0730-1}}

@article{Rapaport:2013aa,
	Abstract = {A large number of computational methods have been developed for analyzing differential gene expression in RNA-seq data. We describe a comprehensive evaluation of common methods using the SEQC benchmark dataset and ENCODE data. We consider a number of key features, including normalization, accuracy of differential expression detection and differential expression analysis when one condition has no detectable expression. We find significant differences among the methods, but note that array-based methods adapted to RNA-seq data perform comparably to methods designed for RNA-seq. Our results demonstrate that increasing the number of replicate samples significantly improves detection power over increased sequencing depth.},
	An = {24020486},
	Author = {Rapaport, Franck and Khanin, Raya and Liang, Yupu and Pirun, Mono and Krek, Azra and Zumbo, Paul and Mason, Christopher E and Socci, Nicholas D and Betel, Doron},
	Date-Added = {2020-09-01 13:11:45 -0700},
	Date-Modified = {2020-09-01 13:11:45 -0700},
	Db = {PubMed},
	Doi = {10.1186/gb-2013-14-9-r95},
	Isbn = {1474-760X; 1465-6906},
	J2 = {Genome Biol},
	Journal = {Genome biology},
	Keywords = {Brain Chemistry; Cell Line; Datasets as Topic; Gene Expression; Gene Expression Profiling; High-Throughput Nucleotide Sequencing/*statistics \& numerical data; Humans; Nerve Tissue Proteins/*genetics; Oligonucleotide Array Sequence Analysis; RNA/*genetics; Sequence Analysis, RNA/methods/*statistics \& numerical data; Signal-To-Noise Ratio; *Software},
	L2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4054597/},
	La = {eng},
	Number = {9},
	Pages = {R95--R95},
	Publisher = {BioMed Central},
	Title = {Comprehensive evaluation of differential gene expression analysis methods for RNA-seq data},
	Ty = {JOUR},
	U1 = {24020486{$[$}pmid{$]$}},
	U2 = {PMC4054597{$[$}pmcid{$]$}},
	U4 = {gb-2013-14-9-r95{$[$}PII{$]$}},
	Url = {https://pubmed.ncbi.nlm.nih.gov/24020486},
	Volume = {14},
	Year = {2013},
	Bdsk-Url-1 = {https://pubmed.ncbi.nlm.nih.gov/24020486},
	Bdsk-Url-2 = {https://doi.org/10.1186/gb-2013-14-9-r95}}

@article{Simonsen:2018aa,
	Abstract = {The current literature on single cell genomic analyses on the DNA level is conflicting regarding requirements for cell quality, amplification success rates, allelic dropouts and resolution, lacking a systematic comparison of multiple cell input down to the single cell. We hypothesized that such a correlation assay would provide an approach to address the latter issues, utilizing the leukemic cell line OCI-AML3 with a known set of genetic aberrations.},
	Author = {Simonsen, Anita T. and Hansen, Marcus C. and Kjeldsen, Eigil and M{\o}ller, Peter L. and Hindkj{\ae}r, Johnny J. and Hokland, Peter and Aggerholm, Anni},
	Da = {2018/09/17},
	Date-Added = {2020-09-01 07:43:18 -0700},
	Date-Modified = {2020-09-01 07:43:18 -0700},
	Doi = {10.1186/s12864-018-5063-5},
	Id = {Simonsen2018},
	Isbn = {1471-2164},
	Journal = {BMC Genomics},
	Number = {1},
	Pages = {681},
	Title = {Systematic evaluation of signal-to-noise ratio in variant detection from single cell genome multiple displacement amplification and exome sequencing},
	Ty = {JOUR},
	Url = {https://doi.org/10.1186/s12864-018-5063-5},
	Volume = {19},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1186/s12864-018-5063-5}}

@article{Xiang:2020aa,
	Abstract = {Quantitative comparison of epigenomic data across multiple cell types or experimental conditions is a promising way to understand the biological functions of epigenetic modifications. However, differences in sequencing depth and signal-to-noise ratios in the data from different experiments can hinder our ability to identify real biological variation from raw epigenomic data. Proper normalization is required prior to data analysis to gain meaningful insights. Most existing methods for data normalization standardize signals by rescaling either background regions or peak regions, assuming that the same scale factor is applicable to both background and peak regions. While such methods adjust for differences in sequencing depths, they do not address differences in the signal-to-noise ratios across different experiments. We developed a new data normalization method, called S3norm, that normalizes the sequencing depths and signal-to-noise ratios across different data sets simultaneously by a monotonic nonlinear transformation. We show empirically that the epigenomic data normalized by our method, compared to existing methods, can better capture real biological variation, such as impact on gene expression regulation.},
	Author = {Xiang, Guanjue and Keller, Cheryl A and Giardine, Belinda and An, Lin and Li, Qunhua and Zhang, Yu and Hardison, Ross C},
	Date-Added = {2020-09-01 07:39:56 -0700},
	Date-Modified = {2020-09-01 07:39:56 -0700},
	Doi = {10.1093/nar/gkaa105},
	Isbn = {0305-1048},
	Journal = {Nucleic Acids Research},
	Journal1 = {Nucleic Acids Res},
	Month = {9/1/2020},
	Number = {8},
	Pages = {e43--e43},
	Title = {S3norm: simultaneous normalization of sequencing depth and signal-to-noise ratio in epigenomic data},
	Ty = {JOUR},
	Url = {https://doi.org/10.1093/nar/gkaa105},
	Volume = {48},
	Year = {2020},
	Year1 = {2020/05/07},
	Bdsk-Url-1 = {https://doi.org/10.1093/nar/gkaa105}}

@article{Lozoya:2018aa,
	Abstract = {To life scientists, one important feature offered by RNAseq, a next-generation sequencing tool used to estimate changes in gene expression levels, lies in its unprecedented resolution. It can score countable differences in transcript numbers among thousands of genes and between experimental groups, all at once. However, its high cost limits experimental designs to very small sample sizes, usually N = 3, which often results in statistically underpowered analysis and poor reproducibility. All these issues are compounded by the presence of experimental noise, which is harder to distinguish from instrumental error when sample sizes are limiting (e.g., small-budget pilot tests), experimental populations exhibit biologically heterogeneous or diffuse expression phenotypes (e.g., patient samples), or when discriminating among transcriptional signatures of closely related experimental conditions (e.g., toxicological modes of action, or MOAs). Here, we present a leveraged signal-to-noise ratio (LSTNR) thresholding method, founded on generalized linear modeling (GLM) of aligned read detection limits to extract differentially expressed genes (DEGs) from noisy low-replication RNAseq data. The LSTNR method uses an agnostic independent filtering strategy to define the dynamic range of detected aggregate read counts per gene, and assigns statistical weights that prioritize genes with better sequencing resolution in differential expression analyses. To assess its performance, we implemented the LSTNR method to analyze three separate datasets: first, using a systematically noisy in silico dataset, we demonstrated that LSTNR can extract pre-designed patterns of expression and discriminate between "noise" and "true" differentially expressed pseudogenes at a 100{\%} success rate; then, we illustrated how the LSTNR method can assign patient-derived breast cancer specimens correctly to one out of their four reported molecular subtypes (luminal A, luminal B, Her2-enriched and basal-like); and last, we showed the ability to retrieve five different modes of action (MOA) elicited in livers of rats exposed to three toxicants under three nutritional routes by using the LSTNR method. By combining differential measurements with resolving power to detect DEGs, the LSTNR method offers an alternative approach to interrogate noisy and low-replication RNAseq datasets, which handles multiple biological conditions at once, and defines benchmarks to validate RNAseq experiments with standard benchtop assays.},
	An = {29868123},
	Author = {Lozoya, Oswaldo A and Santos, Janine H and Woychik, Richard P},
	Date = {2018/05/16},
	Date-Added = {2020-09-01 07:34:59 -0700},
	Date-Modified = {2020-09-01 07:34:59 -0700},
	Db = {PubMed},
	Doi = {10.3389/fgene.2018.00176},
	Isbn = {1664-8021; 1664-8021},
	J2 = {Front Genet},
	Journal = {Frontiers in genetics},
	Keywords = {DEG; LSTNR; RNAseq; biomarker discovery; expression patterns; noise},
	L2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5964166/},
	La = {eng},
	Month = {05},
	Pages = {176--176},
	Publisher = {Frontiers Media S.A.},
	Title = {A Leveraged Signal-to-Noise Ratio (LSTNR) Method to Extract Differentially Expressed Genes and Multivariate Patterns of Expression From Noisy and Low-Replication RNAseq Data},
	Ty = {JOUR},
	U1 = {29868123{$[$}pmid{$]$}},
	U2 = {PMC5964166{$[$}pmcid{$]$}},
	Url = {https://pubmed.ncbi.nlm.nih.gov/29868123},
	Volume = {9},
	Year = {2018},
	Bdsk-Url-1 = {https://pubmed.ncbi.nlm.nih.gov/29868123},
	Bdsk-Url-2 = {https://doi.org/10.3389/fgene.2018.00176},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAmLi4vLi4vLi4vLi4vLi4vRG93bmxvYWRzLzE5MDk2NzA3Lm5iaWJPEQE8AAAAAAE8AAIAAAZNYWMgSEQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8NMTkwOTY3MDcubmJpYgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAAFAAIAAAogY3UAAAAAAAAAAAAAAAAACURvd25sb2FkcwAAAgAnLzpVc2VyczpmY29sbGluOkRvd25sb2FkczoxOTA5NjcwNy5uYmliAAAOABwADQAxADkAMAA5ADYANwAwADcALgBuAGIAaQBiAA8ADgAGAE0AYQBjACAASABEABIAJVVzZXJzL2Zjb2xsaW4vRG93bmxvYWRzLzE5MDk2NzA3Lm5iaWIAABMAAS8AABUAAgAO//8AAAAIAA0AGgAkAE0AAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAABjQ==}}

@article{Bertsimas:2016aa,
	Abstract = {In the period 1991-2015, algorithmic advances in Mixed Integer Optimization (MIO) coupled with hardware improvements have resulted in an astonishing 450 billion factor speedup in solving MIO problems. We present a MIO approach for solving the classical best subset selection problem of choosing $k$ out of $p$ features in linear regression given $n$ observations. We develop a discrete extension of modern first-order continuous optimization methods to find high quality feasible solutions that we use as warm starts to a MIO solver that finds provably optimal solutions. The resulting algorithm (a) provides a solution with a guarantee on its suboptimality even if we terminate the algorithm early, (b) can accommodate side constraints on the coefficients of the linear regression and (c) extends to finding best subset solutions for the least absolute deviation loss function. Using a wide variety of synthetic and real datasets, we demonstrate that our approach solves problems with $n$ in the 1000s and $p$ in the 100s in minutes to provable optimality, and finds near optimal solutions for $n$ in the 100s and $p$ in the 1000s in minutes. We also establish via numerical experiments that the MIO approach performs better than Lasso and other popularly used sparse learning procedures, in terms of achieving sparse solutions with good predictive power.},
	Author = {Bertsimas, Dimitris and King, Angela and Mazumder, Rahul},
	Da = {2016/04},
	Date-Added = {2020-08-31 16:04:13 -0700},
	Date-Modified = {2020-08-31 16:04:13 -0700},
	Doi = {10.1214/15-AOS1388},
	Isbn = {0090-5364},
	Journal = {Ann. Statist.},
	Keywords = {Sparse linear regression; best subset selection; {\$}{$\backslash$}ell{\_}{\{}0{\}}{\$}-constrained minimization; lasso; least absolute deviation; algorithms; mixed integer programming; global optimization; discrete optimization},
	La = {en},
	Number = {2},
	Pages = {813--852},
	Publisher = {The Institute of Mathematical Statistics},
	Title = {Best subset selection via a modern optimization lens},
	Ty = {JOUR},
	Url = {https://projecteuclid.org:443/euclid.aos/1458245736},
	Volume = {44},
	Year = {2016},
	Bdsk-Url-1 = {https://projecteuclid.org:443/euclid.aos/1458245736},
	Bdsk-Url-2 = {https://doi.org/10.1214/15-AOS1388}}

@article{Hastie:2017aa,
	Author = {T. Hastie and R. Tibshirani},
	Date-Added = {2020-08-31 11:55:22 -0700},
	Date-Modified = {2020-08-31 11:55:42 -0700},
	Journal = {arXiv: Methodology},
	Title = {Extended Comparisons of Best Subset Selection, Forward Stepwise Selection, and the Lasso},
	Year = {2017}}

@article{Simon:2013aa,
	Author = {Simon, Noah and Friedman, Jerome and Hastie, Trevor},
	Date = {2013},
	Date-Added = {2020-08-30 18:24:58 -0700},
	Date-Modified = {2020-08-30 18:24:58 -0700},
	Journal = {arXiv preprint arXiv:1311.6529},
	Title = {A blockwise descent algorithm for group-penalized multiresponse and multinomial regression},
	Year = {2013}}

@article{Tibshirani:2012aa,
	Abstract = {We consider rules for discarding predictors in lasso regression and related problems, for computational efficiency. El Ghaoui and his colleagues have propose 'SAFE' rules, based on univariate inner products between each predictor and the outcome, which guarantee that a coefficient will be 0 in the solution vector. This provides a reduction in the number of variables that need to be entered into the optimization. We propose strong rules that are very simple and yet screen out far more predictors than the SAFE rules. This great practical improvement comes at a price: the strong rules are not foolproof and can mistakenly discard active predictors, i.e. predictors that have non-zero coefficients in the solution. We therefore combine them with simple checks of the Karush-Kuhn-Tucker conditions to ensure that the exact solution to the convex problem is delivered. Of course, any (approximate) screening method can be combined with the Karush-Kuhn-Tucker, conditions to ensure the exact solution; the strength of the strong rules lies in the fact that, in practice, they discard a very large number of the inactive predictors and almost never commit mistakes. We also derive conditions under which they are foolproof. Strong rules provide substantial savings in computational time for a variety of statistical optimization problems.},
	An = {25506256},
	Author = {Tibshirani, Robert and Bien, Jacob and Friedman, Jerome and Hastie, Trevor and Simon, Noah and Taylor, Jonathan and Tibshirani, Ryan J},
	Date = {2012/03/},
	Date-Added = {2020-08-30 18:19:48 -0700},
	Date-Modified = {2020-08-30 18:19:48 -0700},
	Db = {PubMed},
	Doi = {10.1111/j.1467-9868.2011.01004.x},
	Isbn = {1369-7412},
	J2 = {J R Stat Soc Series B Stat Methodol},
	Journal = {Journal of the Royal Statistical Society. Series B, Statistical methodology},
	L2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4262615/},
	La = {eng},
	Month = {03},
	Number = {2},
	Pages = {245--266},
	Title = {Strong rules for discarding predictors in lasso-type problems},
	Ty = {JOUR},
	U1 = {25506256{$[$}pmid{$]$}},
	U2 = {PMC4262615{$[$}pmcid{$]$}},
	Url = {https://pubmed.ncbi.nlm.nih.gov/25506256},
	Volume = {74},
	Year = {2012},
	Bdsk-Url-1 = {https://pubmed.ncbi.nlm.nih.gov/25506256},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.1467-9868.2011.01004.x}}

@article{Simon:2011aa,
	Abstract = {We introduce a pathwise algorithm for the Cox proportional hazards model, regularized by convex combinations of ℓ(1) and ℓ(2) penalties (elastic net). Our algorithm fits via cyclical coordinate descent, and employs warm starts to find a solution along a regularization path. We demonstrate the efficacy of our algorithm on real and simulated data sets, and find considerable speedup between our algorithm and competing methods.},
	Address = {Department of Statistics, Stanford University, 390 Serra Mall, Stanford CA, 94305, United States of America.; Department of Statistics, Stanford University, 390 Serra Mall, Stanford CA, 94305, United States of America.; Department of Statistics, Stanford University, 390 Serra Mall, Stanford CA, 94305, United States of America.; Department of Statistics, Stanford University, 390 Serra Mall, Stanford CA, 94305, United States of America.},
	Author = {Simon, Noah and Friedman, Jerome and Hastie, Trevor and Tibshirani, Rob},
	Crdt = {2016/04/12 06:00},
	Date = {2011 Mar},
	Date-Added = {2020-08-30 18:15:05 -0700},
	Date-Modified = {2020-08-30 18:15:05 -0700},
	Doi = {10.18637/jss.v039.i05},
	Edat = {2011/03/01 00:00},
	Gr = {R01 EB001988/EB/NIBIB NIH HHS/United States},
	Issn = {1548-7660 (Print); 1548-7660 (Electronic); 1548-7660 (Linking)},
	Jid = {101307056},
	Journal = {J Stat Softw},
	Jt = {Journal of statistical software},
	Keywords = {Cox model; elastic net; lasso; survival},
	Language = {eng},
	Lr = {20191120},
	Mhda = {2011/03/01 00:00},
	Mid = {NIHMS723167},
	Month = {Mar},
	Number = {5},
	Oto = {NOTNLM},
	Own = {NLM},
	Pages = {1--13},
	Phst = {2016/04/12 06:00 {$[$}entrez{$]$}; 2011/03/01 00:00 {$[$}pubmed{$]$}; 2011/03/01 00:00 {$[$}medline{$]$}},
	Pmc = {PMC4824408},
	Pmid = {27065756},
	Pst = {ppublish},
	Pt = {Journal Article},
	Status = {Publisher},
	Title = {Regularization Paths for Cox's Proportional Hazards Model via Coordinate Descent.},
	Volume = {39},
	Year = {2011},
	Bdsk-Url-1 = {https://doi.org/10.18637/jss.v039.i05}}

@article{Friedman:2010aa,
	Abstract = {We develop fast algorithms for estimation of generalized linear models with convex penalties. The models include linear regression, two-class logistic regression, and multinomial regression problems while the penalties include ℓ(1) (the lasso), ℓ(2) (ridge regression) and mixtures of the two (the elastic net). The algorithms use cyclical coordinate descent, computed along a regularization path. The methods can handle large problems and can also deal efficiently with sparse features. In comparative timings we find that the new algorithms are considerably faster than competing methods.},
	Address = {Department of Statistics, Stanford University.},
	Author = {Friedman, Jerome and Hastie, Trevor and Tibshirani, Rob},
	Crdt = {2010/09/03 06:00},
	Date = {2010},
	Date-Added = {2020-08-30 18:12:43 -0700},
	Date-Modified = {2020-08-30 18:12:43 -0700},
	Edat = {2010/09/03 06:00},
	Gr = {N01HV28183/HL/NHLBI NIH HHS/United States; R01 EB001988/EB/NIBIB NIH HHS/United States; R01 EB001988-14/EB/NIBIB NIH HHS/United States},
	Issn = {1548-7660 (Print); 1548-7660 (Electronic); 1548-7660 (Linking)},
	Jid = {101307056},
	Journal = {J Stat Softw},
	Jt = {Journal of statistical software},
	Language = {eng},
	Lr = {20191120},
	Mhda = {2010/09/03 06:01},
	Mid = {NIHMS201118},
	Number = {1},
	Own = {NLM},
	Pages = {1--22},
	Phst = {2010/09/03 06:00 {$[$}entrez{$]$}; 2010/09/03 06:00 {$[$}pubmed{$]$}; 2010/09/03 06:01 {$[$}medline{$]$}},
	Pmc = {PMC2929880},
	Pmid = {20808728},
	Pst = {ppublish},
	Pt = {Journal Article},
	Status = {PubMed-not-MEDLINE},
	Title = {Regularization Paths for Generalized Linear Models via Coordinate Descent.},
	Volume = {33},
	Year = {2010}}

@article{McCarthy:2009aa,
	Abstract = {Motivation: Statistical methods are used to test for the differential expression of genes in microarray experiments. The most widely used methods successfully test whether the true differential expression is different from zero, but give no assurance that the differences found are large enough to be biologically meaningful. Results: We present a method, t-tests relative to a threshold (TREAT), that allows researchers to test formally the hypothesis (with associated p-values) that the differential expression in a microarray experiment is greater than a given (biologically meaningful) threshold. We have evaluated the method using simulated data, a dataset from a quality control experiment for microarrays and data from a biological experiment investigating histone deacetylase inhibitors. When the magnitude of differential expression is taken into account, TREAT improves upon the false discovery rate of existing methods and identifies more biologically relevant genes. Availability: R code implementing our methods is contributed to the software package limma available at http://www.bioconductor.org. Contact: smyth{\char64}wehi.edu.au},
	An = {PMC2654802},
	Author = {McCarthy, Davis J and Smyth, Gordon K},
	Date = {2009/03/15},
	Date-Added = {2020-08-30 13:58:02 -0700},
	Date-Modified = {2020-08-30 13:58:02 -0700},
	Db = {PMC},
	Doi = {10.1093/bioinformatics/btp053},
	Isbn = {1367-4803; 1460-2059},
	J1 = {Bioinformatics},
	Journal = {Bioinformatics},
	Month = {03},
	Number = {6},
	Pages = {765--771},
	Publisher = {Oxford University Press},
	Title = {Testing significance relative to a fold-change threshold is a TREAT},
	Ty = {JOUR},
	U1 = {btp053{$[$}PII{$]$}; 19176553{$[$}pmid{$]$}},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2654802/},
	Volume = {25},
	Year = {2009},
	Year1 = {2009/01/28},
	Year2 = {2008/10/12/received},
	Year3 = {2009/01/21/revised},
	Year4 = {2009/01/22/accepted},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2654802/},
	Bdsk-Url-2 = {https://dx.doi.org/10.1093/bioinformatics/btp053}}

@article{Gagnon-Bartsch:2012aa,
	Annote = {10.1093/biostatistics/kxr034},
	Author = {Gagnon-Bartsch, Johann A. and Speed, Terence P.},
	Date = {2012/07/01},
	Date-Added = {2020-08-29 19:13:10 -0700},
	Date-Modified = {2020-08-29 19:13:10 -0700},
	Isbn = {1465-4644},
	Journal = {Biostatistics},
	M3 = {doi: 10.1093/biostatistics/kxr034},
	Month = {07},
	N2 = {Microarray expression studies suffer from the problem of batch effects and other unwanted variation. Many methods have been proposed to adjust microarray data to mitigate the problems of unwanted variation. Several of these methods rely on factor analysis to infer the unwanted variation from the data. A central problem with this approach is the difficulty in discerning the unwanted variation from the biological variation that is of interest to the researcher. We present a new method, intended for use in differential expression studies, that attempts to overcome this problem by restricting the factor analysis to negative control genes. Negative control genes are genes known a priori not to be differentially expressed with respect to the biological factor of interest. Variation in the expression levels of these genes can therefore be assumed to be unwanted variation. We name this method ``Remove Unwanted Variation, 2-step''(RUV-2). We discuss various techniques for assessing the performance of an adjustment method and compare the performance of RUV-2 with that of other commonly used adjustment methods such as Combat and Surrogate Variable Analysis (SVA). We present several example studies, each concerning genes differentially expressed with respect to gender in the brain and find that RUV-2 performs as well or better than other methods. Finally, we discuss the possibility of adapting RUV-2 for use in studies not concerned with differential expression and conclude that there may be promise but substantial challenges remain.},
	Number = {3},
	Pages = {539--552},
	Title = {Using control genes to correct for unwanted variation in microarray data},
	Ty = {JOUR},
	Url = {http://dx.doi.org/10.1093/biostatistics/kxr034},
	Volume = {13},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1093/biostatistics/kxr034}}

@article{Gandolfo:2018aa,
	Abstract = {Unwanted variation can be highly problematic and so its detection is often crucial. Relative log expression (RLE) plots are a powerful tool for visualizing such variation in high dimensional data. We provide a detailed examination of these plots, with the aid of examples and simulation, explaining what they are and what they can reveal. RLE plots are particularly useful for assessing whether a procedure aimed at removing unwanted variation, i.e. a normalization procedure, has been successful. These plots, while originally devised for gene expression data from microarrays, can also be used to reveal unwanted variation in many other kinds of high dimensional data, where such variation can be problematic.},
	An = {29401521},
	Author = {Gandolfo, Luke C and Speed, Terence P},
	Date = {2018/02/05},
	Date-Added = {2020-08-29 19:13:10 -0700},
	Date-Modified = {2020-08-29 19:13:10 -0700},
	Db = {PubMed},
	Doi = {10.1371/journal.pone.0191629},
	Isbn = {1932-6203},
	J2 = {PLoS One},
	Journal = {PloS one},
	Keywords = {*Computer Simulation; Gene Expression},
	L2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5798764/},
	La = {eng},
	Month = {02},
	Number = {2},
	Pages = {e0191629--e0191629},
	Publisher = {Public Library of Science},
	Title = {RLE plots: Visualizing unwanted variation in high dimensional data},
	Ty = {JOUR},
	U1 = {29401521{$[$}pmid{$]$}},
	U2 = {PMC5798764{$[$}pmcid{$]$}},
	U4 = {PONE-D-17-37752{$[$}PII{$]$}},
	Url = {https://pubmed.ncbi.nlm.nih.gov/29401521},
	Volume = {13},
	Year = {2018},
	Bdsk-Url-1 = {https://pubmed.ncbi.nlm.nih.gov/29401521},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pone.0191629}}

@article{Lazar:2013aa,
	Annote = {10.1093/bib/bbs037},
	Author = {Lazar, Cosmin and Meganck, Stijn and Taminau, Jonatan and Steenhoff, David and Coletta, Alain and Molter, Colin and Weiss-Sol{\'\i}s, David Y. and Duque, Robin and Bersini, Hugues and Now{\'e}, Ann},
	Date = {2013/07/01},
	Date-Added = {2020-08-29 19:13:10 -0700},
	Date-Modified = {2020-08-29 19:13:10 -0700},
	Isbn = {1467-5463},
	Journal = {Briefings in Bioinformatics},
	M3 = {doi: 10.1093/bib/bbs037},
	Month = {07},
	N2 = {Genomic data integration is a key goal to be achieved towards large-scale genomic data analysis. This process is very challenging due to the diverse sources of information resulting from genomics experiments. In this work, we review methods designed to combine genomic data recorded from microarray gene expression (MAGE) experiments. It has been acknowledged that the main source of variation between different MAGE datasets is due to the so-called `batch effects'. The methods reviewed here perform data integration by removing (or more precisely attempting to remove) the unwanted variation associated with batch effects. They are presented in a unified framework together with a wide range of evaluation tools, which are mandatory in assessing the efficiency and the quality of the data integration process. We provide a systematic description of the MAGE data integration methodology together with some basic recommendation to help the users in choosing the appropriate tools to integrate MAGE data for large-scale analysis; and also how to evaluate them from different perspectives in order to quantify their efficiency. All genomic data used in this study for illustration purposes were retrieved from InSilicoDB http://insilico.ulb.ac.be.},
	Number = {4},
	Pages = {469--490},
	Title = {Batch effect removal methods for microarray gene expression data integration: a survey},
	Ty = {JOUR},
	Url = {http://dx.doi.org/10.1093/bib/bbs037},
	Volume = {14},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1093/bib/bbs037}}

@article{Leek:2012aa,
	Annote = {10.1093/bioinformatics/bts034},
	Author = {Leek, Jeffrey T. and Johnson, W. Evan and Parker, Hilary S. and Jaffe, Andrew E. and Storey, John D.},
	Date = {2012/03/15},
	Date-Added = {2020-08-29 19:13:10 -0700},
	Date-Modified = {2020-08-29 19:13:10 -0700},
	Isbn = {1367-4803},
	Journal = {Bioinformatics},
	M3 = {doi: 10.1093/bioinformatics/bts034},
	Month = {03},
	N2 = {Summary: Heterogeneity and latent variables are now widely recognized as major sources of bias and variability in high-throughput experiments. The most well-known source of latent variation in genomic experiments are batch effects---when samples are processed on different days, in different groups or by different people. However, there are also a large number of other variables that may have a major impact on high-throughput measurements. Here we describe the sva package for identifying, estimating and removing unwanted sources of variation in high-throughput experiments. The sva package supports surrogate variable estimation with the sva function, direct adjustment for known batch effects with the ComBat function and adjustment for batch and latent variables in prediction problems with the fsva function.Availability: The R package sva is freely available from http://www.bioconductor.org.Contact:jleek{\char64}jhsph.eduSupplementary information:Supplementary data are available at Bioinformatics online.},
	Number = {6},
	Pages = {882--883},
	Title = {The sva package for removing batch effects and other unwanted variation in high-throughput experiments},
	Ty = {JOUR},
	Url = {http://dx.doi.org/10.1093/bioinformatics/bts034},
	Volume = {28},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAdLi4vLlRyYXNoLzIzNzU5MDljaXRhdGlvbi5yaXNPEQF+AAAAAAF+AAIAAAdNYWMgT1NYAAAAAAAAAAAAAAAAAAAAAAAAAADUDjYKSCsAAAAvCmUTMjM3NTkwOWNpdGF0aW9uLnJpcwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGMautWKb5sAAAAAAAAAAAABAAIAAAkgAAAAAAAAAAAAAAAAAAAABi5UcmFzaAAQAAgAANQOmHoAAAARAAgAANWK0gsAAAABAAwALwplABCywwACEpkAAgA0TWFjIE9TWDpVc2VyczoAZnJhbmNvaXM6AC5UcmFzaDoAMjM3NTkwOWNpdGF0aW9uLnJpcwAOACgAEwAyADMANwA1ADkAMAA5AGMAaQB0AGEAdABpAG8AbgAuAHIAaQBzAA8AEAAHAE0AYQBjACAATwBTAFgAEgApVXNlcnMvZnJhbmNvaXMvLlRyYXNoLzIzNzU5MDljaXRhdGlvbi5yaXMAABMAAS8AABUAAgAP//8AAAAIAA0AGgAkAEQAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAABxg==},
	Bdsk-File-2 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAvLi4vUmVmcy9kZUNvbnZvbHV0aW9uL0RlY29uUk5BU2VxL0dvbmdfMjAxMy5yaXNPEQHCAAAAAAHCAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8NR29uZ18yMDEzLnJpcwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAABAAQAAAogY3UAAAAAAAAAAAAAAAAAC0RlY29uUk5BU2VxAAACAGQvOlVzZXJzOmZjb2xsaW46RG9jdW1lbnRzOkJsdWVTdGFyOmJzZy1hbmFseXNpczpmY29sbGluOlJlZnM6ZGVDb252b2x1dGlvbjpEZWNvblJOQVNlcTpHb25nXzIwMTMucmlzAA4AHAANAEcAbwBuAGcAXwAyADAAMQAzAC4AcgBpAHMADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBiVXNlcnMvZmNvbGxpbi9Eb2N1bWVudHMvQmx1ZVN0YXIvYnNnLWFuYWx5c2lzL2Zjb2xsaW4vUmVmcy9kZUNvbnZvbHV0aW9uL0RlY29uUk5BU2VxL0dvbmdfMjAxMy5yaXMAEwABLwAAFQACAA7//wAAAAgADQAaACQAVgAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAIc},
	Bdsk-Url-1 = {http://dx.doi.org/10.1093/bioinformatics/bts034}}

@article{Risso:2014aa,
	Abstract = {Remove unwanted variation (RUV) is a new statistical method for RNA-seq data normalization that uses control genes or samples to improve differential expression analysis.},
	Author = {Risso, Davide and Ngai, John and Speed, Terence P and Dudoit, Sandrine},
	Da = {2014/09/01},
	Date-Added = {2020-08-29 19:13:10 -0700},
	Date-Modified = {2020-08-29 19:13:10 -0700},
	Doi = {10.1038/nbt.2931},
	Id = {Risso2014},
	Isbn = {1546-1696},
	Journal = {Nature Biotechnology},
	Number = {9},
	Pages = {896--902},
	Title = {Normalization of RNA-seq data using factor analysis of control genes or samples},
	Ty = {JOUR},
	Url = {https://doi.org/10.1038/nbt.2931},
	Volume = {32},
	Year = {2014},
	Bdsk-Url-1 = {https://doi.org/10.1038/nbt.2931}}

@article{Peixoto:2015aa,
	Abstract = {The sequencing of the full transcriptome (RNA-seq) has become the preferred choice for the measurement of genome-wide gene expression. Despite its widespread use, challenges remain in RNA-seq data analysis. One often-overlooked aspect is normalization. Despite the fact that a variety of factors or 'batch effects' can contribute unwanted variation to the data, commonly used RNA-seq normalization methods only correct for sequencing depth. The study of gene expression is particularly problematic when it is influenced simultaneously by a variety of biological factors in addition to the one of interest. Using examples from experimental neuroscience, we show that batch effects can dominate the signal of interest; and that the choice of normalization method affects the power and reproducibility of the results. While commonly used global normalization methods are not able to adequately normalize the data, more recently developed RNA-seq normalization can. We focus on one particular method, RUVSeq and show that it is able to increase power and biological insight of the results. Finally, we provide a tutorial outlining the implementation of RUVSeq normalization that is applicable to a broad range of studies as well as meta-analysis of publicly available data.},
	An = {26202970},
	Author = {Peixoto, Lucia and Risso, Davide and Poplawski, Shane G and Wimmer, Mathieu E and Speed, Terence P and Wood, Marcelo A and Abel, Ted},
	Date = {2015/09/18},
	Date-Added = {2020-08-29 19:09:00 -0700},
	Date-Modified = {2020-08-29 19:09:00 -0700},
	Db = {PubMed},
	Doi = {10.1093/nar/gkv736},
	Et = {2015/07/21},
	Isbn = {1362-4962; 0305-1048},
	J2 = {Nucleic Acids Res},
	Journal = {Nucleic acids research},
	Keywords = {Animals; Gene Expression Profiling/*methods; Genetic Variation; Male; Mice, Inbred C57BL; Neurosciences/methods; Reproducibility of Results; Sequence Analysis, RNA/*methods},
	L2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4652761/},
	La = {eng},
	Month = {09},
	Number = {16},
	Pages = {7664--7674},
	Publisher = {Oxford University Press},
	Title = {How data analysis affects power, reproducibility and biological insight of RNA-seq studies in complex datasets},
	Ty = {JOUR},
	U1 = {26202970{$[$}pmid{$]$}},
	U2 = {PMC4652761{$[$}pmcid{$]$}},
	U4 = {gkv736{$[$}PII{$]$}},
	Url = {https://pubmed.ncbi.nlm.nih.gov/26202970},
	Volume = {43},
	Year = {2015},
	Bdsk-Url-1 = {https://pubmed.ncbi.nlm.nih.gov/26202970},
	Bdsk-Url-2 = {https://doi.org/10.1093/nar/gkv736}}

@article{Robinson:2010aa,
	Abstract = {A novel and empirical method for normalization of RNA-seq data is presented},
	An = {PMC2864565},
	Author = {Robinson, Mark D and Oshlack, Alicia},
	Date-Added = {2020-08-29 14:56:07 -0700},
	Date-Modified = {2020-08-29 14:56:07 -0700},
	Db = {PMC},
	Doi = {10.1186/gb-2010-11-3-r25},
	Isbn = {1465-6906; 1465-6914},
	J1 = {Genome Biol},
	Journal = {Genome Biology},
	Number = {3},
	Pages = {R25--R25},
	Publisher = {BioMed Central},
	Title = {A scaling normalization method for differential expression analysis of RNA-seq data},
	Ty = {JOUR},
	U1 = {gb-2010-11-3-r25{$[$}PII{$]$}; 20196867{$[$}pmid{$]$}},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2864565/},
	Volume = {11},
	Year = {2010},
	Year1 = {2010/03/02},
	Year2 = {2009/11/19/received},
	Year3 = {2010/01/28/revised},
	Year4 = {2010/03/02/accepted},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAoLi4vUmVmcy9OSVBUL05vcnRvbl8yMDE1L05vcnRvbl8yMDE1LnJpc08RAboAAAAAAboAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////w9Ob3J0b25fMjAxNS5yaXMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAEABAAACiBjdQAAAAAAAAAAAAAAAAALTm9ydG9uXzIwMTUAAAIAXS86VXNlcnM6ZmNvbGxpbjpEb2N1bWVudHM6Qmx1ZVN0YXI6YnNnLWFuYWx5c2lzOmZjb2xsaW46UmVmczpOSVBUOk5vcnRvbl8yMDE1Ok5vcnRvbl8yMDE1LnJpcwAADgAgAA8ATgBvAHIAdABvAG4AXwAyADAAMQA1AC4AcgBpAHMADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBbVXNlcnMvZmNvbGxpbi9Eb2N1bWVudHMvQmx1ZVN0YXIvYnNnLWFuYWx5c2lzL2Zjb2xsaW4vUmVmcy9OSVBUL05vcnRvbl8yMDE1L05vcnRvbl8yMDE1LnJpcwAAEwABLwAAFQACAA7//wAAAAgADQAaACQATwAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAIN},
	Bdsk-File-2 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAnLi4vLi4vLi4vLi4vLi4vRG93bmxvYWRzL1BNQzQ2NTI3NjEucmlzTxEBSgAAAAABSgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////DlBNQzQ2NTI3NjEucmlzAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAABQACAAAKIGN1AAAAAAAAAAAAAAAAAAlEb3dubG9hZHMAAAIAKC86VXNlcnM6ZmNvbGxpbjpEb3dubG9hZHM6UE1DNDY1Mjc2MS5yaXMADgAeAA4AUABNAEMANAA2ADUAMgA3ADYAMQAuAHIAaQBzAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAJlVzZXJzL2Zjb2xsaW4vRG93bmxvYWRzL1BNQzQ2NTI3NjEucmlzABMAAS8AABUAAgAO//8AAAAIAA0AGgAkAE4AAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAABnA==},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2864565/},
	Bdsk-Url-2 = {http://dx.doi.org/10.1186/gb-2010-11-3-r25}}

@misc{RNASeqPower,
	Author = {Terry Therneau and Steven Hart and Jean-Pierre Kocher},
	Date-Added = {2020-08-25 13:00:00 -0700},
	Date-Modified = {2020-08-25 13:02:21 -0700},
	Journal = {R package version 1.28.0},
	Title = {Calculating samplesSize estimates for RNA Seq studies},
	Year = {2020},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAaLi4vUmVmcy9STkFTZXFQb3dlci5iaWJ0ZXhPEQGQAAAAAAGQAAIAAAZNYWMgSEQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8SUk5BU2VxUG93ZXIuYmlidGV4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAABAAIAAAogY3UAAAAAAAAAAAAAAAAABFJlZnMAAgBQLzpVc2VyczpmY29sbGluOkRvY3VtZW50czpQcm9qZWN0czpSc3R1ZmY6SENDNWhtQ0V4cGxvcmU6UmVmczpSTkFTZXFQb3dlci5iaWJ0ZXgADgAmABIAUgBOAEEAUwBlAHEAUABvAHcAZQByAC4AYgBpAGIAdABlAHgADwAOAAYATQBhAGMAIABIAEQAEgBOVXNlcnMvZmNvbGxpbi9Eb2N1bWVudHMvUHJvamVjdHMvUnN0dWZmL0hDQzVobUNFeHBsb3JlL1JlZnMvUk5BU2VxUG93ZXIuYmlidGV4ABMAAS8AABUAAgAO//8AAAAIAA0AGgAkAEEAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAB1Q==}}

@article{Poplawski:2017aa,
	Abstract = {Sample size calculation is a crucial step in study design but is not yet fully established for RNA sequencing (RNA-seq) analyses. To evaluate feasibility and provide guidance, we evaluated RNA-seq sample size tools identified from a systematic search. The focus was on whether real pilot data would be needed for reliable results and on identifying tools that would perform well in scenarios with different levels of biological heterogeneity and fold changes (FCs) between conditions. We used simulations based on real data for tool evaluation. In all settings, the six evaluated tools provided widely different answers, which were strongly affected by FC. Although all tools failed for small FCs, some tools can at least be recommended when closely matching pilot data are available and relatively large FCs are anticipated.},
	Author = {Poplawski, Alicia and Binder, Harald},
	Booktitle = {Briefings in Bioinformatics},
	Date-Added = {2020-08-23 17:05:07 -0700},
	Date-Modified = {2020-08-23 17:05:07 -0700},
	Doi = {10.1093/bib/bbw144},
	Isbn = {1477-4054},
	Journal = {Briefings in Bioinformatics},
	Journal1 = {bib},
	Month = {7/24/2019},
	Number = {4},
	Pages = {713--720},
	Title = {Feasibility of sample size calculation for RNA-seq studies},
	Ty = {JOUR},
	Url = {https://doi.org/10.1093/bib/bbw144},
	Volume = {19},
	Year = {2017},
	Year1 = {2017/01/18/},
	Bdsk-Url-1 = {https://doi.org/10.1093/bib/bbw144}}

@article{Zhao:2018ab,
	Abstract = {BACKGROUND: One of the most important and often neglected components of a successful RNA sequencing (RNA-Seq) experiment is sample size estimation. A few negative binomial model-based methods have been developed to estimate sample size based on the parameters of a single gene. However, thousands of genes are quantified and tested for differential expression simultaneously in RNA-Seq experiments. Thus, additional issues should be carefully addressed, including the false discovery rate for multiple statistic tests, widely distributed read counts and dispersions for different genes. RESULTS: To solve these issues, we developed a sample size and power estimation method named RnaSeqSampleSize, based on the distributions of gene average read counts and dispersions estimated from real RNA-seq data. Datasets from previous, similar experiments such as the Cancer Genome Atlas (TCGA) can be used as a point of reference. Read counts and their dispersions were estimated from the reference's distribution; using that information, we estimated and summarized the power and sample size. RnaSeqSampleSize is implemented in R language and can be installed from Bioconductor website. A user friendly web graphic interface is provided at http://cqs.mc.vanderbilt.edu/shiny/RnaSeqSampleSize/ . CONCLUSIONS: RnaSeqSampleSize provides a convenient and powerful way for power and sample size estimation for an RNAseq experiment. It is also equipped with several unique features, including estimation for interested genes or pathway, power curve visualization, and parameter optimization.},
	An = {29843589},
	Author = {Zhao, Shilin and Li, Chung-I and Guo, Yan and Sheng, Quanhu and Shyr, Yu},
	Date = {2018/05/30},
	Date-Added = {2020-08-23 17:04:53 -0700},
	Date-Modified = {2020-08-23 17:04:53 -0700},
	Db = {PubMed},
	Doi = {10.1186/s12859-018-2191-5},
	Isbn = {1471-2105},
	J2 = {BMC Bioinformatics},
	Journal = {BMC bioinformatics},
	Keywords = {*Power analysis; *RNA-Seq; *Sample size; *Simulation; Gene Expression Profiling/*methods; High-Throughput Nucleotide Sequencing; Models, Statistical; Sample Size; Sequence Analysis, RNA/*methods; Software},
	L2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5975570/},
	La = {eng},
	Month = {05},
	Number = {1},
	Pages = {191--191},
	Publisher = {BioMed Central},
	Title = {RnaSeqSampleSize: real data based sample size estimation for RNA sequencing},
	Ty = {JOUR},
	U1 = {29843589{$[$}pmid{$]$}},
	U2 = {PMC5975570{$[$}pmcid{$]$}},
	U4 = {10.1186/s12859-018-2191-5{$[$}PII{$]$}},
	Url = {https://www.ncbi.nlm.nih.gov/pubmed/29843589},
	Volume = {19},
	Year = {2018},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pubmed/29843589},
	Bdsk-Url-2 = {https://doi.org/10.1186/s12859-018-2191-5}}

@article{Yu:2017aa,
	Abstract = {Sample size calculation and power estimation are essential components of experimental designs in biomedical research. It is very challenging to estimate power for RNA-Seq differential expression under complex experimental designs. Moreover, the dependency among genes should be taken into account in order to obtain accurate results.},
	Author = {Yu, Lianbo and Fernandez, Soledad and Brock, Guy},
	Da = {2017/05/03},
	Date-Added = {2020-08-23 17:04:41 -0700},
	Date-Modified = {2020-08-23 17:04:41 -0700},
	Doi = {10.1186/s12859-017-1648-2},
	Id = {Yu2017},
	Isbn = {1471-2105},
	Journal = {BMC Bioinformatics},
	Number = {1},
	Pages = {234},
	Title = {Power analysis for RNA-Seq differential expression studies},
	Ty = {JOUR},
	Url = {https://doi.org/10.1186/s12859-017-1648-2},
	Volume = {18},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1186/s12859-017-1648-2}}

@article{Guo:2014aa,
	Abstract = {Sample size and power determination is the first step in the experimental design of a successful study. Sample size and power calculation is required for applications for National Institutes of Health (NIH) funding. Sample size and power calculation is well established for traditional biological studies such as mouse model, genome wide association study (GWAS), and microarray studies. Recent developments in high-throughput sequencing technology have allowed RNAseq to replace microarray as the technology of choice for high-throughput gene expression profiling. However, the sample size and power analysis of RNAseq technology is an underdeveloped area. Here, we present RNAseqPS, an advanced online RNAseq power and sample size calculation tool based on the Poisson and negative binomial distributions. RNAseqPS was built using the Shiny package in R. It provides an interactive graphical user interface that allows the users to easily conduct sample size and power analysis for RNAseq experimental design. RNAseqPS can be accessed directly at http://cqs.mc.vanderbilt.edu/shiny/RNAseqPS/.},
	An = {25374457},
	Author = {Guo, Yan and Zhao, Shilin and Li, Chung-I and Sheng, Quanhu and Shyr, Yu},
	Date = {2014/10/13},
	Date-Added = {2020-08-23 17:04:13 -0700},
	Date-Modified = {2020-08-23 17:04:13 -0700},
	Db = {PubMed},
	Doi = {10.4137/CIN.S17688},
	Isbn = {1176-9351; 1176-9351},
	J2 = {Cancer Inform},
	Journal = {Cancer informatics},
	Keywords = {RNAseq; experiment design; power analysis; sample size calculation},
	L2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4213196/},
	La = {eng},
	Month = {10},
	Number = {Suppl 6},
	Pages = {1--5},
	Publisher = {Libertas Academica},
	Title = {RNAseqPS: A Web Tool for Estimating Sample Size and Power for RNAseq Experiment},
	Ty = {JOUR},
	U1 = {25374457{$[$}pmid{$]$}},
	U2 = {PMC4213196{$[$}pmcid{$]$}},
	U4 = {cin-suppl.6-2014-001{$[$}PII{$]$}},
	Url = {https://www.ncbi.nlm.nih.gov/pubmed/25374457},
	Volume = {13},
	Year = {2014},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pubmed/25374457},
	Bdsk-Url-2 = {https://doi.org/10.4137/CIN.S17688}}

@article{Baccarella:2018aa,
	Abstract = {BACKGROUND: RNA-Sequencing analysis methods are rapidly evolving, and the tool choice for each step of one common workflow, differential expression analysis, which includes read alignment, expression modeling, and differentially expressed gene identification, has a dramatic impact on performance characteristics. Although a number of workflows are emerging as high performers that are robust to diverse input types, the relative performance characteristics of these workflows when either read depth or sample number is limited-a common occurrence in real-world practice-remain unexplored. RESULTS: Here, we evaluate the impact of varying read depth and sample number on the performance of differential gene expression identification workflows, as measured by precision, or the fraction of genes correctly identified as differentially expressed, and by recall, or the fraction of differentially expressed genes identified. We focus our analysis on 30 high-performing workflows, systematically varying the read depth and number of biological replicates of patient monocyte samples provided as input. We find that, in general for most workflows, read depth has little effect on workflow performance when held above two million reads per sample, with reduced workflow performance below this threshold. The greatest impact of decreased sample number is seen below seven samples per group, when more heterogeneity in workflow performance is observed. The choice of differential expression identification tool, in particular, has a large impact on the response to limited inputs. CONCLUSIONS: Among the tested workflows, the recall/precision balance remains relatively stable at a range of read depths and sample numbers, although some workflows are more sensitive to input restriction. At ranges typically recommended for biological studies, performance is more greatly impacted by the number of biological replicates than by read depth. Caution should be used when selecting analysis workflows and interpreting results from low sample number experiments, as all workflows exhibit poorer performance at lower sample numbers near typically reported values, with variable impact on recall versus precision. These analyses highlight the performance characteristics of common differential gene expression workflows at varying read depths and sample numbers, and provide empirical guidance in experimental and analytical design.},
	An = {30428853},
	Author = {Baccarella, Alyssa and Williams, Claire R and Parrish, Jay Z and Kim, Charles C},
	Date = {2018/11/14},
	Date-Added = {2020-08-23 17:04:01 -0700},
	Date-Modified = {2020-08-23 17:04:01 -0700},
	Db = {PubMed},
	Doi = {10.1186/s12859-018-2445-2},
	Isbn = {1471-2105},
	J2 = {BMC Bioinformatics},
	Journal = {BMC bioinformatics},
	Keywords = {Gene expression analysis; Monocytes; RNA-sequencing; Read depth; Sample number; Gene Expression Profiling/*methods; High-Throughput Nucleotide Sequencing/*methods; Humans; RNA/*genetics; Sequence Analysis, RNA/*methods; *Workflow},
	L2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6234607/},
	La = {eng},
	Month = {11},
	Number = {1},
	Pages = {423--423},
	Publisher = {BioMed Central},
	Title = {Empirical assessment of the impact of sample number and read depth on RNA-Seq analysis workflow performance},
	Ty = {JOUR},
	U1 = {30428853{$[$}pmid{$]$}},
	U2 = {PMC6234607{$[$}pmcid{$]$}},
	U4 = {10.1186/s12859-018-2445-2{$[$}PII{$]$}},
	Url = {https://www.ncbi.nlm.nih.gov/pubmed/30428853},
	Volume = {19},
	Year = {2018},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pubmed/30428853},
	Bdsk-Url-2 = {https://doi.org/10.1186/s12859-018-2445-2}}

@article{Bi:2016aa,
	Abstract = {BACKGROUND: RNA-Sequencing (RNA-seq) experiments have been popularly applied to transcriptome studies in recent years. Such experiments are still relatively costly. As a result, RNA-seq experiments often employ a small number of replicates. Power analysis and sample size calculation are challenging in the context of differential expression analysis with RNA-seq data. One challenge is that there are no closed-form formulae to calculate power for the popularly applied tests for differential expression analysis. In addition, false discovery rate (FDR), instead of family-wise type I error rate, is controlled for the multiple testing error in RNA-seq data analysis. So far, there are very few proposals on sample size calculation for RNA-seq experiments. RESULTS: In this paper, we propose a procedure for sample size calculation while controlling FDR for RNA-seq experimental design. Our procedure is based on the weighted linear model analysis facilitated by the voom method which has been shown to have competitive performance in terms of power and FDR control for RNA-seq differential expression analysis. We derive a method that approximates the average power across the differentially expressed genes, and then calculate the sample size to achieve a desired average power while controlling FDR. Simulation results demonstrate that the actual power of several popularly applied tests for differential expression is achieved and is close to the desired power for RNA-seq data with sample size calculated based on our method. CONCLUSIONS: Our proposed method provides an efficient algorithm to calculate sample size while controlling FDR for RNA-seq experimental design. We also provide an R package ssizeRNA that implements our proposed method and can be downloaded from the Comprehensive R Archive Network ( http://cran.r-project.org ).},
	An = {27029470},
	Author = {Bi, Ran and Liu, Peng},
	Date = {2016/03/31},
	Date-Added = {2020-08-23 17:03:47 -0700},
	Date-Modified = {2020-08-23 17:03:47 -0700},
	Db = {PubMed},
	Doi = {10.1186/s12859-016-0994-9},
	Isbn = {1471-2105},
	J2 = {BMC Bioinformatics},
	Journal = {BMC bioinformatics},
	Keywords = {Experimental design; FDR; Power analysis; RNA-seq; Sample size calculation; *Algorithms; Internet; RNA/chemistry/genetics/*metabolism; Sample Size; *Sequence Analysis, RNA; Transcriptome; User-Computer Interface},
	L2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4815167/},
	La = {eng},
	Month = {03},
	Pages = {146--146},
	Publisher = {BioMed Central},
	Title = {Sample size calculation while controlling false discovery rate for differential expression analysis with RNA-sequencing experiments},
	Ty = {JOUR},
	U1 = {27029470{$[$}pmid{$]$}},
	U2 = {PMC4815167{$[$}pmcid{$]$}},
	U4 = {10.1186/s12859-016-0994-9{$[$}PII{$]$}},
	Url = {https://www.ncbi.nlm.nih.gov/pubmed/27029470},
	Volume = {17},
	Year = {2016},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pubmed/27029470},
	Bdsk-Url-2 = {https://doi.org/10.1186/s12859-016-0994-9}}

@article{Hart:2013aa,
	Abstract = {Abstract Background: Given the high technical reproducibility and orders of magnitude greater resolution than microarrays, next-generation sequencing of mRNA (RNA-Seq) is quickly becoming the de facto standard for measuring levels of gene expression in biological experiments. Two important questions must be taken into consideration when designing a particular experiment, namely, 1) how deep does one need to sequence? and, 2) how many biological replicates are necessary to observe a significant change in expression? Results: Based on the gene expression distributions from 127 RNA-Seq experiments, we find evidence that 91{\%}?$\pm$?4{\%} of all annotated genes are sequenced at a frequency of 0.1 times per million bases mapped, regardless of sample source. Based on this observation, and combining this information with other parameters such as biological variation and technical variation that we empirically estimate from our large datasets, we developed a model to estimate the statistical power needed to identify differentially expressed genes from RNA-Seq experiments. Conclusions: Our results provide a needed reference for ensuring RNA-Seq gene expression studies are conducted with the optimally sample size, power, and sequencing depth. We also make available both R code and an Excel worksheet for investigators to calculate for their own experiments.},
	Annote = {doi: 10.1089/cmb.2012.0283},
	Author = {Hart, Steven N. and Therneau, Terry M. and Zhang, Yuji and Poland, Gregory A. and Kocher, Jean-Pierre},
	Booktitle = {Journal of Computational Biology},
	Da = {2013/12/01},
	Date = {2013/08/20},
	Date-Added = {2020-08-23 17:01:35 -0700},
	Date-Modified = {2020-08-23 17:01:35 -0700},
	Doi = {10.1089/cmb.2012.0283},
	Journal = {Journal of Computational Biology},
	Journal1 = {Journal of Computational Biology},
	M3 = {doi: 10.1089/cmb.2012.0283},
	Month = {2019/07/24},
	N2 = {Abstract Background: Given the high technical reproducibility and orders of magnitude greater resolution than microarrays, next-generation sequencing of mRNA (RNA-Seq) is quickly becoming the de facto standard for measuring levels of gene expression in biological experiments. Two important questions must be taken into consideration when designing a particular experiment, namely, 1) how deep does one need to sequence? and, 2) how many biological replicates are necessary to observe a significant change in expression? Results: Based on the gene expression distributions from 127 RNA-Seq experiments, we find evidence that 91{\%}?$\pm$?4{\%} of all annotated genes are sequenced at a frequency of 0.1 times per million bases mapped, regardless of sample source. Based on this observation, and combining this information with other parameters such as biological variation and technical variation that we empirically estimate from our large datasets, we developed a model to estimate the statistical power needed to identify differentially expressed genes from RNA-Seq experiments. Conclusions: Our results provide a needed reference for ensuring RNA-Seq gene expression studies are conducted with the optimally sample size, power, and sequencing depth. We also make available both R code and an Excel worksheet for investigators to calculate for their own experiments.},
	Number = {12},
	Pages = {970--978},
	Publisher = {Mary Ann Liebert, Inc., publishers},
	Title = {Calculating Sample Size Estimates for RNA Sequencing Data},
	Ty = {JOUR},
	Url = {https://doi.org/10.1089/cmb.2012.0283},
	Volume = {20},
	Year = {2013},
	Year1 = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1089/cmb.2012.0283}}

@article{Ritchie:2015aa,
	Abstract = {limma is an R/Bioconductor software package that provides an integrated solution for analysing data from gene expression experiments. It contains rich features for handling complex experimental designs and for information borrowing to overcome the problem of small sample sizes. Over the past decade, limma has been a popular choice for gene discovery through differential expression analyses of microarray and high-throughput PCR data. The package contains particularly strong facilities for reading, normalizing and exploring such data. Recently, the capabilities of limma have been significantly expanded in two important directions. First, the package can now perform both differential expression and differential splicing analyses of RNA sequencing (RNA-seq) data. All the downstream analysis tools previously restricted to microarray data are now available for RNA-seq as well. These capabilities allow users to analyse both RNA-seq and microarray data with very similar pipelines. Second, the package is now able to go past the traditional gene-wise expression analyses in a variety of ways, analysing expression profiles in terms of co-regulated sets of genes or in terms of higher-order expression signatures. This provides enhanced possibilities for biological interpretation of gene expression differences. This article reviews the philosophy and design of the limma package, summarizing both new and historical features, with an emphasis on recent enhancements and features that have not been previously described.},
	An = {25605792},
	Author = {Ritchie, Matthew E and Phipson, Belinda and Wu, Di and Hu, Yifang and Law, Charity W and Shi, Wei and Smyth, Gordon K},
	Date = {2015/04/20},
	Date-Added = {2020-08-23 15:45:48 -0700},
	Date-Modified = {2020-08-23 15:45:48 -0700},
	Db = {PubMed},
	Doi = {10.1093/nar/gkv007},
	Et = {2015/01/20},
	Isbn = {1362-4962; 0305-1048},
	J2 = {Nucleic Acids Res},
	Journal = {Nucleic acids research},
	Keywords = {*Gene Expression Regulation; *Oligonucleotide Array Sequence Analysis; *Sequence Analysis, RNA; *Software},
	L2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4402510/},
	La = {eng},
	Month = {04},
	Number = {7},
	Pages = {e47--e47},
	Publisher = {Oxford University Press},
	Title = {limma powers differential expression analyses for RNA-sequencing and microarray studies},
	Ty = {JOUR},
	U1 = {25605792{$[$}pmid{$]$}},
	U2 = {PMC4402510{$[$}pmcid{$]$}},
	U4 = {gkv007{$[$}PII{$]$}},
	Url = {https://pubmed.ncbi.nlm.nih.gov/25605792},
	Volume = {43},
	Year = {2015},
	Bdsk-Url-1 = {https://pubmed.ncbi.nlm.nih.gov/25605792},
	Bdsk-Url-2 = {https://doi.org/10.1093/nar/gkv007}}

@article{Law:2018aa,
	Author = {Law, CW and Alhamdoosh, M and Su, S and Dong, X and Tian, L and Smyth, GK and Ritchie, ME},
	Date = {2018},
	Date-Added = {2020-08-23 14:33:52 -0700},
	Date-Modified = {2020-08-29 14:44:23 -0700},
	Journal = {F1000Research},
	Number = {1408},
	Title = {RNA-seq analysis is easy as 1-2-3 with limma, Glimma and edgeR [version 3; peer review: 3 approved]},
	Type = {10.12688/f1000research.9005.3},
	Url = {https://dx.doi.org/10.12688%2Ff1000research.9005.3},
	Volume = {5},
	Year = {2018},
	Bdsk-Url-1 = {http://openr.es/e5n}}

@article{Permenter:2015aa,
	Abstract = {Proper storage of whole blood is crucial for isolating nucleic acids from leukocytes and to ensure adequate performance of downstream assays in the molecular diagnostic laboratory. Short-term and long-term storage recommendations are lacking for successful isolation of genomic DNA (gDNA). Container type (EDTA or heparin), temperature (4 $\,^{\circ}$C and room temperature) and time (1--130 days) were assessed as criterion for sample acceptance policies. The percentage of integrated area ({\%}Ti) between 150 and 10,000 bp from the 2200 TapeStation electropherogram was calculated to measure gDNA degradation. Refrigerated EDTA samples yielded gDNA with low {\%}Ti (high quality). Heparinized samples stored at room temperature yielded gDNA of worst quality. Downstream analysis demonstrated that the quality of the gDNA correlated with the quality of the data; samples with high {\%}Ti generated significantly lower levels of high molecular weight amplicons. Recommendations from these analyses include storing blood samples intended for nucleic acid isolation in EDTA tubes at 4 $\,^{\circ}$C for long term storage (>10 days). gDNA should be extracted within 3 days when blood is stored at room temperature regardless of the container. Finally, refrigerated heparinized samples should not be stored longer than 9 days if expecting high quality gDNA isolates. Laboratories should consider many factors, in addition to the results obtained herein, to update their policies for sample acceptance for gDNA extraction intended for molecular genetic testing.},
	Author = {Permenter, Jessalyn and Ishwar, Arjun and Rounsavall, Angie and Smith, Maddie and Faske, Jennifer and Sailey, Charles J. and Alfaro, Maria P.},
	Da = {2015/12/01/},
	Date-Added = {2020-08-23 11:55:23 -0700},
	Date-Modified = {2020-08-23 11:55:23 -0700},
	Doi = {https://doi.org/10.1016/j.mcp.2015.07.002},
	Isbn = {0890-8508},
	Journal = {Molecular and Cellular Probes},
	Keywords = {Genomic DNA; Sample storage; Extraction; Diagnostic testing; Clinical lab; Guidelines},
	Number = {6},
	Pages = {449--453},
	Title = {Quantitative analysis of genomic DNA degradation in whole blood under various storage conditions for molecular diagnostic testing},
	Ty = {JOUR},
	Url = {http://www.sciencedirect.com/science/article/pii/S0890850815300207},
	Volume = {29},
	Year = {2015},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0890850815300207},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.mcp.2015.07.002}}

@article{Huang:2017aa,
	Abstract = {DNA and RNA samples from blood are the common examination target for non-invasive physical tests and/or biomedical studies. Since high-quality DNA and RNA samples guarantee the correctness of these tests and/or studies, we investigated the effects of storage temperature and storage duration of whole blood on DNA and RNA qualities. Subjects were enrolled to donate blood samples which were stored for different durations and at different temperatures, followed by the examinations on RNA quality, qPCR, DNA quality and DNA methylation. For RNA, we observed obvious quality decline with storage duration longer than 24 hours. Storage at low temperature does not keep RNA samples from degradation. And, storing whole blood samples in freezer dramatically damage RNA. For DNA, quality decline was not observed even with storage duration for 15 days. However, DNA methylation significantly altered with storage duration longer than three days. Storage duration within 24 hours is critical for collecting high-quality RNA samples for next-generation sequencing (NGS) assays (RIN≧8). If microarray assays are expected (RIN≧7), storage duration within 32 hours is acceptable. Although DNA is resistant within 15 days when kept in whole blood, DNA quantity dramatically decreases owing to WBC lysis. In addition, duration for more than three days significantly alter DNA methylation status, globally and locally. Our result provides a reference for dealing with blood samples.},
	An = {28926588},
	Author = {Huang, Lien-Hung and Lin, Pei-Hsien and Tsai, Kuo-Wang and Wang, Liang-Jen and Huang, Ying-Hsien and Kuo, Ho-Chang and Li, Sung-Chou},
	Date = {2017/09/19},
	Date-Added = {2020-08-23 11:48:38 -0700},
	Date-Modified = {2020-08-23 11:48:38 -0700},
	Db = {PubMed},
	Doi = {10.1371/journal.pone.0184692},
	Isbn = {1932-6203},
	J2 = {PLoS One},
	Journal = {PloS one},
	Keywords = {*Blood Preservation; DNA/isolation \& purification/*metabolism; DNA Methylation; High-Throughput Nucleotide Sequencing; Humans; Leukocytes/cytology/metabolism; RNA/isolation \& purification/*metabolism; Real-Time Polymerase Chain Reaction; Sequence Analysis, DNA; Sequence Analysis, RNA; Temperature; Time Factors},
	L2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5604973/},
	La = {eng},
	Month = {09},
	Number = {9},
	Pages = {e0184692--e0184692},
	Publisher = {Public Library of Science},
	Title = {The effects of storage temperature and duration of blood samples on DNA and RNA qualities},
	Ty = {JOUR},
	U1 = {28926588{$[$}pmid{$]$}},
	U2 = {PMC5604973{$[$}pmcid{$]$}},
	U4 = {PONE-D-17-18280{$[$}PII{$]$}},
	Url = {https://pubmed.ncbi.nlm.nih.gov/28926588},
	Volume = {12},
	Year = {2017},
	Bdsk-Url-1 = {https://pubmed.ncbi.nlm.nih.gov/28926588},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pone.0184692}}

@article{Song:2017aa,
	Abstract = {5-Hydroxymethylcytosine (5hmC) is an important mammalian DNA epigenetic modification that has been linked to gene regulation and cancer pathogenesis. Here we explored the diagnostic potential of 5hmC in circulating cell-free DNA (cfDNA) using a sensitive chemical labeling-based low-input shotgun sequencing approach. We sequenced cell-free 5hmC from 49 patients of seven different cancer types and found distinct features that could be used to predict cancer types and stages with high accuracy. Specifically, we discovered that lung cancer leads to a progressive global loss of 5hmC in cfDNA, whereas hepatocellular carcinoma and pancreatic cancer lead to disease-specific changes in the cell-free hydroxymethylome. Our proof-of-principle results suggest that cell-free 5hmC signatures may potentially be used not only to identify cancer types but also to track tumor stage in some cancers.},
	Author = {Song, Chun-Xiao and Yin, Senlin and Ma, Li and Wheeler, Amanda and Chen, Yu and Zhang, Yan and Liu, Bin and Xiong, Junjie and Zhang, Weihan and Hu, Jiankun and Zhou, Zongguang and Dong, Biao and Tian, Zhiqi and Jeffrey, Stefanie S and Chua, Mei-Sze and So, Samuel and Li, Weimin and Wei, Yuquan and Diao, Jiajie and Xie, Dan and Quake, Stephen R},
	Da = {2017/10/01},
	Date-Added = {2020-08-22 12:53:18 -0700},
	Date-Modified = {2020-08-22 12:53:18 -0700},
	Doi = {10.1038/cr.2017.106},
	Id = {Song2017},
	Isbn = {1748-7838},
	Journal = {Cell Research},
	Number = {10},
	Pages = {1231--1242},
	Title = {5-Hydroxymethylcytosine signatures in cell-free DNA provide information about tumor types and stages},
	Ty = {JOUR},
	Url = {https://doi.org/10.1038/cr.2017.106},
	Volume = {27},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1038/cr.2017.106}}

@article{Gai:2019aa,
	Abstract = {Cell-free circulating DNA (cfDNA) in plasma has gained global interest as a diagnostic material for noninvasive prenatal testing and cancer diagnosis, or the so-called "liquid biopsy". Recent studies have discovered a great number of valuable genetic and epigenetic biomarkers for cfDNA-based liquid biopsy. Considering that the genetic biomarkers, e.g., somatic mutations, usually vary from case to case in most cancer patients, epigenetic biomarkers that are generalizable across various samples thus possess certain advantages. In this study, we reviewed the most recent studies and advances on utilizing epigenetic biomarkers for liquid biopsies. We first reviewed more traditional methods of using tissue/cancer-specific DNA methylation biomarkers and digital PCR or sequencing technologies for cancer diagnosis, as well as tumor origin determination. In the second part, we discussed the emerging novel approaches for exploring the biological basis and clinical applications of cfDNA fragmentation patterns. We further provided our comments and points of view on the future directions on epigenetic biomarker development for cfDNA-based liquid biopsies.},
	An = {30634483},
	Author = {Gai, Wanxia and Sun, Kun},
	Date = {2019/01/09},
	Date-Added = {2020-08-22 12:18:37 -0700},
	Date-Modified = {2020-08-22 12:18:37 -0700},
	Db = {PubMed},
	Doi = {10.3390/genes10010032},
	Isbn = {2073-4425; 2073-4425},
	J2 = {Genes (Basel)},
	Journal = {Genes},
	Keywords = {*DNA methylation; *cancer testing; *cell-free DNA; *fragmentation pattern; *plasma; *preferred ends; *tissue-of-origin analysis; Biomarkers, Tumor/blood/*genetics; Cell-Free Nucleic Acids/blood/*genetics; DNA Methylation; Early Detection of Cancer/methods; *Epigenesis, Genetic; Humans; Prenatal Diagnosis/methods},
	L2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6356936/},
	La = {eng},
	Month = {01},
	Number = {1},
	Pages = {32},
	Publisher = {MDPI},
	Title = {Epigenetic Biomarkers in Cell-Free DNA and Applications in Liquid Biopsy},
	Ty = {JOUR},
	U1 = {30634483{$[$}pmid{$]$}},
	U2 = {PMC6356936{$[$}pmcid{$]$}},
	U4 = {genes10010032{$[$}PII{$]$}},
	Url = {https://pubmed.ncbi.nlm.nih.gov/30634483},
	Volume = {10},
	Year = {2019},
	Bdsk-Url-1 = {https://pubmed.ncbi.nlm.nih.gov/30634483},
	Bdsk-Url-2 = {https://doi.org/10.3390/genes10010032}}

@manual{R-bookdown,
	Author = {Yihui Xie},
	Date-Added = {2020-08-22 11:48:26 -0700},
	Date-Modified = {2020-08-22 11:48:26 -0700},
	Note = {R package version 0.19},
	Title = {bookdown: Authoring Books and Technical Documents with R Markdown},
	Url = {https://CRAN.R-project.org/package=bookdown},
	Year = {2020},
	Bdsk-Url-1 = {https://CRAN.R-project.org/package=bookdown}}

@article{Brenton:2005aa,
	Abstract = {Profiling breast cancer with expression arrays has become common, and it has been suggested that the results from early studies will lead to understanding of the molecular differences between clinical cases and allow individualization of care. We critically review two main applications of expression profiling; studies unraveling novel breast cancer classifications and those that aim to identify novel markers for prediction of clinical outcome. Breast cancer may now be subclassified into luminal, basal, and HER2 subtypes with distinct differences in prognosis and response to therapy. However, profiling studies to identify predictive markers have suffered from methodologic problems that prevent general application of their results. Future work will need to reanalyze existing microarray data sets to identify more representative sets of candidate genes for use as prognostic signatures and will need to take into account the new knowledge of molecular subtypes of breast cancer when assessing predictive effects.},
	Address = {Cancer Genomics Program, Department of Oncology, University of Cambridge, Hutchison/MRC Research Centre, Cambridge, United Kingdom CB22XZ.},
	Author = {Brenton, James D and Carey, Lisa A and Ahmed, Ahmed Ashour and Caldas, Carlos},
	Cin = {J Clin Oncol. 2006 Feb 1;24(4):721-2; author reply 722-3. PMID: 16446348},
	Crdt = {2005/09/08 09:00},
	Date = {2005 Oct 10},
	Date-Added = {2020-08-21 19:28:41 -0700},
	Date-Modified = {2020-08-21 19:28:41 -0700},
	Dcom = {20051221},
	Dep = {20050906},
	Doi = {10.1200/JCO.2005.03.3845},
	Edat = {2005/09/08 09:00},
	Issn = {0732-183X (Print); 0732-183X (Linking)},
	Jid = {8309333},
	Journal = {J Clin Oncol},
	Jt = {Journal of clinical oncology : official journal of the American Society of Clinical Oncology},
	Language = {eng},
	Lr = {20191210},
	Mh = {Biomarkers, Tumor/*genetics; Breast Neoplasms/classification/*genetics; Female; Forecasting; *Gene Expression Profiling; Genetic Markers; Humans; Outcome Assessment, Health Care; Predictive Value of Tests},
	Mhda = {2005/12/22 09:00},
	Month = {Oct},
	Number = {29},
	Own = {NLM},
	Pages = {7350--7360},
	Phst = {2005/09/08 09:00 {$[$}pubmed{$]$}; 2005/12/22 09:00 {$[$}medline{$]$}; 2005/09/08 09:00 {$[$}entrez{$]$}},
	Pii = {JCO.2005.03.3845},
	Pl = {United States},
	Pmid = {16145060},
	Pst = {ppublish},
	Pt = {Journal Article; Review},
	Rf = {66},
	Rn = {0 (Biomarkers, Tumor); 0 (Genetic Markers)},
	Sb = {IM},
	Status = {MEDLINE},
	Title = {Molecular classification and molecular forecasting of breast cancer: ready for clinical application?},
	Volume = {23},
	Year = {2005},
	Bdsk-Url-1 = {https://doi.org/10.1200/JCO.2005.03.3845}}

@article{Ahmed:2005aa,
	Abstract = {This review takes a sceptical view of the impact of breast cancer studies that have used microarrays to identify predictors of clinical outcome. In addition to discussing general pitfalls of microarray experiments, we also critically review the key breast cancer studies to highlight methodological problems in cohort selection, statistical analysis, validation of results and reporting of raw data. We conclude that the optimum use of microarrays in clinical studies requires further optimisation and standardisation of methodology and reporting, together with improvements in clinical study design.},
	Address = {Cancer Genomics Programme, Department of Oncology, University of Cambridge, Hutchison/MRC Research Centre, Cambridge, UK.},
	Author = {Ahmed, Ahmed Ashour and Brenton, James D},
	Crdt = {2005/07/01 09:00},
	Date = {2005},
	Date-Added = {2020-08-21 19:27:19 -0700},
	Date-Modified = {2020-08-21 19:27:19 -0700},
	Dcom = {20060125},
	Dep = {20050401},
	Doi = {10.1186/bcr1017},
	Edat = {2005/07/01 09:00},
	Issn = {1465-542X (Electronic); 1465-5411 (Print); 1465-5411 (Linking)},
	Jid = {100927353},
	Journal = {Breast Cancer Res},
	Jt = {Breast cancer research : BCR},
	Language = {eng},
	Lr = {20181113},
	Mh = {Breast Neoplasms/*genetics/*therapy; Clinical Trials as Topic; Endpoint Determination; Female; *Gene Expression Profiling; *Genetic Markers; Humans; *Oligonucleotide Array Sequence Analysis/methods; Prognosis; Research Design; Treatment Outcome},
	Mhda = {2006/01/26 09:00},
	Number = {3},
	Own = {NLM},
	Pages = {96--99},
	Phst = {2005/07/01 09:00 {$[$}pubmed{$]$}; 2006/01/26 09:00 {$[$}medline{$]$}; 2005/07/01 09:00 {$[$}entrez{$]$}},
	Pii = {bcr1017},
	Pmc = {PMC1143564},
	Pmid = {15987437},
	Pst = {ppublish},
	Pt = {Journal Article; Review},
	Rn = {0 (Genetic Markers)},
	Sb = {IM},
	Status = {MEDLINE},
	Title = {Microarrays and breast cancer clinical studies: forgetting what we have not yet learnt.},
	Volume = {7},
	Year = {2005},
	Bdsk-Url-1 = {https://doi.org/10.1186/bcr1017}}

@article{Lonning:2005aa,
	Abstract = {The introduction of DNA microarray techniques has had dramatic implications on cancer research, allowing researchers to analyze expression of multiple genes in concert and relate the findings to clinical parameters. The main discoveries in breast cancer, as well as in other malignancies, have so far been with respect to two key issues. First, individual tumors arising from the same organ may be grouped into distinct classes based on their gene expression profiles, independent of stage and grade. Second, the biologic relevance of such classification is corroborated by significant prognostic impact. We review how the use of microarray technologies can provide unique possibilities to explore the mechanisms of tumor behavior in vivo that will allow evaluation of prognosis and, potentially, drug resistance. However, in spite of recent advances, we are not yet at a stage where the use of these techniques should be implemented for routine clinical use, whether to define prognostic factors or to predict sensitivity to therapy.},
	Address = {Breast Cancer Unit, Section of Oncology, Institute of Medicine, Haukeland University Hospital, Bergen, Norway.},
	Author = {L{\o}nning, Per Eystein and S{\o}rlie, Therese and B{\o}rresen-Dale, Anne-Lise},
	Crdt = {2005/11/03 09:00},
	Date = {2005 Jan},
	Date-Added = {2020-08-21 19:25:57 -0700},
	Date-Modified = {2020-08-21 19:25:57 -0700},
	Dcom = {20051115},
	Doi = {10.1038/ncponc0072},
	Edat = {2005/11/03 09:00},
	Issn = {1743-4254 (Print); 1743-4254 (Linking)},
	Jid = {101226509},
	Journal = {Nat Clin Pract Oncol},
	Jt = {Nature clinical practice. Oncology},
	Language = {eng},
	Lr = {20051102},
	Mh = {Antineoplastic Agents/pharmacology/therapeutic use; Breast Neoplasms/*genetics/*therapy; Drug Resistance, Neoplasm; Female; *Gene Expression Profiling; Humans; *Oligonucleotide Array Sequence Analysis; Patient Care Planning; Prognosis},
	Mhda = {2005/11/16 09:00},
	Month = {Jan},
	Number = {1},
	Own = {NLM},
	Pages = {26--33},
	Phst = {2004/09/06 00:00 {$[$}received{$]$}; 2004/12/06 00:00 {$[$}accepted{$]$}; 2005/11/03 09:00 {$[$}pubmed{$]$}; 2005/11/16 09:00 {$[$}medline{$]$}; 2005/11/03 09:00 {$[$}entrez{$]$}},
	Pii = {ncponc0072},
	Pl = {England},
	Pmid = {16264853},
	Pst = {ppublish},
	Pt = {Journal Article; Review},
	Rf = {47},
	Rn = {0 (Antineoplastic Agents)},
	Sb = {IM},
	Status = {MEDLINE},
	Title = {Genomics in breast cancer-therapeutic implications.},
	Volume = {2},
	Year = {2005},
	Bdsk-Url-1 = {https://doi.org/10.1038/ncponc0072}}

@article{Ioannidis:2005aa,
	Address = {Department of Hygiene and Epidemiology, University of Ioannina School of Medicine, Ioannina 45110, Greece. jioannid@cc.uoi.gr},
	Author = {Ioannidis, John P A},
	Con = {Lancet. 2005 Feb 5-11;365(9458):488-92. PMID: 15705458},
	Crdt = {2005/02/12 09:00},
	Date = {2005 Feb 5-11},
	Date-Added = {2020-08-21 19:24:49 -0700},
	Date-Modified = {2020-08-21 19:24:49 -0700},
	Dcom = {20050222},
	Doi = {10.1016/S0140-6736(05)17878-7},
	Edat = {2005/02/12 09:00},
	Issn = {1474-547X (Electronic); 0140-6736 (Linking)},
	Jid = {2985213R},
	Journal = {Lancet},
	Jt = {Lancet (London, England)},
	Language = {eng},
	Lr = {20150616},
	Mh = {Data Interpretation, Statistical; *Gene Expression Profiling; Humans; Neoplasms/*genetics; *Oligonucleotide Array Sequence Analysis; Prognosis; Reproducibility of Results},
	Mhda = {2005/02/23 09:00},
	Month = {Feb},
	Number = {9458},
	Own = {NLM},
	Pages = {454--455},
	Phst = {2005/02/12 09:00 {$[$}pubmed{$]$}; 2005/02/23 09:00 {$[$}medline{$]$}; 2005/02/12 09:00 {$[$}entrez{$]$}},
	Pii = {S0140-6736(05)17878-7},
	Pl = {England},
	Pmid = {15705441},
	Pst = {ppublish},
	Pt = {Comment; Journal Article},
	Sb = {AIM; IM},
	Status = {MEDLINE},
	Title = {Microarrays and molecular research: noise discovery?},
	Volume = {365},
	Year = {2005},
	Bdsk-Url-1 = {https://doi.org/10.1016/S0140-6736(05)17878-7}}

@article{Michiels:2005aa,
	Abstract = {BACKGROUND: General studies of microarray gene-expression profiling have been undertaken to predict cancer outcome. Knowledge of this gene-expression profile or molecular signature should improve treatment of patients by allowing treatment to be tailored to the severity of the disease. We reanalysed data from the seven largest published studies that have attempted to predict prognosis of cancer patients on the basis of DNA microarray analysis. METHODS: The standard strategy is to identify a molecular signature (ie, the subset of genes most differentially expressed in patients with different outcomes) in a training set of patients and to estimate the proportion of misclassifications with this signature on an independent validation set of patients. We expanded this strategy (based on unique training and validation sets) by using multiple random sets, to study the stability of the molecular signature and the proportion of misclassifications. FINDINGS: The list of genes identified as predictors of prognosis was highly unstable; molecular signatures strongly depended on the selection of patients in the training sets. For all but one study, the proportion misclassified decreased as the number of patients in the training set increased. Because of inadequate validation, our chosen studies published overoptimistic results compared with those from our own analyses. Five of the seven studies did not classify patients better than chance. INTERPRETATION: The prognostic value of published microarray results in cancer studies should be considered with caution. We advocate the use of validation by repeated random sampling.},
	Address = {Biostatistics and Epidemiology Unit, Institut Gustave Roussy, Villejuif, France.},
	Author = {Michiels, Stefan and Koscielny, Serge and Hill, Catherine},
	Cin = {Lancet. 2005 Feb 5-11;365(9458):454-5. PMID: 15705441; Lancet. 2005 May 14-20;365(9472):1683-4; author reply 1684-5. PMID: 15894090; Lancet. 2005 May 14-20;365(9472):1683; author reply 1684-5. PMID: 15894091; Lancet. 2005 May 14-20;365(9472):1685. PMID: 15894093},
	Crdt = {2005/02/12 09:00},
	Date = {2005 Feb 5-11},
	Date-Added = {2020-08-21 19:23:46 -0700},
	Date-Modified = {2020-08-21 19:23:46 -0700},
	Dcom = {20050222},
	Doi = {10.1016/S0140-6736(05)17866-0},
	Edat = {2005/02/12 09:00},
	Issn = {1474-547X (Electronic); 0140-6736 (Linking)},
	Jid = {2985213R},
	Journal = {Lancet},
	Jt = {Lancet (London, England)},
	Language = {eng},
	Lr = {20191210},
	Mh = {*Gene Expression Profiling; Humans; Neoplasms/*genetics/therapy; *Oligonucleotide Array Sequence Analysis; Prognosis; Sample Size},
	Mhda = {2005/02/23 09:00},
	Month = {Feb},
	Number = {9458},
	Own = {NLM},
	Pages = {488--492},
	Phst = {2005/02/12 09:00 {$[$}pubmed{$]$}; 2005/02/23 09:00 {$[$}medline{$]$}; 2005/02/12 09:00 {$[$}entrez{$]$}},
	Pii = {S0140-6736(05)17866-0},
	Pl = {England},
	Pmid = {15705458},
	Pst = {ppublish},
	Pt = {Journal Article; Research Support, Non-U.S. Gov't; Validation Study},
	Sb = {AIM; IM},
	Status = {MEDLINE},
	Title = {Prediction of cancer outcome with microarrays: a multiple random validation strategy.},
	Volume = {365},
	Year = {2005},
	Bdsk-Url-1 = {https://doi.org/10.1016/S0140-6736(05)17866-0}}

@article{Fu:2005aa,
	Abstract = {Motivation: The standard paradigm for a classifier design is to obtain a sample of feature-label pairs and then to apply a classification rule to derive a classifier from the sample data. Typically in laboratory situations the sample size is limited by cost, time or availability of sample material. Thus, an investigator may wish to consider a sequential approach in which there is a sufficient number of patients to train a classifier in order to make a sound decision for diagnosis while at the same time keeping the number of patients as small as possible to make the studies affordable.Results: A sequential classification procedure is studied via the martingale central limit theorem. It updates the classification rule at each step and provides stopping criteria to ensure with a certain confidence that at stopping a future subject will have misclassification probability smaller than a predetermined threshold. Simulation studies and applications to microarray data analysis are provided. The procedure possesses several attractive properties: (1) it updates the classification rule sequentially and thus does not rely on distributions of primary measurements from other studies; (2) it assesses the stopping criteria at each sequential step and thus can substantially reduce cost via early stopping; and (3) it is not restricted to any particular classification rule and therefore applies to any parametric or non-parametric method, including feature selection or extraction.Availability: R-code for the sequential stopping rule is available at http://stat.tamu.edu/\~{}wfu/microarray/sequential/R-code.htmlContact:wfu{\char64}stat.tamu.edu},
	Author = {Fu, Wenjiang J. and Dougherty, Edward R. and Mallick, Bani and Carroll, Raymond J.},
	Date-Added = {2020-08-21 18:03:18 -0700},
	Date-Modified = {2020-08-21 18:03:18 -0700},
	Doi = {10.1093/bioinformatics/bth461},
	Isbn = {1367-4803},
	Journal = {Bioinformatics},
	Journal1 = {Bioinformatics},
	Month = {8/22/2020},
	Number = {1},
	Pages = {63--70},
	Title = {How many samples are needed to build a classifier: a general sequential approach},
	Ty = {JOUR},
	Url = {https://doi.org/10.1093/bioinformatics/bth461},
	Volume = {21},
	Year = {2005},
	Year1 = {2004/08/05/},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAXLi4vUmVmcy9TaW1vbl8yMDExLm5iaWJPEQGGAAAAAAGGAAIAAAZNYWMgSEQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8PU2ltb25fMjAxMS5uYmliAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAABAAIAAAogY3UAAAAAAAAAAAAAAAAABFJlZnMAAgBNLzpVc2VyczpmY29sbGluOkRvY3VtZW50czpQcm9qZWN0czpSc3R1ZmY6SENDNWhtQ0V4cGxvcmU6UmVmczpTaW1vbl8yMDExLm5iaWIAAA4AIAAPAFMAaQBtAG8AbgBfADIAMAAxADEALgBuAGIAaQBiAA8ADgAGAE0AYQBjACAASABEABIAS1VzZXJzL2Zjb2xsaW4vRG9jdW1lbnRzL1Byb2plY3RzL1JzdHVmZi9IQ0M1aG1DRXhwbG9yZS9SZWZzL1NpbW9uXzIwMTEubmJpYgAAEwABLwAAFQACAA7//wAAAAgADQAaACQAPgAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAHI},
	Bdsk-Url-1 = {https://doi.org/10.1093/bioinformatics/bth461}}

@article{Dobbin:2007aa,
	Abstract = {Many gene expression studies attempt to develop a predictor of pre-defined diagnostic or prognostic classes. If the classes are similar biologically, then the number of genes that are differentially expressed between the classes is likely to be small compared to the total number of genes measured. This motivates a two-step process for predictor development, a subset of differentially expressed genes is selected for use in the predictor and then the predictor constructed from these. Both these steps will introduce variability into the resulting classifier, so both must be incorporated in sample size estimation. We introduce a methodology for sample size determination for prediction in the context of high-dimensional data that captures variability in both steps of predictor development. The methodology is based on a parametric probability model, but permits sample size computations to be carried out in a practical manner without extensive requirements for preliminary data. We find that many prediction problems do not require a large training set of arrays for classifier development.},
	Author = {Dobbin, Kevin K. and Simon, Richard M.},
	Date-Added = {2020-08-21 17:14:43 -0700},
	Date-Modified = {2020-08-21 17:14:43 -0700},
	Doi = {10.1093/biostatistics/kxj036},
	Isbn = {1465-4644},
	Journal = {Biostatistics},
	Journal1 = {Biostatistics},
	Month = {8/22/2020},
	Number = {1},
	Pages = {101--117},
	Title = {Sample size planning for developing classifiers using high-dimensional DNA microarray data},
	Ty = {JOUR},
	Url = {https://doi.org/10.1093/biostatistics/kxj036},
	Volume = {8},
	Year = {2007},
	Year1 = {2006/04/13/},
	Bdsk-Url-1 = {https://doi.org/10.1093/biostatistics/kxj036}}

@article{Fan:2006aa,
	Annote = {doi: 10.1056/NEJMoa052933},
	Author = {Fan, Cheng and Oh, Daniel S. and Wessels, Lodewyk and Weigelt, Britta and Nuyten, Dimitry S. A. and Nobel, Andrew B. and van't Veer, Laura J. and Perou, Charles M.},
	Booktitle = {New England Journal of Medicine},
	Da = {2006/08/10},
	Date = {2006/08/10},
	Date-Added = {2020-08-21 17:05:25 -0700},
	Date-Modified = {2020-08-21 17:05:25 -0700},
	Doi = {10.1056/NEJMoa052933},
	Isbn = {0028-4793},
	Journal = {New England Journal of Medicine},
	Journal1 = {N Engl J Med},
	M3 = {doi: 10.1056/NEJMoa052933},
	Month = {2020/08/21},
	Number = {6},
	Pages = {560--569},
	Publisher = {Massachusetts Medical Society},
	Title = {Concordance among Gene-Expression--Based Predictors for Breast Cancer},
	Ty = {JOUR},
	Url = {https://doi.org/10.1056/NEJMoa052933},
	Volume = {355},
	Year = {2006},
	Year1 = {2006},
	Bdsk-Url-1 = {https://doi.org/10.1056/NEJMoa052933}}

@article{Ein-Dor:2006aa,
	Abstract = {Predicting at the time of discovery the prognosis and metastatic potential of cancer is a major challenge in current clinical research. Numerous recent studies searched for gene expression signatures that outperform traditionally used clinical parameters in outcome prediction. Finding such a signature will free many patients of the suffering and toxicity associated with adjuvant chemotherapy given to them under current protocols, even though they do not need such treatment. A reliable set of predictive genes also will contribute to a better understanding of the biological mechanism of metastasis. Several groups have published lists of predictive genes and reported good predictive performance based on them. However, the gene lists obtained for the same clinical types of patients by different groups differed widely and had only very few genes in common. This lack of agreement raised doubts about the reliability and robustness of the reported predictive gene lists, and the main source of the problem was shown to be the small number of samples that were used to generate the gene lists. Here, we introduce a previously undescribed mathematical method, probably approximately correct (PAC) sorting, for evaluating the robustness of such lists. We calculate for several published data sets the number of samples that are needed to achieve any desired level of reproducibility. For example, to achieve a typical overlap of 50{\%} between two predictive lists of genes, breast cancer studies would need the expression profiles of several thousand early discovery patients.},
	An = {16585533},
	Author = {Ein-Dor, Liat and Zuk, Or and Domany, Eytan},
	Date = {2006/04/11},
	Date-Added = {2020-08-21 16:33:02 -0700},
	Date-Modified = {2020-08-21 16:33:02 -0700},
	Db = {PubMed},
	Doi = {10.1073/pnas.0601231103},
	Et = {2006/04/03},
	Isbn = {0027-8424; 1091-6490},
	J2 = {Proc Natl Acad Sci U S A},
	Journal = {Proceedings of the National Academy of Sciences of the United States of America},
	Keywords = {Breast Neoplasms/*genetics; Computer Simulation; Female; Gene Expression Profiling/methods; *Gene Expression Regulation, Neoplastic; Humans; Models, Genetic; Neoplasm Proteins/genetics; Neoplasms/*genetics/pathology; Predictive Value of Tests; Prognosis; Reproducibility of Results; *Treatment Outcome},
	L2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1458674/},
	La = {eng},
	Month = {04},
	Number = {15},
	Pages = {5923--5928},
	Publisher = {National Academy of Sciences},
	Title = {Thousands of samples are needed to generate a robust gene list for predicting outcome in cancer},
	Ty = {JOUR},
	U1 = {16585533{$[$}pmid{$]$}},
	U2 = {PMC1458674{$[$}pmcid{$]$}},
	U4 = {0601231103{$[$}PII{$]$}},
	Url = {https://pubmed.ncbi.nlm.nih.gov/16585533},
	Volume = {103},
	Year = {2006},
	Bdsk-Url-1 = {https://pubmed.ncbi.nlm.nih.gov/16585533},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.0601231103}}

@article{Collin:2018aa,
	Author = {Collin, Francois and Ning, Yuhong and Phillips, Tierney and McCarthy, Erin and Scott, Aaron and Ellison, Chris and Ku, Chin-Jen and Guler, Gulfem D and Chau, Kim and Ashworth, Alan and Quake, Stephen R and Levy, Samuel},
	Date = {2018/01/01},
	Date-Added = {2020-08-21 16:17:47 -0700},
	Date-Modified = {2020-08-21 16:17:47 -0700},
	Doi = {10.1101/422675},
	Journal = {bioRxiv},
	Month = {01},
	N2 = {Pancreatic cancers are typically diagnosed at late stage where disease prognosis is poor as exemplified by a 5-year survival rate of 8.2{\%}. Earlier diagnosis would be beneficial by enabling surgical resection or earlier application of therapeutic regimens. We investigated the detection of pancreatic ductal adenocarcinoma (PDAC) in a non-invasive manner by interrogating changes in 5-hydroxymethylation cytosine status (5hmC) of circulating cell free DNA in the plasma of a PDAC cohort (n=51) in comparison with a non-cancer cohort (n=41). We found that 5hmC sites are enriched in a disease and stage specific manner in exons, 3'UTRs and transcription termination sites. Our data show that 5hmC density is reduced in promoters and histone H3K4me3-associated sites with progressive disease suggesting increased transcriptional activity. 5hmC density is differentially represented in thousands of genes, and a stringently filtered set of the most significant genes points to biology related to pancreas (GATA4, GATA6, PROX1, ONECUT1) and/or cancer development (YAP1, TEAD1, PROX1, ONECUT1, ONECUT2, IGF1 and IGF2). Regularized regression models were built using 5hmC densities in statistically filtered genes or a comprehensive set of highly variable 5hmC counts in genes and performed with an AUC = 0.94-0.96 on training data. We were able to test the ability to classify PDAC and non-cancer samples with the Elastic net and Lasso models on two external pancreatic cancer 5hmC data sets and found validation performance to be AUC = 0.74-0.97. The findings suggest that 5hmC changes enable classification of PDAC patients with high fidelity and are worthy of further investigation on larger cohorts of patient samples.},
	Pages = {422675},
	Title = {Detection of early stage pancreatic cancer using 5-hydroxymethylcytosine signatures in circulating cell free DNA},
	Ty = {JOUR},
	Url = {http://biorxiv.org/content/early/2018/09/26/422675.abstract},
	Year = {2018},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAqLi4vLi4vSENDNWhtQ0FuYWx5c2lzL1JlZnMvRG9iYmluXzIwMDcucmlzTxEBhgAAAAABhgACAAAGTWFjIEhEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////D0RvYmJpbl8yMDA3LnJpcwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAAAgADAAAKIGN1AAAAAAAAAAAAAAAAAARSZWZzAAIATi86VXNlcnM6ZmNvbGxpbjpEb2N1bWVudHM6UHJvamVjdHM6UnN0dWZmOkhDQzVobUNBbmFseXNpczpSZWZzOkRvYmJpbl8yMDA3LnJpcwAOACAADwBEAG8AYgBiAGkAbgBfADIAMAAwADcALgByAGkAcwAPAA4ABgBNAGEAYwAgAEgARAASAExVc2Vycy9mY29sbGluL0RvY3VtZW50cy9Qcm9qZWN0cy9Sc3R1ZmYvSENDNWhtQ0FuYWx5c2lzL1JlZnMvRG9iYmluXzIwMDcucmlzABMAAS8AABUAAgAO//8AAAAIAA0AGgAkAFEAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAB2w==},
	Bdsk-Url-1 = {http://biorxiv.org/content/early/2018/09/26/422675.abstract},
	Bdsk-Url-2 = {https://doi.org/10.1101/422675}}

@article{Liu:2004aa,
	Annote = {doi: 10.1021/ci049810a},
	Author = {Liu, Ying},
	Booktitle = {Journal of Chemical Information and Computer Sciences},
	Da = {2004/11/01},
	Date = {2004/11/01},
	Date-Added = {2020-08-21 11:50:39 -0700},
	Date-Modified = {2020-08-21 11:50:39 -0700},
	Doi = {10.1021/ci049810a},
	Isbn = {0095-2338},
	Journal = {Journal of Chemical Information and Computer Sciences},
	Journal1 = {J. Chem. Inf. Comput. Sci.},
	M3 = {doi: 10.1021/ci049810a},
	Month = {11},
	Number = {6},
	Pages = {1936--1941},
	Publisher = {American Chemical Society},
	Title = {Active Learning with Support Vector Machine Applied to Gene Expression Data for Cancer Classification},
	Ty = {JOUR},
	Url = {https://doi.org/10.1021/ci049810a},
	Volume = {44},
	Year = {2004},
	Year1 = {2004},
	Bdsk-Url-1 = {https://doi.org/10.1021/ci049810a}}

@article{Mukherjee:2003aa,
	Abstract = {A statistical methodology for estimating dataset size requirements for classifying microarray data using learning curves is introduced. The goal is to use existing classification results to estimate dataset size requirements for future classification experiments and to evaluate the gain in accuracy and significance of classifiers built with additional data. The method is based on fitting inverse power-law models to construct empirical learning curves. It also includes a permutation test procedure to assess the statistical significance of classification performance for a given dataset size. This procedure is applied to several molecular classification problems representing a broad spectrum of levels of complexity.},
	Address = {Whitehead Institute/Massachusetts Institute of Technology Center for Genome Research, Cambridge, MA 02139, USA. sayan@genome.wi.mit.edu},
	Author = {Mukherjee, Sayan and Tamayo, Pablo and Rogers, Simon and Rifkin, Ryan and Engle, Anna and Campbell, Colin and Golub, Todd R and Mesirov, Jill P},
	Crdt = {2003/06/14 05:00},
	Date = {2003},
	Date-Added = {2020-08-21 10:12:56 -0700},
	Date-Modified = {2020-08-21 10:12:56 -0700},
	Dcom = {20030715},
	Doi = {10.1089/106652703321825928},
	Edat = {2003/06/14 05:00},
	Issn = {1066-5277 (Print); 1066-5277 (Linking)},
	Jid = {9433358},
	Journal = {J Comput Biol},
	Jt = {Journal of computational biology : a journal of computational molecular cell biology},
	Language = {eng},
	Lr = {20061115},
	Mh = {Algorithms; Computational Biology/methods; Computer Simulation; Gene Expression Profiling/classification/*methods; Humans; Models, Molecular; Neoplasms/*classification/*genetics/metabolism; *Oligonucleotide Array Sequence Analysis},
	Mhda = {2003/07/16 05:00},
	Number = {2},
	Own = {NLM},
	Pages = {119--142},
	Phst = {2003/06/14 05:00 {$[$}pubmed{$]$}; 2003/07/16 05:00 {$[$}medline{$]$}; 2003/06/14 05:00 {$[$}entrez{$]$}},
	Pl = {United States},
	Pmid = {12804087},
	Pst = {ppublish},
	Pt = {Comparative Study; Journal Article; Research Support, Non-U.S. Gov't; Research Support, U.S. Gov't, Non-P.H.S.},
	Sb = {IM},
	Status = {MEDLINE},
	Title = {Estimating dataset size requirements for classifying DNA microarray data.},
	Volume = {10},
	Year = {2003},
	Bdsk-Url-1 = {https://doi.org/10.1089/106652703321825928}}

@article{Dobbin:2008aa,
	Abstract = {PURPOSE: A common goal of gene expression microarray studies is the development of a classifier that can be used to divide patients into groups with different prognoses, or with different expected responses to a therapy. These types of classifiers are developed on a training set, which is the set of samples used to train a classifier. The question of how many samples are needed in the training set to produce a good classifier from high-dimensional microarray data is challenging. EXPERIMENTAL DESIGN: We present a model-based approach to determining the sample size required to adequately train a classifier. RESULTS: It is shown that sample size can be determined from three quantities: standardized fold change, class prevalence, and number of genes or features on the arrays. Numerous examples and important experimental design issues are discussed. The method is adapted to address ex post facto determination of whether the size of a training set used to develop a classifier was adequate. An interactive web site for performing the sample size calculations is provided. CONCLUSION: We showed that sample size calculations for classifier development from high-dimensional microarray data are feasible, discussed numerous important considerations, and presented examples.},
	Address = {Biometric Research Branch, Division of Cancer Treatment and Diagnosis, National Cancer Institute, NIH, Rockville, Maryland 20852, USA. dobbinke@mail.nih.gov},
	Author = {Dobbin, Kevin K and Zhao, Yingdong and Simon, Richard M},
	Crdt = {2008/01/04 09:00},
	Date = {2008 Jan 1},
	Date-Added = {2020-08-21 10:12:52 -0700},
	Date-Modified = {2020-08-21 10:12:52 -0700},
	Dcom = {20080327},
	Doi = {10.1158/1078-0432.CCR-07-0443},
	Edat = {2008/01/04 09:00},
	Issn = {1078-0432 (Print); 1078-0432 (Linking)},
	Jid = {9502500},
	Journal = {Clin Cancer Res},
	Jt = {Clinical cancer research : an official journal of the American Association for Cancer Research},
	Language = {eng},
	Lid = {10.1158/1078-0432.CCR-07-0443 {$[$}doi{$]$}},
	Lr = {20080103},
	Mh = {*Gene Expression Profiling; Humans; *Models, Theoretical; *Oligonucleotide Array Sequence Analysis; *Research Design; Sample Size},
	Mhda = {2008/03/28 09:00},
	Month = {Jan},
	Number = {1},
	Own = {NLM},
	Pages = {108--114},
	Phst = {2008/01/04 09:00 {$[$}pubmed{$]$}; 2008/03/28 09:00 {$[$}medline{$]$}; 2008/01/04 09:00 {$[$}entrez{$]$}},
	Pii = {14/1/108},
	Pl = {United States},
	Pmid = {18172259},
	Pst = {ppublish},
	Pt = {Journal Article},
	Sb = {IM},
	Status = {MEDLINE},
	Title = {How large a training set is needed to develop a classifier for microarray data?},
	Volume = {14},
	Year = {2008},
	Bdsk-Url-1 = {https://doi.org/10.1158/1078-0432.CCR-07-0443}}

@article{Tam:2006aa,
	Abstract = {Monte Carlo simulations are increasingly used to predict pharmacokinetic variability of antimicrobials in a population. We investigated the sample size necessary to provide robust pharmacokinetic predictions. To obtain reasonably robust predictions, a nonparametric model derived from a sample population size of >/=50 appears to be necessary as the input information.},
	An = {16954312},
	Author = {Tam, Vincent H and Kabbara, Samer and Yeh, Rosa F and Leary, Robert H},
	Date = {2006/11/},
	Date-Added = {2020-08-21 10:12:47 -0700},
	Date-Modified = {2020-08-21 10:12:47 -0700},
	Db = {PubMed},
	Doi = {10.1128/AAC.00337-06},
	Et = {2006/09/05},
	Isbn = {0066-4804; 1098-6596},
	J2 = {Antimicrob Agents Chemother},
	Journal = {Antimicrobial agents and chemotherapy},
	Keywords = {Anti-Bacterial Agents/*pharmacokinetics; Area Under Curve; Humans; Monte Carlo Method; *Pharmacokinetics; Population; Sample Size},
	L2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1635223/},
	La = {eng},
	Month = {11},
	Number = {11},
	Pages = {3950--3952},
	Publisher = {American Society for Microbiology},
	Title = {Impact of sample size on the performance of multiple-model pharmacokinetic simulations},
	Ty = {JOUR},
	U1 = {16954312{$[$}pmid{$]$}},
	U2 = {PMC1635223{$[$}pmcid{$]$}},
	U4 = {AAC.00337-06{$[$}PII{$]$}},
	Url = {https://pubmed.ncbi.nlm.nih.gov/16954312},
	Volume = {50},
	Year = {2006},
	Bdsk-Url-1 = {https://pubmed.ncbi.nlm.nih.gov/16954312},
	Bdsk-Url-2 = {https://doi.org/10.1128/AAC.00337-06}}

@article{Kim:2009aa,
	Abstract = {BACKGROUND: Few overlap between independently developed gene signatures and poor inter-study applicability of gene signatures are two of major concerns raised in the development of microarray-based prognostic gene signatures. One recent study suggested that thousands of samples are needed to generate a robust prognostic gene signature. RESULTS: A data set of 1,372 samples was generated by combining eight breast cancer gene expression data sets produced using the same microarray platform and, using the data set, effects of varying samples sizes on a few performances of a prognostic gene signature were investigated. The overlap between independently developed gene signatures was increased linearly with more samples, attaining an average overlap of 16.56{\%} with 600 samples. The concordance between predicted outcomes by different gene signatures also was increased with more samples up to 94.61{\%} with 300 samples. The accuracy of outcome prediction also increased with more samples. Finally, analysis using only Estrogen Receptor-positive (ER+) patients attained higher prediction accuracy than using both patients, suggesting that sub-type specific analysis can lead to the development of better prognostic gene signatures CONCLUSION: Increasing sample sizes generated a gene signature with better stability, better concordance in outcome prediction, and better prediction accuracy. However, the degree of performance improvement by the increased sample size was different between the degree of overlap and the degree of concordance in outcome prediction, suggesting that the sample size required for a study should be determined according to the specific aims of the study.},
	An = {19445687},
	Author = {Kim, Seon-Young},
	Date = {2009/05/16},
	Date-Added = {2020-08-21 10:12:43 -0700},
	Date-Modified = {2020-08-21 10:12:43 -0700},
	Db = {PubMed},
	Doi = {10.1186/1471-2105-10-147},
	Isbn = {1471-2105},
	J2 = {BMC Bioinformatics},
	Journal = {BMC bioinformatics},
	Keywords = {Breast Neoplasms/genetics; Computational Biology/methods; Databases, Genetic; Female; Gene Expression Profiling/*methods; Gene Expression Regulation, Neoplastic; Humans; Oligonucleotide Array Sequence Analysis/*methods; Sample Size},
	L2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2689196/},
	La = {eng},
	Month = {05},
	Pages = {147--147},
	Publisher = {BioMed Central},
	Title = {Effects of sample size on robustness and prediction accuracy of a prognostic gene signature},
	Ty = {JOUR},
	U1 = {19445687{$[$}pmid{$]$}},
	U2 = {PMC2689196{$[$}pmcid{$]$}},
	U4 = {1471-2105-10-147{$[$}PII{$]$}},
	Url = {https://pubmed.ncbi.nlm.nih.gov/19445687},
	Volume = {10},
	Year = {2009},
	Bdsk-Url-1 = {https://pubmed.ncbi.nlm.nih.gov/19445687},
	Bdsk-Url-2 = {https://doi.org/10.1186/1471-2105-10-147}}

@article{Kalayeh:1983aa,
	Abstract = {In this paper a criterion which measures the quality of the estimate of the covariance matrix of a multivariate normal distribution is developed. Based on this criterion, the necessary number of training samples is predicted. Experimental results which are used as a guide for determining the number of training samples are included.},
	Author = {H. M. Kalayeh and D. A. Landgrebe},
	Booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	Date-Added = {2020-08-21 10:12:38 -0700},
	Date-Modified = {2020-08-21 10:12:38 -0700},
	Doi = {10.1109/TPAMI.1983.4767459},
	Isbn = {1939-3539},
	Journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	Journal1 = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	Keywords = {Upper bound; Probability distribution; Pattern recognition; Mathematics; Distributed computing; Linear approximation; Character generation; Statistical analysis; Error probability; Decision theory; Multivariate normal distribution; parameter estimation; training samples; transformed divergence},
	Number = {6},
	Pages = {664--667},
	Title = {Predicting the Required Number of Training Samples},
	Ty = {JOUR},
	Vo = {PAMI-5},
	Volume = {PAMI-5},
	Year = {1983},
	Year1 = {Nov. 1983},
	Bdsk-Url-1 = {https://doi.org/10.1109/TPAMI.1983.4767459}}

@article{Nigam:2000aa,
	Abstract = {This paper shows that the accuracy of learned text classifiers can be improved by augmenting a small number of labeled training documents with a large pool of unlabeled documents. This is important because in many text classification problems obtaining training labels is expensive, while large quantities of unlabeled documents are readily available.},
	Author = {Nigam, Kamal and Mccallum, Andrew Kachites and Thrun, Sebastian and Mitchell, Tom},
	Da = {2000/05/01},
	Date-Added = {2020-08-21 10:12:31 -0700},
	Date-Modified = {2020-08-21 10:12:31 -0700},
	Doi = {10.1023/A:1007692713085},
	Id = {Nigam2000},
	Isbn = {1573-0565},
	Journal = {Machine Learning},
	Number = {2},
	Pages = {103--134},
	Title = {Text Classification from Labeled and Unlabeled Documents using EM},
	Ty = {JOUR},
	Url = {https://doi.org/10.1023/A:1007692713085},
	Volume = {39},
	Year = {2000},
	Bdsk-Url-1 = {https://doi.org/10.1023/A:1007692713085}}

@article{Figueroa:2012aa,
	Abstract = {BACKGROUND: Supervised learning methods need annotated data in order to generate efficient models. Annotated data, however, is a relatively scarce resource and can be expensive to obtain. For both passive and active learning methods, there is a need to estimate the size of the annotated sample required to reach a performance target. METHODS: We designed and implemented a method that fits an inverse power law model to points of a given learning curve created using a small annotated training set. Fitting is carried out using nonlinear weighted least squares optimization. The fitted model is then used to predict the classifier's performance and confidence interval for larger sample sizes. For evaluation, the nonlinear weighted curve fitting method was applied to a set of learning curves generated using clinical text and waveform classification tasks with active and passive sampling methods, and predictions were validated using standard goodness of fit measures. As control we used an un-weighted fitting method. RESULTS: A total of 568 models were fitted and the model predictions were compared with the observed performances. Depending on the data set and sampling method, it took between 80 to 560 annotated samples to achieve mean average and root mean squared error below 0.01. Results also show that our weighted fitting method outperformed the baseline un-weighted method (p < 0.05). CONCLUSIONS: This paper describes a simple and effective sample size prediction algorithm that conducts weighted fitting of learning curves. The algorithm outperformed an un-weighted algorithm described in previous literature. It can help researchers determine annotation sample size for supervised machine learning.},
	An = {22336388},
	Author = {Figueroa, Rosa L and Zeng-Treitler, Qing and Kandula, Sasikiran and Ngo, Long H},
	Date = {2012/02/15},
	Date-Added = {2020-08-21 09:33:02 -0700},
	Date-Modified = {2020-08-21 09:33:02 -0700},
	Db = {PubMed},
	Doi = {10.1186/1472-6947-12-8},
	Isbn = {1472-6947},
	J2 = {BMC Med Inform Decis Mak},
	Journal = {BMC medical informatics and decision making},
	Keywords = {*Algorithms; Data Interpretation, Statistical; Diagnosis, Computer-Assisted; Humans; *Learning Curve; Models, Statistical; Nonlinear Dynamics; Pattern Recognition, Automated; Predictive Value of Tests; Probability Learning; Problem-Based Learning/*methods; Reproducibility of Results; *Sample Size; Stochastic Processes},
	L2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3307431/},
	La = {eng},
	Month = {02},
	Pages = {8--8},
	Publisher = {BioMed Central},
	Title = {Predicting sample size required for classification performance},
	Ty = {JOUR},
	U1 = {22336388{$[$}pmid{$]$}},
	U2 = {PMC3307431{$[$}pmcid{$]$}},
	U4 = {1472-6947-12-8{$[$}PII{$]$}},
	Url = {https://pubmed.ncbi.nlm.nih.gov/22336388},
	Volume = {12},
	Year = {2012},
	Bdsk-Url-1 = {https://pubmed.ncbi.nlm.nih.gov/22336388},
	Bdsk-Url-2 = {https://doi.org/10.1186/1472-6947-12-8}}

@article{Li:2017aa,
	Author = {Li, Wenshuai and Zhang, Xu and Lu, Xingyu and You, Lei and Song, Yanqun and Luo, Zhongguang and Zhang, Jun and Nie, Ji and Zheng, Wanwei and Xu, Diannan and Wang, Yaping and Dong, Yuanqiang and Yu, Shulin and Hong, Jun and Shi, Jianping and Hao, Hankun and Luo, Fen and Hua, Luchun and Wang, Peng and Qian, Xiaoping and Yuan, Fang and Wei, Lianhuan and Cui, Ming and Zhang, Taiping and Liao, Quan and Dai, Menghua and Liu, Ziwen and Chen, Ge and Meckel, Katherine and Adhikari, Sarbani and Jia, Guifang and Bissonnette, Marc B. and Zhang, Xinxiang and Zhao, Yupei and Zhang, Wei and He, Chuan and Liu, Jie},
	Date = {2017/01/01},
	Date-Added = {2020-08-20 11:45:19 -0700},
	Date-Modified = {2020-08-20 11:45:19 -0700},
	Doi = {10.1101/163204},
	Journal = {bioRxiv},
	Month = {01},
	N2 = {DNA modifications such as 5-methylcytosines (5mC) and 5-hydroxymethylcytosines (5hmC) are epigenetic marks known to affect global gene expression in mammals(1, 2). Given their prevalence in the human genome, close correlation with gene expression, and high chemical stability, these DNA epigenetic marks could serve as ideal biomarkers for cancer diagnosis. Taking advantage of a highly sensitive and selective chemical labeling technology(3), we report here genome-wide 5hmC profiling in circulating cell-free DNA (cfDNA) and in genomic DNA of paired tumor/adjacent tissues collected from a cohort of 90 healthy individuals and 260 patients recently diagnosed with colorectal, gastric, pancreatic, liver, or thyroid cancer. 5hmC was mainly distributed in transcriptionally active regions coincident with open chromatin and permissive histone modifications. Robust cancer-associated 5hmC signatures in cfDNA were identified with specificity for different cancers. 5hmC-based biomarkers of circulating cfDNA demonstrated highly accurate predictive value for patients with colorectal and gastric cancers versus healthy controls, superior to conventional biomarkers, and comparable to 5hmC biomarkers from tissue biopsies. This new strategy could lead to the development of effective blood-based, minimally-invasive cancer diagnosis and prognosis approaches.},
	Pages = {163204},
	Title = {DNA 5-Hydroxymethylcytosines from Cell-free Circulating DNA as Diagnostic Biomarkers for Human Cancers},
	Ty = {JOUR},
	Url = {http://biorxiv.org/content/early/2017/07/13/163204.abstract},
	Year = {2017},
	Bdsk-Url-1 = {http://biorxiv.org/content/early/2017/07/13/163204.abstract},
	Bdsk-Url-2 = {https://doi.org/10.1101/163204}}

@article{Turck:2010aa,
	Abstract = {PURPOSE: Accurate early anticipation of long-term irreversible brain damage during the acute phase of patients with aneurysmal subarachnoid hemorrhage (aSAH) remains difficult. Using a combination of clinical scores together with brain injury-related biomarkers (H-FABP, NDKA, UFD1 and S100beta), this study aimed at developing a multiparameter prognostic panel to facilitate early outcome prediction following aSAH. METHODS: Blood samples of 141 aSAH patients from two separated cohorts (sets of 28 and 113 patients) were prospectively enrolled and analyzed with 14 months of delay. Patients were admitted within 48 h following aSAH onset. A venous blood sample was withdrawn within 12 h after admission. H-FABP, NDKA, UFD1, S100beta and troponin I levels were determined using classical immunoassays. The World Federation of Neurological Surgeons (WFNS) at admission and the Glasgow Outcome Score (GOS) at 6 months were evaluated. RESULTS: In the two cohorts, blood concentration of H-FABP, S100beta and troponin I at admission significantly predicted unfavorable outcome (GOS 1-2-3). A multivariate analysis identified a six-parameter panel, including WFNS, H-FABP, S100beta, troponin I, NDKA and UFD-1; when at least three of these parameters were simultaneously above cutoff values, prediction of unfavorable outcome reached around 70% sensitivity in both cohorts for 100% specificity. CONCLUSION: The use of this panel, including four brain injury-related proteins, one cardiac marker and a clinical score, could be a valuable tool to identify aSAH patients at risk of poor outcome.},
	Address = {Biomedical Proteomics Research Group, Department of Structural Biology and Bioinformatics, Medical University Centre, DBSB/CMU, Rue Michel Servet, 1, 1211 Geneva 4, Switzerland. natacha.turck@unige.ch},
	Author = {Turck, Natacha and Vutskits, Laszlo and Sanchez-Pena, Paola and Robin, Xavier and Hainard, Alexandre and Gex-Fabry, Marianne and Fouda, Catherine and Bassem, Hadiji and Mueller, Markus and Lisacek, Fr{\'e}d{\'e}rique and Puybasset, Louis and Sanchez, Jean-Charles},
	Crdt = {2009/09/18 06:00},
	Date = {2010 Jan},
	Date-Added = {2020-08-20 10:09:03 -0700},
	Date-Modified = {2020-08-20 10:09:03 -0700},
	Dcom = {20100420},
	Dep = {20090917},
	Doi = {10.1007/s00134-009-1641-y},
	Edat = {2009/09/18 06:00},
	Issn = {1432-1238 (Electronic); 0342-4642 (Linking)},
	Jid = {7704851},
	Journal = {Intensive Care Med},
	Jt = {Intensive care medicine},
	Language = {eng},
	Lid = {10.1007/s00134-009-1641-y {$[$}doi{$]$}},
	Lr = {20191210},
	Mh = {Acute Disease; Adaptor Proteins, Vesicular Transport; Aged; Brain Damage, Chronic/epidemiology/etiology; Carrier Proteins/metabolism; Enzyme-Linked Immunosorbent Assay; Fatty Acids/*metabolism; Female; France; Heart/*physiology; Humans; Male; Middle Aged; NM23 Nucleoside Diphosphate Kinases/*metabolism; Nerve Growth Factors/*blood; Neurosurgical Procedures; *Outcome Assessment, Health Care; Predictive Value of Tests; Prognosis; Prospective Studies; Proteins/*metabolism; S100 Calcium Binding Protein beta Subunit; S100 Proteins/*blood; Subarachnoid Hemorrhage/complications/*diagnosis/surgery; Troponin I/*blood},
	Mhda = {2010/04/21 06:00},
	Month = {Jan},
	Number = {1},
	Own = {NLM},
	Pages = {107--115},
	Phst = {2009/01/28 00:00 {$[$}received{$]$}; 2009/07/30 00:00 {$[$}accepted{$]$}; 2009/07/30 00:00 {$[$}revised{$]$}; 2009/09/18 06:00 {$[$}entrez{$]$}; 2009/09/18 06:00 {$[$}pubmed{$]$}; 2010/04/21 06:00 {$[$}medline{$]$}},
	Pl = {United States},
	Pmid = {19760205},
	Pst = {ppublish},
	Pt = {Journal Article; Research Support, Non-U.S. Gov't},
	Rn = {0 (Adaptor Proteins, Vesicular Transport); 0 (Carrier Proteins); 0 (Fatty Acids); 0 (NM23 Nucleoside Diphosphate Kinases); 0 (Nerve Growth Factors); 0 (Proteins); 0 (S100 Calcium Binding Protein beta Subunit); 0 (S100 Proteins); 0 (Troponin I); 0 (UFD1 protein, human)},
	Sb = {IM},
	Status = {MEDLINE},
	Title = {A multiparameter panel method for outcome prediction following aneurysmal subarachnoid hemorrhage.},
	Volume = {36},
	Year = {2010},
	Bdsk-Url-1 = {https://doi.org/10.1007/s00134-009-1641-y}}

@article{Pepe:2009aa,
	Abstract = {The receiver operating characteristic (ROC) curve displays the capacity of a marker or diagnostic test to discriminate between two groups of subjects, cases versus controls. We present a comprehensive suite of Stata commands for performing ROC analysis. Non-parametric, semiparametric and parametric estimators are calculated. Comparisons between curves are based on the area or partial area under the ROC curve. Alternatively pointwise comparisons between ROC curves or inverse ROC curves can be made. Options to adjust these analyses for covariates, and to perform ROC regression are described in a companion article. We use a unified framework by representing the ROC curve as the distribution of the marker in cases after standardizing it to the control reference distribution.},
	An = {20161343},
	Author = {Pepe, Margaret and Longton, Gary and Janes, Holly},
	Date = {2009/03/01},
	Date-Added = {2020-08-20 10:08:51 -0700},
	Date-Modified = {2020-08-20 10:08:51 -0700},
	Db = {PubMed},
	Isbn = {1536-867X},
	J2 = {Stata J},
	Journal = {The Stata journal},
	L2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2774909/},
	La = {eng},
	Month = {03},
	Number = {1},
	Pages = {1--1},
	Title = {Estimation and Comparison of Receiver Operating Characteristic Curves},
	Ty = {JOUR},
	U1 = {20161343{$[$}pmid{$]$}},
	U2 = {PMC2774909{$[$}pmcid{$]$}},
	Url = {https://pubmed.ncbi.nlm.nih.gov/20161343},
	Volume = {9},
	Year = {2009},
	Bdsk-Url-1 = {https://pubmed.ncbi.nlm.nih.gov/20161343}}

@article{Venkatraman:2000aa,
	Annote = {doi: 10.1111/j.0006-341X.2000.01134.x},
	Author = {Venkatraman, E. S.},
	Booktitle = {Biometrics},
	Da = {2000/12/01},
	Date = {2000/12/01},
	Date-Added = {2020-08-20 10:08:42 -0700},
	Date-Modified = {2020-08-20 10:08:42 -0700},
	Doi = {10.1111/j.0006-341X.2000.01134.x},
	Isbn = {0006-341X},
	Journal = {Biometrics},
	Journal1 = {Biometrics},
	Keywords = {Diagnostic test; Permutation test; Receiver operating characteristic curves},
	M3 = {doi: 10.1111/j.0006-341X.2000.01134.x},
	Month = {2020/08/19},
	N2 = {Summary. We developed a permutation test in our earlier paper (Venkatraman and Begg, 1996, Biometrika83, 835?848) to test the equality of receiver operating characteristic curves based on continuous paired data. Here we extend the underlying concepts to develop a permutation test for continuous unpaired data, and we study its properties through simulations.},
	Number = {4},
	Pages = {1134--1138},
	Publisher = {John Wiley \& Sons, Ltd},
	Title = {A Permutation Test to Compare Receiver Operating Characteristic Curves},
	Ty = {JOUR},
	Url = {https://doi.org/10.1111/j.0006-341X.2000.01134.x},
	Volume = {56},
	Year = {2000},
	Year1 = {2000},
	Bdsk-Url-1 = {https://doi.org/10.1111/j.0006-341X.2000.01134.x}}

@article{Moise:1988aa,
	Annote = {doi: 10.1080/03610928808829727},
	Author = {Moise, Alain and Clement, Bernard and Raissis, Marios},
	Booktitle = {Communications in Statistics - Theory and Methods},
	Da = {1988/01/01},
	Date = {1988/01/01},
	Date-Added = {2020-08-20 10:08:36 -0700},
	Date-Modified = {2020-08-20 10:08:36 -0700},
	Doi = {10.1080/03610928808829727},
	Isbn = {0361-0926},
	Journal = {Communications in Statistics - Theory and Methods},
	Journal1 = {Communications in Statistics - Theory and Methods},
	M3 = {doi: 10.1080/03610928808829727},
	Month = {01},
	Number = {6},
	Pages = {1985--2003},
	Publisher = {Taylor \& Francis},
	Title = {A test for crossing receiver operating characteristic (roc) curves},
	Ty = {JOUR},
	Url = {https://doi.org/10.1080/03610928808829727},
	Volume = {17},
	Year = {1988},
	Year1 = {1988},
	Bdsk-Url-1 = {https://doi.org/10.1080/03610928808829727}}

@article{VENKATRAMAN:1996aa,
	Abstract = {A distribution-free permutation test procedure is proposed for comparing receiver operating characteristic curves based on continuous data from a paired design. The method tests the hypothesis that the two curves are identical for all operating points, unlike previously proposed methods which test the equivalence of the areas under the curves. The new test is shown by simulation to have very similar operating characteristics to the standard method based on comparisons of the areas when the curves are parallel, but markedly superior power when the curves cross, that is when the curves are different but have similar areas. The prospects of generalising the approach to unpaired experiments and to comparisons of ordinal rating data are discussed.},
	Author = {VENKATRAMAN, E. S. and BEGG, COLIN B.},
	Date-Added = {2020-08-20 10:08:21 -0700},
	Date-Modified = {2020-08-20 10:08:21 -0700},
	Doi = {10.1093/biomet/83.4.835},
	Isbn = {0006-3444},
	Journal = {Biometrika},
	Journal1 = {Biometrika},
	Month = {8/19/2020},
	Number = {4},
	Pages = {835--848},
	Title = {A distribution-free procedure for comparing receiver operating characteristic curves from a paired experiment},
	Ty = {JOUR},
	Url = {https://doi.org/10.1093/biomet/83.4.835},
	Volume = {83},
	Year = {1996},
	Year1 = {1996/12/01/},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAWLi4vUmVmcy9TaW1vbl8yMDEzLnJpc08RAYAAAAAAAYAAAgAABk1hYyBIRAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////w5TaW1vbl8yMDEzLnJpcwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAEAAgAACiBjdQAAAAAAAAAAAAAAAAAEUmVmcwACAEwvOlVzZXJzOmZjb2xsaW46RG9jdW1lbnRzOlByb2plY3RzOlJzdHVmZjpIQ0M1aG1DRXhwbG9yZTpSZWZzOlNpbW9uXzIwMTMucmlzAA4AHgAOAFMAaQBtAG8AbgBfADIAMAAxADMALgByAGkAcwAPAA4ABgBNAGEAYwAgAEgARAASAEpVc2Vycy9mY29sbGluL0RvY3VtZW50cy9Qcm9qZWN0cy9Sc3R1ZmYvSENDNWhtQ0V4cGxvcmUvUmVmcy9TaW1vbl8yMDEzLnJpcwATAAEvAAAVAAIADv//AAAACAANABoAJAA9AAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAcE=},
	Bdsk-Url-1 = {https://doi.org/10.1093/biomet/83.4.835}}

@article{Braun:2007aa,
	Abstract = {We develop a permutation test for assessing a difference in the areas under the curve (AUCs) in a paired setting where both modalities are given to each diseased and nondiseased subject. We propose that permutations be made between subjects specifically by shuffling the diseased/nondiseased labels of the subjects within each modality. As these permutations are made within modality, the permutation test is valid even if both modalities are measured on different scales. We show that our permutation test is a sign test for the symmetry of an underlying discrete distribution whose size remains valid under the assumption of equal AUCs. We demonstrate the operating characteristics of our test via simulation and show that our test is equal in power to a permutation test recently proposed by Bandos and others (2005).},
	Author = {Braun, Thomas M. and Alonzo, Todd A.},
	Date-Added = {2020-08-20 10:08:13 -0700},
	Date-Modified = {2020-08-20 10:08:13 -0700},
	Doi = {10.1093/biostatistics/kxm036},
	Isbn = {1465-4644},
	Journal = {Biostatistics},
	Journal1 = {Biostatistics},
	Month = {8/19/2020},
	Number = {2},
	Pages = {364--372},
	Title = {A modified sign test for comparing paired ROC curves},
	Ty = {JOUR},
	Url = {https://doi.org/10.1093/biostatistics/kxm036},
	Volume = {9},
	Year = {2007},
	Year1 = {2007/10/08/},
	Bdsk-Url-1 = {https://doi.org/10.1093/biostatistics/kxm036}}

@article{Bandos:2005aa,
	Annote = {doi: 10.1002/sim.2149},
	Author = {Bandos, Andriy I. and Rockette, Howard E. and Gur, David},
	Booktitle = {Statistics in Medicine},
	Da = {2005/09/30},
	Date = {2005/09/30},
	Date-Added = {2020-08-20 10:08:04 -0700},
	Date-Modified = {2020-08-20 10:08:04 -0700},
	Doi = {10.1002/sim.2149},
	Isbn = {0277-6715},
	Journal = {Statistics in Medicine},
	Journal1 = {Statistics in Medicine},
	Journal2 = {Statist. Med.},
	Keywords = {non-parametric procedure; permutation test; receiver operating characteristic (ROC) curve; paired design},
	M3 = {doi: 10.1002/sim.2149},
	Month = {2020/08/19},
	N2 = {Abstract The area under the receiver operating characteristic (ROC) curve (AUC) is a widely accepted summary index of the overall performance of diagnostic procedures and the difference between AUCs is often used when comparing two diagnostic systems. We developed an exact non-parametric statistical procedure for comparing two ROC curves in paired design settings. The test which is based on all permutations of the subject specific rank ratings is formally a test for equality of ROC curves that is sensitive to the alternatives of AUC difference. The operating characteristics of the proposed test were evaluated using extensive simulations over a wide range of parameters. The proposed procedure can be easily implemented in experimental ROC data sets. For small samples and for underlying parameters that are common in experimental studies in diagnostic imaging the test possesses good operating characteristics and is more powerful than the conventional non-parametric procedure for AUC comparisons. We also derived an asymptotic version of the test which uses an exact estimate of the variance in the permutation space and provides a good approximation even when the sample sizes are small. This asymptotic procedure is a simple and precise approximation to the exact test and is useful for large sample sizes where the exact test may be computationally burdensome. Copyright ? 2005 John Wiley \& Sons, Ltd.},
	Number = {18},
	Pages = {2873--2893},
	Publisher = {John Wiley \& Sons, Ltd},
	Title = {A permutation test sensitive to differences in areas for comparing ROC curves from a paired design},
	Ty = {JOUR},
	Url = {https://doi.org/10.1002/sim.2149},
	Volume = {24},
	Year = {2005},
	Year1 = {2005},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxApLi4vLi4vSENDNWhtQ0FuYWx5c2lzL1JlZnMvTW9pc2VfMTk4NS5yaXNPEQGEAAAAAAGEAAIAAAZNYWMgSEQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8OTW9pc2VfMTk4NS5yaXMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAACAAMAAAogY3UAAAAAAAAAAAAAAAAABFJlZnMAAgBNLzpVc2VyczpmY29sbGluOkRvY3VtZW50czpQcm9qZWN0czpSc3R1ZmY6SENDNWhtQ0FuYWx5c2lzOlJlZnM6TW9pc2VfMTk4NS5yaXMAAA4AHgAOAE0AbwBpAHMAZQBfADEAOQA4ADUALgByAGkAcwAPAA4ABgBNAGEAYwAgAEgARAASAEtVc2Vycy9mY29sbGluL0RvY3VtZW50cy9Qcm9qZWN0cy9Sc3R1ZmYvSENDNWhtQ0FuYWx5c2lzL1JlZnMvTW9pc2VfMTk4NS5yaXMAABMAAS8AABUAAgAO//8AAAAIAA0AGgAkAFAAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAB2A==},
	Bdsk-Url-1 = {https://doi.org/10.1002/sim.2149}}

@article{Hanley:1983aa,
	Abstract = {Receiver operating characteristic (ROC) curves are used to describe and compare the performance of diagnostic technology and diagnostic algorithms. This paper refines the statistical comparison of the areas under two ROC curves derived from the same set of patients by taking into account the correlation between the areas that is induced by the paired nature of the data. The correspondence between the area under an ROC curve and the Wilcoxon statistic is used and underlying Gaussian distributions (binormal) are assumed to provide a table that converts the observed correlations in paired ratings of images into a correlation between the two ROC areas. This between-area correlation can be used to reduce the standard error (uncertainty) about the observed difference in areas. This correction for pairing, analogous to that used in the paired t-test, can produce a considerable increase in the statistical sensitivity (power) of the comparison. For studies involving multiple readers, this method provides a measure of a component of the sampling variation that is otherwise difficult to obtain.},
	Annote = {doi: 10.1148/radiology.148.3.6878708},
	Author = {Hanley, J A and McNeil, B J},
	Booktitle = {Radiology},
	Da = {1983/09/01},
	Date = {1983/09/01},
	Date-Added = {2020-08-20 10:07:20 -0700},
	Date-Modified = {2020-08-20 10:07:20 -0700},
	Doi = {10.1148/radiology.148.3.6878708},
	Isbn = {0033-8419},
	Journal = {Radiology},
	Journal1 = {Radiology},
	M3 = {doi: 10.1148/radiology.148.3.6878708},
	Month = {2020/08/19},
	N2 = {Receiver operating characteristic (ROC) curves are used to describe and compare the performance of diagnostic technology and diagnostic algorithms. This paper refines the statistical comparison of the areas under two ROC curves derived from the same set of patients by taking into account the correlation between the areas that is induced by the paired nature of the data. The correspondence between the area under an ROC curve and the Wilcoxon statistic is used and underlying Gaussian distributions (binormal) are assumed to provide a table that converts the observed correlations in paired ratings of images into a correlation between the two ROC areas. This between-area correlation can be used to reduce the standard error (uncertainty) about the observed difference in areas. This correction for pairing, analogous to that used in the paired t-test, can produce a considerable increase in the statistical sensitivity (power) of the comparison. For studies involving multiple readers, this method provides a measure of a component of the sampling variation that is otherwise difficult to obtain.},
	Number = {3},
	Pages = {839--843},
	Publisher = {Radiological Society of North America},
	Title = {A method of comparing the areas under receiver operating characteristic curves derived from the same cases.},
	Ty = {JOUR},
	Url = {https://doi.org/10.1148/radiology.148.3.6878708},
	Volume = {148},
	Year = {1983},
	Year1 = {1983},
	Bdsk-Url-1 = {https://doi.org/10.1148/radiology.148.3.6878708}}

@article{Streiner:2007aa,
	Abstract = {It is often necessary to dichotomize a continuous scale to separate respondents into normal and abnormal groups. However, because the distributions of the scores in these 2 groups most often overlap, any cut point that is chosen will result in 2 types of errors: false negatives (that is, abnormal cases judged to be normal) and false positives (that is, normal cases placed in the abnormal group). Changing the cut point will alter the numbers of erroneous judgments but will not eliminate the problem. A technique called receiver operating characteristic (ROC) curves allows us to determine the ability ofa test to discriminate between groups, to choose the optimal cut point, and to compare the performance of 2 or more tests. We discuss how to calculate and compareROC curves and the factors that must be considered in choosing an optimal cut point.},
	Address = {Kunin-Lunenfeld Applied Research Unit, Baycrest Centre, Toronto, Ontario. dstreiner@klaru-baycrest.on.ca},
	Author = {Streiner, David L and Cairney, John},
	Crdt = {2007/03/23 09:00},
	Date = {2007 Feb},
	Date-Added = {2020-08-19 14:24:49 -0700},
	Date-Modified = {2020-08-19 14:24:49 -0700},
	Dcom = {20070509},
	Doi = {10.1177/070674370705200210},
	Edat = {2007/03/23 09:00},
	Issn = {0706-7437 (Print); 0706-7437 (Linking)},
	Jid = {7904187},
	Journal = {Can J Psychiatry},
	Jt = {Canadian journal of psychiatry. Revue canadienne de psychiatrie},
	Language = {eng},
	Lr = {20191210},
	Mh = {Humans; Mental Disorders/diagnosis/epidemiology; Psychology/*methods/*statistics \& numerical data; *ROC Curve; Sensitivity and Specificity},
	Mhda = {2007/05/10 09:00},
	Month = {Feb},
	Number = {2},
	Own = {NLM},
	Pages = {121--128},
	Phst = {2007/03/23 09:00 {$[$}pubmed{$]$}; 2007/05/10 09:00 {$[$}medline{$]$}; 2007/03/23 09:00 {$[$}entrez{$]$}},
	Pl = {United States},
	Pmid = {17375868},
	Pst = {ppublish},
	Pt = {Evaluation Study; Journal Article},
	Sb = {IM},
	Status = {MEDLINE},
	Title = {What's under the ROC? An introduction to receiver operating characteristics curves.},
	Volume = {52},
	Year = {2007},
	Bdsk-Url-1 = {https://doi.org/10.1177/070674370705200210}}

@article{Jiang:1996aa,
	Abstract = {PURPOSE: Area under a receiver operating characteristic (ROC) curve (Az) is widely used as an index of diagnostic performance. However, Az is not a meaningful summary of clinical diagnostic performance when high sensitivity must be maintained clinically. The authors developed a new ROC partial area index, which measures clinical diagnostic performance more meaningfully in such situations, to summarize an ROC curve in only a high-sensitivity region. MATERIALS AND METHODS: The mathematical formation of the partial area index was derived from the conventional binormal model. Statistical tests of apparent differences in this index were formulated analogous to that of Az. One common statistical test involving the partial area index was validated by computer simulations under realistic conditions. RESULTS: An example in mammography illustrates a situation in which the partial area index is more meaningful than Az in measuring clinical diagnostic performance. CONCLUSION: The partial area index can be used as a more meaningful alternative to the conventional Az index for highly sensitive diagnostic tests.},
	Annote = {doi: 10.1148/radiology.201.3.8939225},
	Author = {Jiang, Y and Metz, C E and Nishikawa, R M},
	Booktitle = {Radiology},
	Da = {1996/12/01},
	Date = {1996/12/01},
	Date-Added = {2020-08-19 14:24:45 -0700},
	Date-Modified = {2020-08-19 14:24:45 -0700},
	Doi = {10.1148/radiology.201.3.8939225},
	Isbn = {0033-8419},
	Journal = {Radiology},
	Journal1 = {Radiology},
	M3 = {doi: 10.1148/radiology.201.3.8939225},
	Month = {2020/08/19},
	N2 = {PURPOSE: Area under a receiver operating characteristic (ROC) curve (Az) is widely used as an index of diagnostic performance. However, Az is not a meaningful summary of clinical diagnostic performance when high sensitivity must be maintained clinically. The authors developed a new ROC partial area index, which measures clinical diagnostic performance more meaningfully in such situations, to summarize an ROC curve in only a high-sensitivity region. MATERIALS AND METHODS: The mathematical formation of the partial area index was derived from the conventional binormal model. Statistical tests of apparent differences in this index were formulated analogous to that of Az. One common statistical test involving the partial area index was validated by computer simulations under realistic conditions. RESULTS: An example in mammography illustrates a situation in which the partial area index is more meaningful than Az in measuring clinical diagnostic performance. CONCLUSION: The partial area index can be used as a more meaningful alternative to the conventional Az index for highly sensitive diagnostic tests.},
	Number = {3},
	Pages = {745--750},
	Publisher = {Radiological Society of North America},
	Title = {A receiver operating characteristic partial area index for highly sensitive diagnostic tests.},
	Ty = {JOUR},
	Url = {https://doi.org/10.1148/radiology.201.3.8939225},
	Volume = {201},
	Year = {1996},
	Year1 = {1996},
	Bdsk-Url-1 = {https://doi.org/10.1148/radiology.201.3.8939225}}

@article{McClish:1989aa,
	Abstract = {The area under the ROC curve is a common index summarizing the information contained in the curve. When comparing two ROC curves, though, problems arise when interest does not lie in the entire range of false-positive rates (and hence the entire area). Numerical integration is suggested for evaluating the area under a portion of the ROC curve. Variance estimates are derived. The method is applicable for either continuous or rating scale binormal data, from independent or dependent samples. An example is presented which looks at rating scale data of computed tomographic scans of the head with and without concomitant use of clinical history. The areas under the two ROC curves over an a priori range of false-positive rates are examined, as well as the areas under the two curves at a specific point.},
	Address = {Department of Biostatistics, Medical College of Virginia, Richmond 23298.},
	Author = {McClish, D K},
	Crdt = {1989/07/01 00:00},
	Date = {1989 Jul-Sep},
	Date-Added = {2020-08-19 14:24:39 -0700},
	Date-Modified = {2020-08-19 14:24:39 -0700},
	Dcom = {19890908},
	Doi = {10.1177/0272989X8900900307},
	Edat = {1989/07/01 00:00},
	Issn = {0272-989X (Print); 0272-989X (Linking)},
	Jid = {8109073},
	Journal = {Med Decis Making},
	Jt = {Medical decision making : an international journal of the Society for Medical Decision Making},
	Language = {eng},
	Lr = {20170214},
	Mh = {Computer Simulation; *Decision Support Techniques; False Positive Reactions; Humans; *ROC Curve},
	Mhda = {1989/07/01 00:01},
	Month = {Jul-Sep},
	Number = {3},
	Own = {NLM},
	Pages = {190--195},
	Phst = {1989/07/01 00:00 {$[$}pubmed{$]$}; 1989/07/01 00:01 {$[$}medline{$]$}; 1989/07/01 00:00 {$[$}entrez{$]$}},
	Pl = {United States},
	Pmid = {2668680},
	Pst = {ppublish},
	Pt = {Journal Article},
	Sb = {IM},
	Status = {MEDLINE},
	Title = {Analyzing a portion of the ROC curve.},
	Volume = {9},
	Year = {1989},
	Bdsk-Url-1 = {https://doi.org/10.1177/0272989X8900900307}}

@article{Hanczar:2010aa,
	Abstract = {Motivation: The receiver operator characteristic (ROC) curves are commonly used in biomedical applications to judge the performance of a discriminant across varying decision thresholds. The estimated ROC curve depends on the true positive rate (TPR) and false positive rate (FPR), with the key metric being the area under the curve (AUC). With small samples these rates need to be estimated from the training data, so a natural question arises: How well do the estimates of the AUC, TPR and FPR compare with the true metrics?Results: Through a simulation study using data models and analysis of real microarray data, we show that (i) for small samples the root mean square differences of the estimated and true metrics are considerable; (ii) even for large samples, there is only weak correlation between the true and estimated metrics; and (iii) generally, there is weak regression of the true metric on the estimated metric. For classification rules, we consider linear discriminant analysis, linear support vector machine (SVM) and radial basis function SVM. For error estimation, we consider resubstitution, three kinds of cross-validation and bootstrap. Using resampling, we show the unreliability of some published ROC results.Availability: Companion web site at http://compbio.tgen.org/paper{\_}supp/ROC/roc.htmlContact:edward{\char64}mail.ece.tamu.edu},
	Author = {Hanczar, Blaise and Hua, Jianping and Sima, Chao and Weinstein, John and Bittner, Michael and Dougherty, Edward R.},
	Date-Added = {2020-08-19 14:24:32 -0700},
	Date-Modified = {2020-08-19 14:24:32 -0700},
	Doi = {10.1093/bioinformatics/btq037},
	Isbn = {1367-4803},
	Journal = {Bioinformatics},
	Journal1 = {Bioinformatics},
	Month = {8/19/2020},
	Number = {6},
	Pages = {822--830},
	Title = {Small-sample precision of ROC-related estimates},
	Ty = {JOUR},
	Url = {https://doi.org/10.1093/bioinformatics/btq037},
	Volume = {26},
	Year = {2010},
	Year1 = {2010/02/03/},
	Bdsk-Url-1 = {https://doi.org/10.1093/bioinformatics/btq037}}

@article{Sun:2014aa,
	Abstract = {Among algorithms for comparing the areas under two or more correlated receiver operating characteristic (ROC) curves, DeLong's algorithm is perhaps the most widely used one due to its simplicity of implementation in practice. Unfortunately, however, the time complexity of DeLong's algorithm is of quadratic order (the product of sample sizes), thus making it time-consuming and impractical when the sample sizes are large. Based on an equivalent relationship between the Heaviside function and mid-ranks of samples, we improve DeLong's algorithm by reducing the order of time complexity from quadratic down to linearithmic (the product of sample size and its logarithm). Monte Carlo simulations verify the computational efficiency of our algorithmic findings in this work.},
	Author = {X. Sun and W. Xu},
	Booktitle = {IEEE Signal Processing Letters},
	Date-Added = {2020-08-19 14:11:34 -0700},
	Date-Modified = {2020-08-19 14:11:34 -0700},
	Doi = {10.1109/LSP.2014.2337313},
	Isbn = {1558-2361},
	Journal = {IEEE Signal Processing Letters},
	Journal1 = {IEEE Signal Processing Letters},
	Keywords = {computational complexity; correlation methods; Monte Carlo methods; DeLong algorithm; areas-under-correlated receiver characteristic curves; ROC; time complexity order reduction; equivalent relationship; Monte Carlo simulations; computational efficiency; Signal processing algorithms; Time complexity; Vectors; Receivers; Manganese; Sun; Monte Carlo methods; Area under the curve (AUC); DeLong's method; mid-rank; receiver operating characteristic (ROC)},
	Number = {11},
	Pages = {1389--1393},
	Title = {Fast Implementation of DeLong's Algorithm for Comparing the Areas Under Correlated Receiver Operating Characteristic Curves},
	Ty = {JOUR},
	Vo = {21},
	Volume = {21},
	Year = {2014},
	Year1 = {Nov. 2014},
	Bdsk-Url-1 = {https://doi.org/10.1109/LSP.2014.2337313}}

@article{Robin:2011aa,
	Abstract = {Receiver operating characteristic (ROC) curves are useful tools to evaluate classifiers in biomedical and bioinformatics applications. However, conclusions are often reached through inconsistent use or insufficient statistical analysis. To support researchers in their ROC curves analysis we developed pROC, a package for R and S+ that contains a set of tools displaying, analyzing, smoothing and comparing ROC curves in a user-friendly, object-oriented and flexible interface.},
	Author = {Robin, Xavier and Turck, Natacha and Hainard, Alexandre and Tiberti, Natalia and Lisacek, Fr{\'e}d{\'e}rique and Sanchez, Jean-Charles and M{\"u}ller, Markus},
	Da = {2011/03/17},
	Date-Added = {2020-08-19 14:11:22 -0700},
	Date-Modified = {2020-08-19 14:11:22 -0700},
	Doi = {10.1186/1471-2105-12-77},
	Id = {Robin2011},
	Isbn = {1471-2105},
	Journal = {BMC Bioinformatics},
	Number = {1},
	Pages = {77},
	Title = {pROC: an open-source package for R and S+ to analyze and compare ROC curves},
	Ty = {JOUR},
	Url = {https://doi.org/10.1186/1471-2105-12-77},
	Volume = {12},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAVLi4vUmVmcy9IYXJ0XzIwMTIucmlzTxEBfgAAAAABfgACAAAGTWFjIEhEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////DUhhcnRfMjAxMi5yaXMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAAAQACAAAKIGN1AAAAAAAAAAAAAAAAAARSZWZzAAIASy86VXNlcnM6ZmNvbGxpbjpEb2N1bWVudHM6UHJvamVjdHM6UnN0dWZmOkhDQzVobUNFeHBsb3JlOlJlZnM6SGFydF8yMDEyLnJpcwAADgAcAA0ASABhAHIAdABfADIAMAAxADIALgByAGkAcwAPAA4ABgBNAGEAYwAgAEgARAASAElVc2Vycy9mY29sbGluL0RvY3VtZW50cy9Qcm9qZWN0cy9Sc3R1ZmYvSENDNWhtQ0V4cGxvcmUvUmVmcy9IYXJ0XzIwMTIucmlzAAATAAEvAAAVAAIADv//AAAACAANABoAJAA8AAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAb4=},
	Bdsk-Url-1 = {https://doi.org/10.1186/1471-2105-12-77}}

@article{Hanley:1982aa,
	Abstract = {A representation and interpretation of the area under a receiver operating characteristic (ROC) curve obtained by the "rating" method, or by mathematical predictions based on patient characteristics, is presented. It is shown that in such a setting the area represents the probability that a randomly chosen diseased subject is (correctly) rated or ranked with greater suspicion than a randomly chosen non-diseased subject. Moreover, this probability of a correct ranking is the same quantity that is estimated by the already well-studied nonparametric Wilcoxon statistic. These two relationships are exploited to (a) provide rapid closed-form expressions for the approximate magnitude of the sampling variability, i.e., standard error that one uses to accompany the area under a smoothed ROC curve, (b) guide in determining the size of the sample required to provide a sufficiently reliable estimate of this area, and (c) determine how large sample sizes should be to ensure that one can statistically detect differences in the accuracy of diagnostic techniques.},
	Author = {Hanley, J A and McNeil, B J},
	Crdt = {1982/04/01 00:00},
	Date = {1982 Apr},
	Date-Added = {2020-08-19 13:47:27 -0700},
	Date-Modified = {2020-08-19 13:47:27 -0700},
	Dcom = {19820521},
	Doi = {10.1148/radiology.143.1.7063747},
	Edat = {1982/04/01 00:00},
	Issn = {0033-8419 (Print); 0033-8419 (Linking)},
	Jid = {0401260},
	Journal = {Radiology},
	Jt = {Radiology},
	Language = {eng},
	Lr = {20071115},
	Mh = {Evaluation Studies as Topic; Humans; Mathematics; *Models, Theoretical; Statistics as Topic; *Technology, Radiologic},
	Mhda = {1982/04/01 00:01},
	Month = {Apr},
	Number = {1},
	Own = {NLM},
	Pages = {29--36},
	Phst = {1982/04/01 00:00 {$[$}pubmed{$]$}; 1982/04/01 00:01 {$[$}medline{$]$}; 1982/04/01 00:00 {$[$}entrez{$]$}},
	Pl = {United States},
	Pmid = {7063747},
	Pst = {ppublish},
	Pt = {Journal Article; Research Support, Non-U.S. Gov't},
	Sb = {AIM; IM},
	Status = {MEDLINE},
	Title = {The meaning and use of the area under a receiver operating characteristic (ROC) curve.},
	Volume = {143},
	Year = {1982},
	Bdsk-Url-1 = {https://doi.org/10.1148/radiology.143.1.7063747}}

@article{Delgado:2019aa,
	Author = {Delgado, Rosario and Tibau, Xavier-Andoni},
	Date = {2019/09/26},
	Date-Added = {2020-08-18 18:04:05 -0700},
	Date-Modified = {2020-08-18 18:04:05 -0700},
	Journal = {PLOS ONE},
	Journal1 = {PLOS ONE},
	M3 = {doi:10.1371/journal.pone.0222916},
	Month = {09},
	N2 = {We show that Cohen's Kappa and Matthews Correlation Coefficient (MCC), both extended and contrasted measures of performance in multi-class classification, are correlated in most situations, albeit can differ in others. Indeed, although in the symmetric case both match, we consider different unbalanced situations in which Kappa exhibits an undesired behaviour, i.e. a worse classifier gets higher Kappa score, differing qualitatively from that of MCC. The debate about the incoherence in the behaviour of Kappa revolves around the convenience, or not, of using a relative metric, which makes the interpretation of its values difficult. We extend these concerns by showing that its pitfalls can go even further. Through experimentation, we present a novel approach to this topic. We carry on a comprehensive study that identifies an scenario in which the contradictory behaviour among MCC and Kappa emerges. Specifically, we find out that when there is a decrease to zero of the entropy of the elements out of the diagonal of the confusion matrix associated to a classifier, the discrepancy between Kappa and MCC rise, pointing to an anomalous performance of the former. We believe that this finding disables Kappa to be used in general as a performance measure to compare classifiers.},
	Number = {9},
	Pages = {e0222916--},
	Publisher = {Public Library of Science},
	Title = {Why Cohen's Kappa should be avoided as performance measure in classification},
	Ty = {JOUR},
	Url = {https://doi.org/10.1371/journal.pone.0222916},
	Volume = {14},
	Year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1371/journal.pone.0222916}}

@article{Hastie:1998aa,
	Abstract = {{$[$}We discuss a strategy for polychotomous classification that involves estimating class probabilities for each pair of classes, and then coupling the estimates together. The coupling model is similar to the Bradley-Terry method for paired comparisons. We study the nature of the class probability estimates that arise, and examine the performance of the procedure in real and simulated data sets. Classifiers used include linear discriminants, nearest neighbors, adaptive nonlinear methods and the support vector machine.{$]$}},
	Author = {Hastie, Trevor and Tibshirani, Robert},
	Booktitle = {The Annals of Statistics},
	C1 = {Full publication date: Apr., 1998},
	Date-Added = {2020-08-17 12:14:33 -0700},
	Date-Modified = {2020-08-17 12:14:33 -0700},
	Db = {JSTOR},
	Isbn = {00905364},
	Month = {2020/08/17/},
	Number = {2},
	Pages = {451--471},
	Publisher = {Institute of Mathematical Statistics},
	Title = {Classification by Pairwise Coupling},
	Ty = {JOUR},
	Url = {www.jstor.org/stable/120036},
	Volume = {26},
	Year = {1998},
	Bdsk-Url-1 = {www.jstor.org/stable/120036}}

@article{Cai:2019aa,
	Author = {Cai, Jiabin and Chen, Lei and Zhang, Zhou and Zhang, Xinyu and Lu, Xingyu and Liu, Weiwei and Shi, Guoming and Ge, Yang and Gao, Pingting and Yang, Yuan and Ke, Aiwu and Xiao, Linlin and Dong, Ruizhao and Zhu, Yanjing and Yang, Xuan and Wang, Jiefei and Zhu, Tongyu and Yang, Deping and Huang, Xiaowu and Sui, Chengjun and Qiu, Shuangjian and Shen, Feng and Sun, Huichuan and Zhou, Weiping and Zhou, Jian and Nie, Ji and Zeng, Chang and Stroup, Emily Kunce and Zhang, Xu and Chiu, Brian C-H and Lau, Wan Yee and He, Chuan and Wang, Hongyang and Zhang, Wei and Fan, Jia},
	Date = {2019/07/27},
	Date-Added = {2020-08-11 19:08:19 -0700},
	Date-Modified = {2020-08-11 19:08:19 -0700},
	Doi = {10.1136/gutjnl-2019-318882},
	Journal = {Gut},
	Journal1 = {Gut},
	Month = {07},
	N2 = {Objective The lack of highly sensitive and specific diagnostic biomarkers is a major contributor to the poor outcomes of patients with hepatocellular carcinoma (HCC). We sought to develop a non-invasive diagnostic approach using circulating cell-free DNA (cfDNA) for the early detection of HCC.Design Applying the 5hmC-Seal technique, we obtained genome-wide 5-hydroxymethylcytosines (5hmC) in cfDNA samples from 2554 Chinese subjects: 1204 patients with HCC, 392 patients with chronic hepatitis B virus infection (CHB) or liver cirrhosis (LC) and 958 healthy individuals and patients with benign liver lesions. A diagnostic model for early HCC was developed through case-control analyses using the elastic net regularisation for feature selection.Results The 5hmC-Seal data from patients with HCC showed a genome-wide distribution enriched with liver-derived enhancer marks. We developed a 32-gene diagnostic model that accurately distinguished early HCC (stage 0/A) based on the Barcelona Clinic Liver Cancer staging system from non-HCC (validation set: area under curve (AUC)=88.4{\%}; (95{\%} CI 85.8{\%} to 91.1{\%})), showing superior performance over α-fetoprotein (AFP). Besides detecting patients with early stage or small tumours (eg, ≤2.0 cm) from non-HCC, the 5hmC model showed high capacity for distinguishing early HCC from high risk subjects with CHB or LC history (validation set: AUC=84.6{\%}; (95{\%} CI 80.6{\%} to 88.7{\%})), also significantly outperforming AFP. Furthermore, the 5hmC diagnostic model appeared to be independent from potential confounders (eg, smoking/alcohol intake history).Conclusion We have developed and validated a non-invasive approach with clinical application potential for the early detection of HCC that are still surgically resectable in high risk individuals.},
	Pages = {gutjnl-2019-318882},
	Title = {Genome-wide mapping of 5-hydroxymethylcytosines in circulating cell-free DNA as a non-invasive approach for early detection of hepatocellular carcinoma},
	Ty = {JOUR},
	Url = {http://gut.bmj.com/content/early/2019/07/28/gutjnl-2019-318882.abstract},
	Year = {2019},
	Bdsk-Url-1 = {http://gut.bmj.com/content/early/2019/07/28/gutjnl-2019-318882.abstract},
	Bdsk-Url-2 = {https://doi.org/10.1136/gutjnl-2019-318882}}

@incollection{knitr2014,
	Author = {Yihui Xie},
	Booktitle = {Implementing Reproducible Computational Research},
	Date-Added = {2020-08-11 19:04:19 -0700},
	Date-Modified = {2020-08-11 19:04:19 -0700},
	Editor = {Victoria Stodden and Friedrich Leisch and Roger D. Peng},
	Note = {ISBN 978-1466561595},
	Publisher = {Chapman and Hall/CRC},
	Title = {knitr: A Comprehensive Tool for Reproducible Research in {R}},
	Url = {http://www.crcpress.com/product/isbn/9781466561595},
	Year = {2014},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAsLi4vLi4vSENDNWhtQ0FuYWx5c2lzL1JlZnMvRmlndWVyb2FfMjAxMi5yaXNPEQGOAAAAAAGOAAIAAAZNYWMgSEQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQkQAAf////8RRmlndWVyb2FfMjAxMi5yaXMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAACAAMAAAogY3UAAAAAAAAAAAAAAAAABFJlZnMAAgBQLzpVc2VyczpmY29sbGluOkRvY3VtZW50czpQcm9qZWN0czpSc3R1ZmY6SENDNWhtQ0FuYWx5c2lzOlJlZnM6RmlndWVyb2FfMjAxMi5yaXMADgAkABEARgBpAGcAdQBlAHIAbwBhAF8AMgAwADEAMgAuAHIAaQBzAA8ADgAGAE0AYQBjACAASABEABIATlVzZXJzL2Zjb2xsaW4vRG9jdW1lbnRzL1Byb2plY3RzL1JzdHVmZi9IQ0M1aG1DQW5hbHlzaXMvUmVmcy9GaWd1ZXJvYV8yMDEyLnJpcwATAAEvAAAVAAIADv//AAAACAANABoAJABTAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAeU=},
	Bdsk-Url-1 = {http://www.crcpress.com/product/isbn/9781466561595}}

@book{knitr2015,
	Address = {Boca Raton, Florida},
	Author = {Yihui Xie},
	Date-Added = {2020-08-11 19:04:19 -0700},
	Date-Modified = {2020-08-11 19:04:19 -0700},
	Edition = {2nd},
	Note = {ISBN 978-1498716963},
	Publisher = {Chapman and Hall/CRC},
	Title = {Dynamic Documents with {R} and knitr},
	Url = {https://yihui.org/knitr/},
	Year = {2015},
	Bdsk-Url-1 = {https://yihui.org/knitr/}}

@book{xie2015,
	Address = {Boca Raton, Florida},
	Author = {Yihui Xie},
	Edition = {2nd},
	Note = {ISBN 978-1498716963},
	Publisher = {Chapman and Hall/CRC},
	Title = {Dynamic Documents with {R} and knitr},
	Url = {http://yihui.org/knitr/},
	Year = {2015},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxArLi4vLi4vSENDNWhtQ0FuYWx5c2lzL1JlZnMvSGFubGV5XzE5ODIubmJpYk8RAYwAAAAAAYwAAgAABk1hYyBIRAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////xBIYW5sZXlfMTk4Mi5uYmliAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAIAAwAACiBjdQAAAAAAAAAAAAAAAAAEUmVmcwACAE8vOlVzZXJzOmZjb2xsaW46RG9jdW1lbnRzOlByb2plY3RzOlJzdHVmZjpIQ0M1aG1DQW5hbHlzaXM6UmVmczpIYW5sZXlfMTk4Mi5uYmliAAAOACIAEABIAGEAbgBsAGUAeQBfADEAOQA4ADIALgBuAGIAaQBiAA8ADgAGAE0AYQBjACAASABEABIATVVzZXJzL2Zjb2xsaW4vRG9jdW1lbnRzL1Byb2plY3RzL1JzdHVmZi9IQ0M1aG1DQW5hbHlzaXMvUmVmcy9IYW5sZXlfMTk4Mi5uYmliAAATAAEvAAAVAAIADv//AAAACAANABoAJABSAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAeI=},
	Bdsk-Url-1 = {http://yihui.org/knitr/}}
