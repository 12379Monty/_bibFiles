%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Francois Collin at 2023-11-24 00:14:13 -0800 


%% Saved with string encoding Unicode (UTF-8) 



@inbook{Storey:2011aa,
	address = {Berlin, Heidelberg},
	author = {Storey, John D. },
	booktitle = {International Encyclopedia of Statistical Science},
	date = {2011//},
	date-added = {2023-11-24 00:14:10 -0800},
	date-modified = {2023-11-24 00:14:10 -0800},
	doi = {10.1007/978-3-642-04898-2{\_}248},
	editor = {Lovric, Miodrag},
	id = {Storey2011},
	isbn = {978-3-642-04898-2},
	pages = {504--508},
	publisher = {Springer Berlin Heidelberg},
	title = {False Discovery Rate},
	url = {https://doi.org/10.1007/978-3-642-04898-2_248},
	year = {2011},
	bdsk-url-1 = {https://doi.org/10.1007/978-3-642-04898-2_248},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-642-04898-2%7B%5C_%7D248}}

@article{Benjamini:1995aa,
	abstract = {{$[$}The common approach to the multiplicity problem calls for controlling the familywise error rate (FWER). This approach, though, has faults, and we point out a few. A different approach to problems of multiple significance testing is presented. It calls for controlling the expected proportion of falsely rejected hypotheses-the false discovery rate. This error rate is equivalent to the FWER when all hypotheses are true but is smaller otherwise. Therefore, in problems where the control of the false discovery rate rather than that of the FWER is desired, there is potential for a gain in power. A simple sequential Bonferroni-type procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. The use of the new procedure and the appropriateness of the criterion are illustrated with examples.{$]$}},
	author = {Benjamini, Yoav and Hochberg, Yosef},
	c1 = {Full publication date: 1995},
	date-added = {2023-11-23 23:12:09 -0800},
	date-modified = {2023-11-23 23:12:09 -0800},
	db = {JSTOR},
	isbn = {00359246},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	month = {2023/11/24/},
	number = {1},
	pages = {289--300},
	publisher = {{$[$}Royal Statistical Society, Wiley{$]$}},
	title = {Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing},
	url = {http://www.jstor.org/stable/2346101},
	volume = {57},
	year = {1995},
	bdsk-url-1 = {http://www.jstor.org/stable/2346101}}

@article{Efron:2001aa,
	annote = {doi: 10.1198/016214501753382129},
	author = {Efron, Bradley and Tibshirani, Robert and Storey, John D and Tusher, Virginia},
	date = {2001/12/01},
	date-added = {2023-11-23 23:12:09 -0800},
	date-modified = {2023-11-23 23:12:09 -0800},
	doi = {10.1198/016214501753382129},
	isbn = {0162-1459},
	journal = {Journal of the American Statistical Association},
	journal1 = {Journal of the American Statistical Association},
	journal2 = {Journal of the American Statistical Association},
	month = {12},
	number = {456},
	pages = {1151--1160},
	publisher = {Taylor \& Francis},
	title = {Empirical Bayes Analysis of a Microarray Experiment},
	type = {doi: 10.1198/016214501753382129},
	url = {https://doi.org/10.1198/016214501753382129},
	volume = {96},
	year = {2001},
	year1 = {2001},
	bdsk-url-1 = {https://doi.org/10.1198/016214501753382129}}

@article{Fox:2006aa,
	abstract = {Determining whether a gene is differentially expressed in two different samples remains an important statistical problem. Prior work in this area has featured the use of t-tests with pooled estimates of the sample variance based on similarly expressed genes. These methods do not display consistent behavior across the entire range of pooling and can be biased when the prior hyperparameters are specified heuristically.},
	author = {Fox, Richard J. and Dimmic, Matthew W.},
	date = {2006/03/10},
	date-added = {2023-11-23 23:12:09 -0800},
	date-modified = {2023-11-23 23:12:09 -0800},
	doi = {10.1186/1471-2105-7-126},
	id = {Fox2006},
	isbn = {1471-2105},
	journal = {BMC Bioinformatics},
	number = {1},
	pages = {126},
	title = {A two-sample Bayesian t-test for microarray data},
	url = {https://doi.org/10.1186/1471-2105-7-126},
	volume = {7},
	year = {2006},
	bdsk-url-1 = {https://doi.org/10.1186/1471-2105-7-126}}

@article{Storey:2002aa,
	author = {Storey, John},
	date = {2002/08/01},
	date-added = {2023-11-23 23:12:09 -0800},
	date-modified = {2023-11-23 23:12:09 -0800},
	doi = {10.1111/1467-9868.00346},
	journal = {Journal of the Royal Statistical Society Series B},
	month = {08},
	pages = {479--498},
	title = {A Direct Approach to False Discovery Rates},
	volume = {64},
	year = {2002},
	bdsk-url-1 = {https://doi.org/10.1111/1467-9868.00346}}

@article{Storey:2003aa,
	abstract = {With the increase in genomewide experiments and the sequencing of multiple genomes, the analysis of large data sets has become commonplace in biology. It is often the case that thousands of features in a genomewide data set are tested against some null hypothesis, where a number of features are expected to be significant. Here we propose an approach to measuring statistical significance in these genomewide studies based on the concept of the false discovery rate. This approach offers a sensible balance between the number of true and false positives that is automatically calibrated and easily interpreted. In doing so, a measure of statistical significance called the q value is associated with each tested feature. The q value is similar to the well known p value, except it is a measure of significance in terms of the false discovery rate rather than the false positive rate. Our approach avoids a flood of false positive results, while offering a more liberal criterion than what has been used in genome scans for linkage.},
	annote = {doi: 10.1073/pnas.1530509100},
	author = {Storey, John D. and Tibshirani, Robert},
	date = {2003/08/05},
	date-added = {2023-11-23 23:12:09 -0800},
	date-modified = {2023-11-23 23:12:09 -0800},
	doi = {10.1073/pnas.1530509100},
	journal = {Proceedings of the National Academy of Sciences},
	journal1 = {Proceedings of the National Academy of Sciences},
	journal2 = {Proceedings of the National Academy of Sciences},
	month = {2023/11/23},
	n2 = {With the increase in genomewide experiments and the sequencing of multiple genomes, the analysis of large data sets has become commonplace in biology. It is often the case that thousands of features in a genomewide data set are tested against some null hypothesis, where a number of features are expected to be significant. Here we propose an approach to measuring statistical significance in these genomewide studies based on the concept of the false discovery rate. This approach offers a sensible balance between the number of true and false positives that is automatically calibrated and easily interpreted. In doing so, a measure of statistical significance called the q value is associated with each tested feature. The q value is similar to the well known p value, except it is a measure of significance in terms of the false discovery rate rather than the false positive rate. Our approach avoids a flood of false positive results, while offering a more liberal criterion than what has been used in genome scans for linkage.},
	number = {16},
	pages = {9440--9445},
	publisher = {Proceedings of the National Academy of Sciences},
	title = {Statistical significance for genomewide studies},
	type = {doi: 10.1073/pnas.1530509100},
	url = {https://doi.org/10.1073/pnas.1530509100},
	volume = {100},
	year = {2003},
	year1 = {2003},
	bdsk-url-1 = {https://doi.org/10.1073/pnas.1530509100}}

@article{10.3389/fevo.2019.00486,
	abstract = {Second-generation p-values (SGPVs) are a novel and intuitive extension of classical p-values that better summarize the degree to which data support scientific hypotheses. SGPVs measure the overlap between an uncertainty interval for the parameter of interest and an interval null hypothesis that represents the set of null and practically null hypotheses. Although SGPVs are always in the unit interval, they are not formal probabilities. Rather, SGPVs are summary measures of when the data are compatible with null hypotheses (SGPV = 1), compatible with alternative hypotheses (SGPV = 0), or inconclusive (0 < SGPV < 1). Because second-generation p-values differentiate between inconclusive and null results, their Type I Error rate converges to zero along with the Type II Error rate. The SGPV approach is also inferentially agnostic: it can be applied to any uncertainty interval about a parameter of interest such as confidence intervals, likelihood support intervals, and Bayesian highest posterior density intervals. This paper revisits the motivation for using SGPVs and explores their long-run behavior under regularized models that provide shrinkage on point estimates. While shrinkage often results in a more desirable bias-variance trade-off, the impact of shrinkage on the error rates of SGPVs is not well-understood. Through extensive simulations, we find that SPGVs based on shrunken estimates retain the desirable error rate behavior of SGPVs that we observe in classical models---albeit with a minor loss of power---while also retaining the benefits of bias-variance tradeoff.},
	author = {Stewart, Thomas G. and Blume, Jeffrey D.},
	date-added = {2023-11-23 23:11:51 -0800},
	date-modified = {2023-11-23 23:11:51 -0800},
	doi = {10.3389/fevo.2019.00486},
	issn = {2296-701X},
	journal = {Frontiers in Ecology and Evolution},
	title = {Second-Generation P-Values, Shrinkage, and Regularized Models},
	url = {https://www.frontiersin.org/articles/10.3389/fevo.2019.00486},
	volume = {7},
	year = {2019},
	bdsk-url-1 = {https://www.frontiersin.org/articles/10.3389/fevo.2019.00486},
	bdsk-url-2 = {https://doi.org/10.3389/fevo.2019.00486}}

@article{Dazard:2011aa,
	abstract = {We present an implementation in the R language for statistical computing of our recent non-parametric joint adaptive mean-variance regularization and variance stabilization procedure. The method is specifically suited for handling difficult problems posed by high-dimensional multivariate datasets (p â‰« n paradigm), such as in 'omics'-type data, among which are that the variance is often a function of the mean, variable-specific estimators of variances are not reliable, and tests statistics have low powers due to a lack of degrees of freedom. The implementation offers a complete set of features including: (i) normalization and/or variance stabilization function, (ii) computation of mean-variance-regularized t and F statistics, (iii) generation of diverse diagnostic plots, (iv) synthetic and real 'omics' test datasets, (v) computationally efficient implementation, using C interfacing, and an option for parallel computing, (vi) manual and documentation on how to setup a cluster. To make each feature as user-friendly as possible, only one subroutine per functionality is to be handled by the end-user. It is available as an R package, called MVR ('Mean-Variance Regularization'), downloadable from the CRAN.},
	address = {Division of Bioinformatics, Center for Proteomics and Bioinformatics, Case Western Reserve University. Cleveland, OH 44106, USA.; Division of Bioinformatics, Center for Proteomics and Bioinformatics, Case Western Reserve University. Cleveland, OH 44106, USA.; Division of Biostatistics, Dept. of Epidemiology and Public Health, The University of Miami. Miami, FL 33136, USA.},
	author = {Dazard, Jean-Eudes and Xu, Hua and Rao, J Sunil},
	cois = {Conflict of Interest: None declared.},
	crdt = {2016/01/29 06:00},
	date = {2011 Jul-Aug},
	date-added = {2023-11-23 23:11:51 -0800},
	date-modified = {2023-11-23 23:11:51 -0800},
	edat = {2011/07/01 00:00},
	gr = {P30 CA043703/CA/NCI NIH HHS/United States; R01 GM085205/GM/NIGMS NIH HHS/United States},
	issn = {1543-3218 (Print); 1543-3218 (Electronic); 1543-3218 (Linking)},
	jid = {101530522},
	journal = {Proc Am Stat Assoc},
	jt = {Proceedings. American Statistical Association. Annual Meeting},
	keywords = {High-Dimensional Data; Mean-Variance Estimation; Parallel Programming; R package; Regularization and Variance Stabilization; Regularized Test-statistics},
	language = {eng},
	lr = {20191120},
	mhda = {2011/07/01 00:00},
	mid = {NIHMS746138},
	month = {Jul-Aug},
	oto = {NOTNLM},
	own = {NLM},
	pages = {3849--3863},
	phst = {2016/01/29 06:00 {$[$}entrez{$]$}; 2011/07/01 00:00 {$[$}pubmed{$]$}; 2011/07/01 00:00 {$[$}medline{$]$}},
	pl = {United States},
	pmc = {PMC4725579},
	pmid = {26819572},
	pst = {ppublish},
	pt = {Journal Article},
	status = {Publisher},
	title = {R package MVR for Joint Adaptive Mean-Variance Regularization and Variance Stabilization.},
	volume = {2011},
	year = {2011}}

@article{Efron:2002aa,
	abstract = {In a classic two-sample problem, one might use Wilcoxon's statistic to test for a difference between treatment and control subjects. The analogous microarray experiment yields thousands of Wilcoxon statistics, one for each gene on the array, and confronts the statistician with a difficult simultaneous inference situation. We will discuss two inferential approaches to this problem: an empirical Bayes method that requires very little a priori Bayesian modeling, and the frequentist method of "false discovery rates" proposed by Benjamini and Hochberg in 1995. It turns out that the two methods are closely related and can be used together to produce sensible simultaneous inferences.},
	address = {Department of Statistics and Division of Biostatistics, Stanford University, Stanford, California 94305, USA.},
	author = {Efron, Bradley and Tibshirani, Robert},
	copyright = {Copyright 2002 Wiley-Liss, Inc.},
	crdt = {2002/07/12 10:00},
	date = {2002 Jun},
	date-added = {2023-11-23 23:11:51 -0800},
	date-modified = {2023-11-23 23:11:51 -0800},
	dcom = {20030121},
	doi = {10.1002/gepi.1124},
	edat = {2002/07/12 10:00},
	issn = {0741-0395 (Print); 0741-0395 (Linking)},
	jid = {8411723},
	journal = {Genet Epidemiol},
	jt = {Genetic epidemiology},
	language = {eng},
	lr = {20210407},
	mh = {*Bayes Theorem; Breast Neoplasms/genetics; Female; Genes, BRCA1; Genes, BRCA2; Humans; *Oligonucleotide Array Sequence Analysis; Reproducibility of Results},
	mhda = {2003/01/22 04:00},
	month = {Jun},
	number = {1},
	own = {NLM},
	pages = {70--86},
	phst = {2002/07/12 10:00 {$[$}pubmed{$]$}; 2003/01/22 04:00 {$[$}medline{$]$}; 2002/07/12 10:00 {$[$}entrez{$]$}},
	pl = {United States},
	pmid = {12112249},
	pst = {ppublish},
	pt = {Journal Article},
	sb = {IM},
	status = {MEDLINE},
	title = {Empirical bayes methods and false discovery rates for microarrays.},
	volume = {23},
	year = {2002},
	bdsk-url-1 = {https://doi.org/10.1002/gepi.1124}}

@article{Smyth:2004aa,
	abstract = {The problem of identifying differentially expressed genes in designed microarray experiments is considered. Lonnstedt and Speed (2002) derived an expression for the posterior odds of differential expression in a replicated two-color experiment using a simple hierarchical parametric model. The purpose of this paper is to develop the hierarchical model of Lonnstedt and Speed (2002) into a practical approach for general microarray experiments with arbitrary numbers of treatments and RNA samples. The model is reset in the context of general linear models with arbitrary coefficients and contrasts of interest. The approach applies equally well to both single channel and two color microarray experiments. Consistent, closed form estimators are derived for the hyperparameters in the model. The estimators proposed have robust behavior even for small numbers of arrays and allow for incomplete data arising from spot filtering or spot quality weights. The posterior odds statistic is reformulated in terms of a moderated t-statistic in which posterior residual standard deviations are used in place of ordinary standard deviations. The empirical Bayes approach is equivalent to shrinkage of the estimated sample variances towards a pooled estimate, resulting in far more stable inference when the number of arrays is small. The use of moderated t-statistics has the advantage over the posterior odds that the number of hyperparameters which need to estimated is reduced; in particular, knowledge of the non-null prior for the fold changes are not required. The moderated t-statistic is shown to follow a t-distribution with augmented degrees of freedom. The moderated t inferential approach extends to accommodate tests of composite null hypotheses through the use of moderated F-statistics. The performance of the methods is demonstrated in a simulation study. Results are presented for two publicly available data sets.},
	address = {Walter and Eliza Hall Institute. smyth{\char64}wehi.edu.au},
	author = {Smyth, Gordon K},
	crdt = {2006/05/02 09:00},
	date = {2004},
	date-added = {2023-11-23 23:11:51 -0800},
	date-modified = {2023-11-23 23:11:51 -0800},
	dcom = {20060518},
	dep = {20040212},
	doi = {10.2202/1544-6115.1027},
	edat = {2006/05/02 09:00},
	issn = {1544-6115 (Electronic); 1544-6115 (Linking)},
	jid = {101176023},
	journal = {Stat Appl Genet Mol Biol},
	jt = {Statistical applications in genetics and molecular biology},
	language = {eng},
	lr = {20220510},
	mhda = {2006/05/02 09:01},
	own = {NLM},
	pages = {Article3},
	phst = {2006/05/02 09:00 {$[$}pubmed{$]$}; 2006/05/02 09:01 {$[$}medline{$]$}; 2006/05/02 09:00 {$[$}entrez{$]$}},
	pl = {Germany},
	pmid = {16646809},
	pst = {ppublish},
	pt = {Journal Article},
	status = {PubMed-not-MEDLINE},
	title = {Linear models and empirical bayes methods for assessing differential expression in microarray experiments.},
	volume = {3},
	year = {2004},
	bdsk-url-1 = {https://doi.org/10.2202/1544-6115.1027}}

@article{Tusher:2001aa,
	abstract = {Microarrays can measure the expression of thousands of genes to identify changes in expression between different biological states. Methods are needed to determine the significance of these changes while accounting for the enormous number of genes. We describe a method, Significance Analysis of Microarrays (SAM), that assigns a score to each gene on the basis of change in gene expression relative to the standard deviation of repeated measurements. For genes with scores greater than an adjustable threshold, SAM uses permutations of the repeated measurements to estimate the percentage of genes identified by chance, the false discovery rate (FDR). When the transcriptional response of human cells to ionizing radiation was measured by microarrays, SAM identified 34 genes that changed at least 1.5-fold with an estimated FDR of 12%, compared with FDRs of 60 and 84% by using conventional methods of analysis. Of the 34 genes, 19 were involved in cell cycle regulation and 3 in apoptosis. Surprisingly, four nucleotide excision repair genes were induced, suggesting that this repair pathway for UV-damaged DNA might play a previously unrecognized role in repairing DNA damaged by ionizing radiation.},
	address = {Departments of Medicine and Biochemistry, Stanford University, 269 Campus Drive, Center for Clinical Sciences Research 1115, Stanford, CA 94305-5151, USA.},
	author = {Tusher, V G and Tibshirani, R and Chu, G},
	crdt = {2001/04/20 10:00},
	date = {2001 Apr 24},
	date-added = {2023-11-23 23:11:51 -0800},
	date-modified = {2023-11-23 23:11:51 -0800},
	dcom = {20010521},
	dep = {20010417},
	doi = {10.1073/pnas.091062498},
	edat = {2001/04/20 10:00},
	ein = {Proc Natl Acad Sci U S A 2001 Aug 28;98(18):10515},
	gr = {CA75675/CA/NCI NIH HHS/United States; CA77302/CA/NCI NIH HHS/United States},
	issn = {0027-8424 (Print); 1091-6490 (Electronic); 0027-8424 (Linking)},
	jid = {7505876},
	journal = {Proc Natl Acad Sci U S A},
	jt = {Proceedings of the National Academy of Sciences of the United States of America},
	language = {eng},
	lr = {20220410},
	mh = {Apoptosis/genetics/radiation effects; Cell Cycle/genetics/radiation effects; DNA Damage/genetics/radiation effects; DNA Repair/genetics; Down-Regulation/radiation effects; *Gene Expression Profiling; Gene Expression Regulation/*radiation effects; Humans; *Oligonucleotide Array Sequence Analysis; RNA, Messenger/genetics/metabolism; Radiation, Ionizing; Reproducibility of Results; Statistics as Topic; Tumor Cells, Cultured; Up-Regulation/radiation effects},
	mhda = {2001/05/25 10:01},
	month = {Apr},
	number = {9},
	own = {NLM},
	pages = {5116--5121},
	phst = {2001/04/20 10:00 {$[$}pubmed{$]$}; 2001/05/25 10:01 {$[$}medline{$]$}; 2001/04/20 10:00 {$[$}entrez{$]$}},
	pii = {091062498; 0624},
	pl = {United States},
	pmc = {PMC33173},
	pmid = {11309499},
	pst = {ppublish},
	pt = {Journal Article; Research Support, Non-U.S. Gov't; Research Support, U.S. Gov't, P.H.S.},
	rn = {0 (RNA, Messenger)},
	sb = {IM},
	status = {MEDLINE},
	title = {Significance analysis of microarrays applied to the ionizing radiation response.},
	volume = {98},
	year = {2001},
	bdsk-url-1 = {https://doi.org/10.1073/pnas.091062498}}
